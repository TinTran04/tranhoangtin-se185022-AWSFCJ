[
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": " Cách iFood xây dựng nền tảng để chạy hàng trăm mô hình machine learning với Amazon SageMaker Inference Bởi Daniel Vieira, Debora Fanin, Gopi Mudiyala và Saurabh Trikande – ngày 08 tháng 4 năm 2025, trong chuyên mục Nâng cao (300), Amazon SageMaker Data \u0026amp; AI Governance, Customer Solutions.\nGiới thiệu Có trụ sở chính tại São Paulo, Brazil, iFood là một công ty tư nhân quốc gia và là công ty hàng đầu trong lĩnh vực công nghệ thực phẩm ở Mỹ Latinh, xử lý hàng triệu đơn đặt hàng hàng tháng. iFood nổi bật với chiến lược kết hợp công nghệ tiên tiến vào hoạt động của mình. Với sự hỗ trợ của AWS, iFood đã phát triển cơ sở hạ tầng suy luận machine learning (ML) mạnh mẽ, sử dụng các dịch vụ như Amazon SageMaker để tạo và triển khai các mô hình ML một cách hiệu quả. Sự hợp tác này đã cho phép iFood không chỉ tối ưu hóa các quy trình nội bộ mà còn cung cấp các giải pháp sáng tạo cho các đối tác giao hàng và nhà hàng của mình.\nNền tảng ML của iFood bao gồm một tập hợp các công cụ, quy trình và workflow được phát triển với các mục tiêu chính:\nĐẩy nhanh quá trình phát triển và đào tạo các mô hình AI/ML, làm cho chúng đáng tin cậy và dễ tái tạo hơn. Đảm bảo rằng việc triển khai các mô hình này vào sản xuất là đáng tin cậy, có thể mở rộng và có thể truy xuất nguồn gốc. Tạo điều kiện thuận lợi cho việc thử nghiệm, giám sát và đánh giá các mô hình trong sản xuất một cách minh bạch, dễ tiếp cận và tiêu chuẩn hóa. Hình 1. Minh họa tổng quan — iFood và ứng dụng AI/ML trong hệ thống sản phẩm.\nMục tiêu và cách tiếp cận Để đạt được những mục tiêu trên, iFood tận dụng SageMaker để đơn giản hóa việc huấn luyện và triển khai mô hình. Việc tích hợp các tính năng của SageMaker trong cơ sở hạ tầng của iFood tự động hóa các bước quan trọng — từ tạo dataset huấn luyện, huấn luyện mô hình, triển khai mô hình vào production đến liên tục theo dõi hiệu suất.\nBài viết này trình bày cách iFood sử dụng SageMaker để cải tiến toàn bộ vòng đời ML — từ huấn luyện đến suy luận — đồng thời mô tả những thay đổi kiến trúc và các khả năng mà đội ngũ đã phát triển.\nSuy luận AI tại iFood iFood khai thác nền tảng AI/ML để nâng cao trải nghiệm khách hàng trên nhiều điểm tiếp xúc. Một số trường hợp sử dụng điển hình:\nĐề xuất cá nhân hóa — Mô hình phân tích lịch sử đặt hàng, sở thích và ngữ cảnh để đề xuất nhà hàng và món ăn phù hợp, giúp tăng mức độ hài lòng và số lượng đơn hàng. Theo dõi đơn hàng thông minh — Hệ thống dự đoán thời gian giao hàng theo thời gian thực bằng cách kết hợp dữ liệu giao thông, thời gian chuẩn bị nhà hàng và vị trí shipper, từ đó thông báo chủ động cho khách. Dịch vụ khách hàng tự động — Chatbot AI xử lý hàng nghìn yêu cầu phổ biến mỗi ngày, cung cấp phản hồi nhanh và có thể truy xuất dữ liệu liên quan để hỗ trợ cá nhân hóa. Hỗ trợ mua sắm hàng tạp hóa — Ứng dụng tích hợp mô hình ngôn ngữ giúp khách hàng tạo danh sách mua sắm từ yêu cầu bằng giọng nói hoặc văn bản. Nhờ những sáng kiến này, iFood có thể dự đoán nhu cầu, tối ưu hoá quy trình và cung cấp trải nghiệm nhất quán cho người dùng.\nTổng quan về giải pháp (Kiến trúc kế thừa) Sơ đồ dưới đây minh họa kiến trúc kế thừa của iFood, trong đó các nhóm Data Science và Engineering có workflow tách biệt — chính điều này gây ra thách thức khi triển khai mô hình ML thời gian thực vào production.\nHình 2. Kiến trúc kế thừa — mô tả luồng dữ liệu và rào cản giữa các nhóm.\nTrước đây, các nhà khoa học dữ liệu thường phát triển mô hình trong notebook, tinh chỉnh và xuất bản artifact. Các kỹ sư sau đó phải tích hợp các artifact này vào hệ thống production, dẫn tới độ trễ và lỗi tích hợp. Để khắc phục, iFood đã phát triển một nền tảng ML nội bộ nhằm hợp nhất quy trình từ phát triển đến triển khai, tạo trải nghiệm liền mạch cho cả hai bên.\nKiến trúc cập nhật và ML Go! Một trong các khả năng cốt lõi của nền tảng ML của iFood là cung cấp cơ sở hạ tầng để phục vụ dự đoán. Nền tảng nội bộ (gọi là ML Go!) chịu trách nhiệm triển khai quy trình, quản lý SageMaker Endpoints và Jobs. ML Go! hỗ trợ cả dự đoán ngoại tuyến (batch) và dự đoán thời gian thực (online), đồng thời quản lý lifecycle của mô hình (registry, versioning, monitoring).\nHình 3. Kiến trúc cập nhật — bao gồm pipeline, model registry và component cho inference.\nNền tảng cung cấp:\nML pipelines tự động (SageMaker Pipelines) để huấn luyện và tái huấn luyện mô hình. ML Go! CI/CD để đẩy artifact, build Docker image, và kích hoạt pipeline. SageMaker Model Registry để versioning và quản lý mô hình. Cơ chế monitoring để phát hiện drift và cảnh báo hiệu năng suy giảm. Kiến trúc cuối cùng: inference components \u0026amp; ML Go! Gateway Một cải tiến lớn là khái niệm trừu tượng hóa để kết nối với SageMaker (Endpoints \u0026amp; Jobs) gọi là ML Go! Gateway, cùng với tách biệt “inference components” trong endpoint — giúp phân chia mối quan tâm, tăng tốc phân phối và quản lý tài nguyên hiệu quả hơn. Các endpoint giờ đây quản lý nhiều thành phần suy luận (component-based inference), và ML Go! CI/CD chỉ lo phần quảng bá phiên bản mô hình (model promotion), không can thiệp sâu vào tầng hạ tầng.\nHình 4. Kiến trúc cuối cùng — inference components, ML Go! Gateway và tích hợp với service accounts.\nTrong cấu trúc mới:\nEndpoints có thể chứa nhiều component inference, cho phép phân tải công việc, chia theo tải hoặc chức năng. ML Go! Dispatcher/ Gateway đóng vai trò chuyển tiếp yêu cầu tới đúng endpoint hoặc job. CI/CD xử lý artifacts (Docker images, configs), SageMaker Pipeline orchestrates training → evaluation → registry → deployment. Sử dụng SageMaker Inference Model Serving Containers Tiêu chuẩn hóa môi trường bằng container là yếu tố quyết định của nền tảng ML hiện đại. SageMaker cung cấp các container dựng sẵn cho TensorFlow, PyTorch, XGBoost… đồng thời cho phép đưa container tùy chỉnh.\niFood tập trung sử dụng container tùy chỉnh (custom containers) để:\nChuẩn hóa mã ML (không dùng trực tiếp notebook vào production). Đóng gói dependency, thư viện và logic inference trong image (ví dụ: BruceML scaffolding). Dễ dàng tái tạo môi trường huấn luyện và phục vụ, theo dõi kết quả và debug. BruceML giúp chuẩn hóa cách viết mã huấn luyện và phục vụ, tạo scaffold tương thích với SageMaker (autotuning, deployment hooks, monitoring).\nTự động hóa triển khai và đào tạo lại (ML pipelines \u0026amp; CI/CD) iFood dùng SageMaker Pipelines để xây dựng CI/CD cho ML: pipelines chịu trách nhiệm orchestrate toàn bộ luồng dữ liệu — từ data preprocessing, training, evaluation, tới promotion vào Model Registry và deployment. ML Go! CI/CD tích hợp với hệ thống CI/CD của tổ chức để:\nĐẩy artifact (code + container image). Kích hoạt pipeline huấn luyện và đánh giá. Tự động đăng ký mô hình đạt chuẩn vào Model Registry. Triển khai hoặc promote mô hình lên endpoint phù hợp (online / batch). Tùy theo SLA:\nBatch inference: sử dụng SageMaker Transform jobs cho dự đoán quy mô lớn. Real-time inference: triển khai mô hình tới SageMaker Endpoint với cấu hình container/instance phù hợp. SageMaker Pipelines giúp tự động hóa và điều phối các workflow phức tạp, giảm sai sót và rút ngắn vòng lặp phát triển.\nChạy suy luận ở các định dạng SLA khác nhau iFood tận dụng nhiều phương thức suy luận để đáp ứng các yêu cầu khác nhau:\nReal-time endpoints cho các tác vụ cần latency thấp (user-facing). Batch transform jobs cho xử lý dữ liệu quy mô lớn, tính toán gợi ý định kỳ. Asynchronous inference (SageMaker Asynchronous Inference) cho các tác vụ suy luận tốn thời gian. Multi-model endpoints (GPU) để host nhiều mô hình trên cùng một GPU endpoint, tối ưu sử dụng tài nguyên. Những cải tiến hợp tác giữa iFood và đội SageMaker Inference bao gồm:\nTối ưu hóa chi phí và hiệu suất cho inference (giảm ~50% chi phí cho một số workloads, giảm ~20% latency trung bình khi dùng inference components). Cải tiến autoscaling để xử lý spikes hiệu quả hơn (rút ngắn thời gian scale, cải thiện phát hiện scale events). Hỗ trợ triển khai LLM / Foundation Models (FM) dễ dàng hơn. Tính năng scale-to-zero cho endpoints giúp tiết kiệm chi phí khi không có traffic. Multi-model GPU endpoints giúp giảm chi phí cơ sở hạ tầng cho trường hợp nhiều mô hình. Tối ưu hóa và đóng gói mô hình Một số điểm kỹ thuật iFood tập trung:\nChuẩn hóa container cho cả training và serving. Tự động hóa build/publish images lên registry (ECR). Đóng gói LLM / FM để triển khai nhanh hơn. Hỗ trợ autoscaling và scale-to-zero cho môi trường dev/test và low-traffic workloads. Lợi ích đạt được \u0026amp; tác động Những lợi ích iFood thu được:\nGiảm thời gian đưa mô hình vào production (faster time-to-market). Tăng khả năng tái sử dụng pipeline \u0026amp; artifacts giữa các nhóm. Hạ chi phí vận hành nhờ tối ưu GPU/multi-model và scale-to-zero. Cải thiện độ ổn định và khả năng quản lý mô hình ở quy mô lớn. Kết luận Sử dụng các khả năng của SageMaker, iFood đã chuyển đổi cách tiếp cận ML/AI: xây dựng nền tảng ML tập trung (ML Go!), tự động hóa luồng dữ liệu, chuẩn hóa container và hợp tác cùng nhóm SageMaker Inference để tối ưu tính hiệu quả, chi phí và khả năng mở rộng. Việc này đã giúp iFood:\nThu hẹp khoảng cách giữa Data Science và Engineering. Triển khai hàng trăm mô hình ML một cách đáng tin cậy. Tạo nền tảng tham chiếu cho các tổ chức muốn ứng dụng inference ở quy mô lớn. “Tại iFood, chúng tôi đi đầu trong việc áp dụng công nghệ AI và máy học biến đổi\u0026hellip; Các bài học đã học được hỗ trợ chúng tôi trong việc tạo ra nền tảng nội bộ, có thể đóng vai trò như một kế hoạch chi tiết cho các tổ chức khác\u0026hellip;”\n– Daniel Vieira, Giám đốc Nền tảng ML tại iFood.\nGiới thiệu về các tác giả Daniel Vieira — Giám đốc Kỹ thuật Học máy tại iFood. Có nền tảng khoa học máy tính (BSc \u0026amp; MSc, UFMG) và hơn một thập kỷ kinh nghiệm về kỹ thuật phần mềm và nền tảng ML. Thích âm nhạc, triết học và cà phê.\nDebora Fanin — Giám đốc giải pháp khách hàng cấp cao, AWS (Brazil). Chuyên quản lý chuyển đổi khách hàng doanh nghiệp, thiết kế các chiến lược áp dụng đám mây hiệu quả về chi phí.\nSaurabh Trikande — Giám đốc sản phẩm cấp cao, Amazon Bedrock \u0026amp; SageMaker Inference. Tập trung vào dân chủ hóa AI và giải pháp suy luận ở quy mô lớn.\nGopi Mudiyala — Giám đốc tài khoản kỹ thuật cấp cao, AWS. Hỗ trợ khách hàng ngành dịch vụ tài chính và đam mê máy học.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 1: Làm quen với nhóm và môi trường học tập tại First Cloud Journey (FCJ). Hiểu tổng quan về dịch vụ AWS và các nhóm dịch vụ cơ bản. Biết cách tạo tài khoản AWS Free Tier và kích hoạt $200 credit. Làm quen với AWS Management Console để sử dụng các dịch vụ cơ bản. Cài đặt và thiết lập AWS CLI để thao tác với tài nguyên AWS bằng dòng lệnh. Thực hành một số bài lab cơ bản như tạo tài khoản, thiết lập MFA, ngân sách, và tìm hiểu EC2. Các công việc cần triển khai trong tuần này Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tạo tài khoản AWS Free Tier - Thực hiện 5 bước để nhận $200 credit: + Sử dụng mô hình nền tảng trong Amazon Bedrock playground + Tạo cơ sở dữ liệu Amazon RDS + Tạo ứng dụng web bằng AWS Lambda + Thiết lập ngân sách chi phí với AWS Budgets + Khởi chạy một phiên bản máy chủ bằng Amazon EC2 08/09/2025 08/09/2025 AWS Free Tier 3 - Xem và học các Module giới thiệu AWS (YouTube): + Module 01-01 - Điện toán đám mây là gì? + Module 01-02 - Điều gì tạo nên sự khác biệt của AWS? + Module 01-03 - Bắt đầu hành trình lên mây như thế nào + Module 01-04 - Hạ tầng toàn cầu của AWS + Module 01-05 - Công cụ quản lý AWS Services + Module 01-06 - Tối ưu hóa chi phí và làm việc với AWS + Module 01-07 - Thực hành và nghiên cứu bổ sung 09/09/2025 09/09/2025 Tài liệu học tập 4 - Thực hành (YouTube): + Module 01-Lab01-01 - Tạo tài khoản AWS + Module 01-Lab01-02 - Thiết lập thiết bị MFA ảo + Module 01-Lab01-03 - Tạo nhóm quản trị và người dùng quản trị + Module 01-Lab01-04 - Hỗ trợ xác thực tài khoản + Module 01-Lab07-01 - Tạo ngân sách bằng mẫu (Template) + Module 01-Lab07-02 - Hướng dẫn tạo ngân sách chi phí + Module 01-Lab07-03 - Tạo ngân sách sử dụng (Usage Budget) trong AWS + Module 01-Lab07-04 - Tạo ngân sách Dành riêng (Reservation Instance - RI) + Module 01-Lab07-05 - Tạo ngân sách Gói tiết kiệm (Savings Plans) + Module 01-Lab07-06 - Dọn dẹp ngân sách (Clean Up Budgets) + Module 01-Lab09-01 - Các gói hỗ trợ AWS + Module 01-Lab09-02 - Các loại yêu cầu hỗ trợ + Module 01-Lab09-03 - Thay đổi gói hỗ trợ + Module 01-Lab09-04 - Quản lý các yêu cầu hỗ trợ 10/09/2025 10/09/2025 Tài liệu học tập 5 - Tìm hiểu EC2 cơ bản (thực hành): + EC2 là gì? + AMI (Amazon Machine Image) + EBS (Elastic Block Store) + Elastic IP + Các cách kết nối SSH vào EC2 + Tạo và quản lý phiên bản EC2 11/09/2025 11/09/2025 Tài liệu học tập Kết quả đạt được tuần 1: Đã tạo tài khoản AWS Free Tier thành công và kích hoạt được $200 credit. Biết đăng nhập và sử dụng giao diện AWS Management Console, tìm kiếm và truy cập các dịch vụ cơ bản. Cài đặt và cấu hình AWS CLI thành công trên máy tính cá nhân, bao gồm: Thiết lập Access Key, Secret Key, Region mặc định. Làm quen với các module học lý thuyết và lab hướng dẫn trên YouTube, gồm: Tổng quan điện toán đám mây và AWS Hạ tầng toàn cầu của AWS Quản lý tài khoản và ngân sách chi phí Giới thiệu về EC2 và cách tạo instance Bắt đầu hiểu cách tạo, khởi chạy và kết nối tới EC2 instance. Biết cách thiết lập ngân sách bằng AWS Budgets để theo dõi chi phí sử dụng. Hoàn thành các bước cấu hình bảo mật cơ bản (thiết lập MFA, người dùng quản trị IAM). "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Trần Hoàng Tín\nSố điện thoại: 0936091757\nEmail: tinthse185022@fpt.edu.vn\nTrường: Đại học FPT Hồ Chí Minh\nNgành: Công nghệ thông tin\nLớp: SE185022\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Tuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Làm công việc A\u0026hellip;\nTuần 3: Làm công việc B\u0026hellip;\nTuần 4: Làm công việc C\u0026hellip;\nTuần 5: Làm công việc D\u0026hellip;\nTuần 6: Làm công việc E\u0026hellip;\nTuần 7: Làm công việc G\u0026hellip;\nTuần 8: Làm công việc H\u0026hellip;\nTuần 9: Làm công việc I\u0026hellip;\nTuần 10: Làm công việc L\u0026hellip;\nTuần 11: Làm công việc M\u0026hellip;\nTuần 12: Làm công việc N\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/4-eventparticipated/4.1-event1/",
	"title": "Sự kiện 1",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders” Thông tin sự kiện Tên sự kiện: AWS Cloud Day Vietnam – AI Edition 2025 (Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders) Ngày: 18 tháng 9 năm 2025 Địa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, Thành phố Hồ Chí Minh Vai trò: Người tham dự Mục Đích Của Sự Kiện Sự kiện AWS Cloud Day Vietnam – AI Edition 2025 được định vị là một cuộc tụ họp quan trọng của cộng đồng công nghệ và kinh doanh tại Việt Nam. Mục tiêu chính là thúc đẩy quá trình chuyển đổi số bằng cách tận dụng sức mạnh kết hợp của Điện toán đám mây (Cloud Computing) và Trí tuệ nhân tạo (AI).\nCác mục tiêu có thể được khái quát thành các trụ cột và ý nghĩa sau:\nKết nối cộng đồng công nghệ Việt Nam:\nTạo không gian gặp gỡ, trao đổi giữa doanh nghiệp, chuyên gia IT, lập trình viên và lãnh đạo ngành để cùng học hỏi về Cloud \u0026amp; AI.\nGiúp doanh nghiệp hiểu và ứng dụng thực tế Cloud \u0026amp; AI:\nTập trung vào các chủ đề như Gen AI, phân tích dữ liệu (data analytics), hiện đại hóa hệ thống (modernize workloads), và industry cloud cho từng ngành cụ thể.\nTrình diễn các câu chuyện thành công:\nGiới thiệu các case study như Xanh SM, Honda Việt Nam, Masterise Group, Techcombank, TymeX, F88… cho thấy Cloud \u0026amp; AI có thể chuyển hóa vận hành doanh nghiệp như thế nào.\nThúc đẩy phát triển kinh tế số và đổi mới sáng tạo:\nGóp phần hiện thực hóa chiến lược chuyển đổi số quốc gia, đưa Cloud \u0026amp; AI trở thành nền tảng cho tăng trưởng kinh tế.\nXây dựng nền tảng giao lưu – kết nối – hợp tác lâu dài:\nTạo cầu nối giữa công nghệ – doanh nghiệp – lãnh đạo ngành, hướng đến hợp tác bền vững trong kỷ nguyên số.\nBốn trụ cột chiến lược được nhấn mạnh Phổ cập AI tạo sinh (GenAI) cho doanh nghiệp\nĐưa GenAI vượt ra khỏi tính “hào nhoáng” ban đầu để đi vào ứng dụng thực tế. Chứng minh cách doanh nghiệp có thể biến các mô hình AI chung chung thành các giải pháp nhận biết ngữ cảnh, gắn với chiến lược dữ liệu. Xóa bỏ ranh giới giữa Kinh doanh và CNTT\nĐặc biệt trong lĩnh vực Dịch vụ Tài chính (FSI). Cloud không chỉ là hạ tầng, mà là động lực tạo giá trị kinh doanh, cho phép mô hình Ecosystem Banking và Embedded Finance. Tăng tốc hiện đại hóa theo đặc thù ngành\nXây dựng lộ trình riêng cho từng ngành: Bán lẻ, Năng lượng, Viễn thông, Bất động sản, Khu vực công,… Nhấn mạnh rằng hiện đại hóa không có “một công thức chung”, mà phải dựa vào đặc điểm từng hệ thống và chiến lược doanh nghiệp. Củng cố an ninh và khả năng phục hồi\nĐề cao tư duy “security by design” – bảo mật từ khâu thiết kế. Tích hợp bảo mật vào suốt vòng đời ứng dụng, từ phát triển đến vận hành thực tế. Danh Sách Diễn Giả Sự kiện quy tụ 24 diễn giả từ cơ quan nhà nước, đại sứ quán, các tổ chức tài chính – ngân hàng, công nghệ và đối tác AWS. Một số diễn giả tiêu biểu:\nH.E. Pham Duc Long – Thứ trưởng Bộ Khoa học và Công nghệ, Việt Nam H.E. Marc E. Knapper – Đại sứ Hoa Kỳ tại Việt Nam Jaime Valles – Phó Chủ tịch, Tổng Giám đốc khu vực Châu Á Thái Bình Dương \u0026amp; Nhật Bản, AWS Jeff Johnson – Managing Director ASEAN, AWS Dr Jens Lottner – CEO, Techcombank Dieter Botha – CEO, TymeX Trang Phung – CEO, U2U Network Vu Van – Đồng sáng lập \u0026amp; CEO, ELSA Corp Nguyen Hoa Binh – Chủ tịch, Nexttech Group Cùng nhiều lãnh đạo và chuyên gia khác từ F88, Masterise Group, VTV Digital, Honda Việt Nam, Mobifone, Katalon, Renova Cloud, TechX Corp,… Nội Dung Nổi Bật 1. Sự hội tụ chiến lược: Chính sách và lãnh đạo Sự bảo trợ của Chính phủ:\nBài phát biểu khai mạc của Thứ trưởng Bộ KH\u0026amp;CN và Đại sứ Hoa Kỳ cho thấy sự ủng hộ mạnh mẽ đối với hạ tầng số và hệ sinh thái Cloud – AI tại Việt Nam.\nTọa đàm Lãnh đạo (Leadership Panel):\nCác lãnh đạo như Jeff Johnson (AWS), Vu Van (ELSA), Nguyen Hoa Binh (Nexttech)… nhấn mạnh vai trò của con người và văn hóa đổi mới trong việc thúc đẩy chuyển đổi số, chứ không chỉ là vấn đề công nghệ.\n2. Nhóm 1: Dịch vụ Tài chính (FSI) – Mô hình ngân hàng mới Đổi mới trong Ngân hàng \u0026amp; Bảo hiểm:\nTechcombank, Bảo Việt Holdings và các tổ chức tài chính chia sẻ hành trình chuyển dịch sang mô hình Ngân hàng Hệ sinh thái (Ecosystem Banking) và Tài chính Nhúng (Embedded Finance).\nTriển khai XGenAI:\nTechX trình bày về nền tảng XGenAI xây dựng trên AWS, thể hiện cách GenAI được dùng để cá nhân hóa trải nghiệm khách hàng, tối ưu chăm sóc và gợi ý dịch vụ tài chính.\n3. Nhóm 2: Hiện đại hóa đa ngành Honda Việt Nam:\nChia sẻ chi tiết lộ trình di chuyển hệ thống SAP lên AWS, không chỉ dừng ở “lift-and-shift” mà còn hướng tới thay đổi mô hình vận hành, tối ưu chi phí và độ linh hoạt.\nVTV Digital \u0026amp; Mobifone:\nTrình bày hành trình số hóa từ “Tầm nhìn đến Giá trị” trong ngành truyền thông số và viễn thông.\nMasterise Group:\nNhấn mạnh việc di chuyển hàng trăm workload VMware lên AWS, cho thấy quy mô và độ phức tạp trong quá trình hiện đại hóa hạ tầng bất động sản.\n4. Nhóm 3 \u0026amp; 4: Dữ liệu, AI và DevOps Chiến lược dữ liệu (Data Strategy):\nCác chuyên gia từ Onebyzero, Techcom Securities nhấn mạnh rằng “dữ liệu là yếu tố khác biệt then chốt” cho GenAI; chất lượng đầu ra AI phụ thuộc trực tiếp vào chất lượng dữ liệu đầu vào.\nCuộc cách mạng DevOps:\nKatalon và Renova Cloud trình bày cách tích hợp GenAI vào vòng đời DevOps: tự động sinh mã, tự động sinh test cases, phân tích log và tối ưu CI/CD.\n5. Các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu, bỏ lỡ cơ hội thị trường. Hoạt động kém hiệu quả → Mất năng suất, tăng chi phí vận hành. Không tuân thủ quy định bảo mật → Rủi ro mất an ninh, ảnh hưởng uy tín thương hiệu. Những hạn chế này chính là động lực thúc đẩy việc hiện đại hóa kiến trúc ứng dụng.\n6. Chuyển đổi sang kiến trúc Microservices Sự kiện nhấn mạnh việc chuyển từ hệ thống nguyên khối (monolith) sang Microservices Architecture:\nHệ thống được modular hóa, mỗi chức năng là một dịch vụ độc lập. Các service giao tiếp qua sự kiện (event-driven). Ba trụ cột kiến trúc được nêu rõ:\nQueue Management: Xử lý tác vụ bất đồng bộ, giảm tải cho hệ thống chính. Caching Strategy: Tối ưu performance, giảm độ trễ truy vấn. Message Handling: Giao tiếp linh hoạt giữa các service, hỗ trợ mở rộng và phục hồi lỗi. 7. Domain-Driven Design (DDD) Phương pháp 4 bước:\nXác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts.\nCase study “Bookstore”:\nĐược dùng để minh họa cách áp dụng DDD trong thực tế, từ mô hình hóa domain đến tách service.\nContext mapping – 7 patterns tích hợp:\nGiúp quản lý quan hệ giữa các bounded contexts (Partnership, Shared Kernel, Anti-corruption Layer,…).\n8. Event-Driven Architecture 3 patterns tích hợp chính:\nPublish/Subscribe Point-to-Point Streaming Lợi ích:\nLoose coupling giữa các service Scalability dễ dàng Resilience cao hơn khi có lỗi cục bộ So sánh Sync vs Async:\nDiễn giả phân tích rõ trade-offs: synchronous đơn giản nhưng dễ nghẽn; asynchronous phức tạp hơn nhưng linh hoạt và chịu tải tốt.\n9. Compute Evolution \u0026amp; Serverless Shared Responsibility Model:\nGiải thích vai trò AWS vs khách hàng trên các mô hình: EC2 → ECS → Fargate → Lambda.\nLợi ích Serverless:\nKhông cần quản lý server Tự động scale Trả tiền theo giá trị sử dụng thực (pay-for-value) Functions vs Containers:\nGợi ý tiêu chí lựa chọn (thời gian chạy, tính trạng thái, tần suất, độ phức tạp deployment,…).\n10. Amazon Q Developer Tự động hóa SDLC:\nHỗ trợ developer xuyên suốt từ planning → coding → testing → maintenance.\nCode transformation:\nHỗ trợ nâng cấp Java, hiện đại hóa .NET, và migration từ mainframe / legacy stack lên kiến trúc mới.\nAWS Transform Agents:\nCung cấp các agent chuyên biệt cho VMware, Mainframe, .NET…, giúp giảm thời gian và rủi ro khi hiện đại hóa ứng dụng.\nNhững Gì Học Được 1. Tư Duy Thiết K Kế \u0026amp; Chiến Lược Business-first approach:\nGiải pháp công nghệ phải xuất phát từ vấn đề kinh doanh, thay vì chạy theo xu hướng kỹ thuật.\nUbiquitous Language:\nNgôn ngữ chung giữa business và tech giúp giảm hiểu lầm, đẩy nhanh quá trình phân tích yêu cầu và thiết kế.\nResilience là tiêu chuẩn:\nHệ thống hiện đại cần thiết kế cho khả năng phục hồi ngay từ đầu, thay vì “vá” sau khi có sự cố.\n2. Kiến Trúc Kỹ Thuật Event storming:\nLà phương pháp hiệu quả để mô hình hóa quy trình nghiệp vụ thành các domain events, từ đó dẫn đến thiết kế DDD và kiến trúc event-driven.\nEvent-driven communication:\nViệc thay thế một phần giao tiếp synchronous bằng cơ chế event-driven giúp hệ thống linh hoạt, dễ mở rộng và giảm phụ thuộc.\nIntegration patterns:\nHiểu rõ khi nào dùng sync API, khi nào dùng pub/sub, khi nào nên dùng streaming (Kafka/Kinesis).\nCompute spectrum:\nBiết cách cân nhắc giữa VM, containers, serverless để chọn runtime phù hợp cho từng workload.\n3. Chiến Lược Hiện Đại Hóa Phased approach:\nKhông nên “đập đi làm lại” tất cả cùng lúc. Cần roadmap theo giai đoạn, ưu tiên các hệ thống có tác động lớn.\n7Rs framework:\nCó nhiều con đường để hiện đại hóa (Rehost, Replatform, Refactor, Rearchitect, Repurchase, Retire, Retain).\nMỗi ứng dụng cần được đánh giá riêng.\n“Migrate to Operate”:\nMục tiêu không chỉ là di chuyển lên cloud, mà là vận hành thông minh hơn sau khi di chuyển, liên tục tối ưu chi phí, hiệu năng và bảo mật.\nROI measurement:\nCần đo lường rõ ràng: giảm chi phí, tăng agility, rút ngắn time-to-market, cải thiện trải nghiệm khách hàng.\nỨng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại:\nTổ chức các buổi event storming với team business để mô hình hóa domain và tách bounded contexts.\nRefactor Microservices:\nDùng bounded contexts để xác định ranh giới service, tránh microservices bị “chia vụn” hoặc overlap trách nhiệm.\nImplement Event-driven patterns:\nDần thay thế một số API synchronous bằng cơ chế async messaging, pub/sub, hoặc streaming.\nServerless Adoption:\nThử nghiệm triển khai một số use case bằng AWS Lambda hoặc Fargate để đánh giá lợi ích thực tế.\nKiểm toán độ sẵn sàng dữ liệu:\nTrước khi bắt đầu bất kỳ dự án GenAI nào, cần kiểm tra data quality, data governance và chiến lược dữ liệu tổng thể.\nThử nghiệm GenAI trong DevOps:\nSử dụng các công cụ như Amazon Q Developer để sinh mã, sinh test tự động, rút ngắn chu kỳ phát triển.\nTriển khai “Security by design”:\nÁp dụng các best practices về IAM, encryption, logging, monitoring ngay từ giai đoạn thiết kế hệ thống.\nTrải nghiệm trong sự kiện Tham dự AWS Cloud Day Vietnam – AI Edition 2025 mang lại cho tôi cái nhìn vừa chiến lược, vừa thực tiễn:\nHọc hỏi từ các diễn giả có chuyên môn cao Các bài chia sẻ của lãnh đạo ngân hàng, chuyên gia cloud, kiến trúc sư giải pháp giúp tôi hiểu rõ sự gắn kết giữa chiến lược kinh doanh và hạ tầng kỹ thuật. Những case study thực tế (Techcombank, Honda, Masterise, TymeX…) giúp tôi hình dung rõ ràng hơn về con đường chuyển đổi của từng ngành. Trải nghiệm kỹ thuật thực tế Các phiên về event storming, DDD, microservices, event-driven architecture giúp tôi kết nối kiến thức lý thuyết với kịch bản triển khai thực tế. Tôi đặc biệt ấn tượng với workshop “GenAI-powered App-DB Modernization”, nơi mô phỏng hành trình hiện đại hóa một ứng dụng monolith sang kiến trúc cloud-native. Ứng dụng công cụ hiện đại Lần đầu tiếp cận sâu với Amazon Q Developer trong bối cảnh SDLC thực tế, tôi thấy rõ tiềm năng sử dụng AI để tăng năng suất và giảm lặp lại công việc của developer. Việc tích hợp GenAI vào DevOps cho tôi cái nhìn mới về tương lai phát triển phần mềm. Kết nối và trao đổi Sự kiện là cơ hội tốt để trao đổi với các chuyên gia, anh chị làm trong ngành tài chính, công nghệ, cloud consulting,… Qua các cuộc thảo luận ngắn bên lề, tôi nhận ra rằng chuyển đổi số không chỉ là chuyện kỹ thuật, mà còn là thay đổi cách nghĩ, cách làm việc và văn hóa doanh nghiệp. Bài học rút ra Dữ liệu là yếu tố khác biệt then chốt: GenAI không thể phát huy hiệu quả nếu dữ liệu không được quản trị tốt. Hiện đại hóa là một hành trình liên tục: Không có “đích đến cố định”, mà là quá trình liên tục tối ưu và thích nghi. Bảo mật là việc của mọi người: Từ developer đến vận hành, từ lãnh đạo đến nhân viên, ai cũng phải ý thức về security. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/4-eventparticipated/4.2-event2/",
	"title": "Sự kiện 2",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “Khám Phá Agentic AI – Amazon QuickSuite” Thông tin sự kiện Tên sự kiện: GenAI-powered App-DB Modernization workshop Ngày: Ngày 7 tháng 11 năm 2025 Địa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, Thành phố Hồ Chí Minh Vai trò: Người tham dự Mục Đích Của Sự Kiện Làm rõ khái niệm Agentic AI: sự chuyển dịch từ Generative AI thụ động sang AI Tác tử (Agentic) có khả năng hành động tự chủ. Giới thiệu và trình diễn trực tiếp Amazon QuickSuite lần đầu tiên tại Việt Nam. Thúc đẩy doanh nghiệp ứng dụng Agentic AI thông qua chương trình hỗ trợ tài chính AWS LIFT (tín dụng lên đến 80,000 USD). Cung cấp môi trường hands-on thực tế, giúp người tham dự trực tiếp xây dựng và trải nghiệm mô hình AI dưới sự hướng dẫn của chuyên gia AWS và đối tác. Danh Sách Diễn Giả Vivien Nguyen – Territory Manager (Quản lý Vùng), AWS Tung Cao – Solution Architect (Kiến trúc sư Giải pháp), AWS Đội ngũ Cloud Kinetics – Đối tác triển khai chiến lược của AWS tại Việt Nam Nội Dung Nổi Bật Sự thay đổi mô hình: Từ Generative AI đến Agentic AI Generative AI (AI Tạo sinh)\nTập trung vào việc tạo nội dung (văn bản, hình ảnh, mã nguồn,…) theo prompt của người dùng. Mang tính thụ động: chỉ phản hồi khi được hỏi. Agentic AI (AI Tác tử)\nTập trung vào sự tự chủ và khả năng hành động. Có thể nhận thức môi trường, lập kế hoạch, suy luận qua nhiều bước và tự động thực thi nhiệm vụ mà không cần con người can thiệp liên tục. Mục tiêu: xây dựng các hệ thống “AI làm việc thay mình”, chứ không chỉ “trò chuyện với AI”. Workshop giúp tôi hiểu rõ rằng Agentic AI là bước tiến từ “AI trả lời” sang “AI hành động”, rất phù hợp cho các tác vụ phức tạp và lặp lại trong doanh nghiệp.\nGiới thiệu Amazon QuickSuite Lần đầu demo trực tiếp tại Việt Nam:\nWorkshop đánh dấu buổi trình diễn live đầu tiên của Amazon QuickSuite với người dùng tại Việt Nam. Hệ sinh thái hợp nhất:\nKết nối chặt chẽ giữa: Amazon QuickSight – trực quan hóa và phân tích dữ liệu. QuickSuite Q – tương tác bằng ngôn ngữ tự nhiên, đặt câu hỏi và tạo insight. Từ đó hình thành các “Analyst Agents” có thể đọc dữ liệu, trả lời câu hỏi nghiệp vụ và đề xuất hành động. Tốc độ và tính linh hoạt (“Quick”):\nCho phép doanh nghiệp đi từ ý tưởng → prototype → thử nghiệm thực tế trong thời gian ngắn. Phù hợp với đội ngũ muốn thử nghiệm nhanh và cải thiện liên tục. Lấy dữ liệu làm trung tâm:\nQuickSuite được thiết kế cho khối lượng dữ liệu lớn, đảm bảo tác tử AI có đủ “chất liệu” để đưa ra quyết định chính xác và bám sát thực tế kinh doanh. Hệ sinh thái đối tác \u0026amp; hỗ trợ chiến lược AWS cung cấp nền tảng hạ tầng và dịch vụ AI/Analytics. Cloud Kinetics đóng vai trò: Tư vấn kiến trúc, bảo đảm giải pháp phù hợp với đặc thù từng doanh nghiệp. Hỗ trợ triển khai “bước cuối cùng” (last-mile) – biến công nghệ trừu tượng thành giải pháp cụ thể, chạy được trong môi trường thật. Mô hình “hai lớp hỗ trợ” (AWS + đối tác) giúp doanh nghiệp giảm rủi ro, nhất là khi bắt đầu với các công nghệ mới như Agentic AI.\nChương trình AWS LIFT – Hỗ trợ tài chính cho đổi mới Tín dụng lên tới 80,000 USD cho khách hàng đủ điều kiện, đặc biệt là doanh nghiệp mới, SMBs. Mục đích: Giảm rào cản chi phí khi thử nghiệm các hệ thống tính toán hiệu năng cao và các dự án R\u0026amp;D về AI. Cho phép doanh nghiệp tập trung vào ý tưởng và triển khai, thay vì lo lắng quá nhiều về chi phí hạ tầng ban đầu. Những Gì Học Được Tư Duy Thiết Kế Tập trung vào sự tự chủ của hệ thống:\nKhi thiết kế Agentic AI, mục tiêu là xây dựng các tác tử chủ động làm việc thay con người, ví dụ: Tự động tạo báo cáo định kỳ. Giám sát số liệu và gửi cảnh báo. Gợi ý điều chỉnh vận hành (như chuỗi cung ứng). Gắn AI với “nút thắt” vận hành cụ thể:\nKhông xây AI theo phong trào, mà bắt đầu từ những quy trình: Lặp đi lặp lại. Gồm nhiều bước thủ công. Dễ sai sót nếu con người tự làm. Kiến Trúc Kỹ Thuật Tiếp cận theo hệ sinh thái (ecosystem-based):\nMột tác tử hiệu quả cần kết nối với nhiều công cụ: nguồn dữ liệu, BI, API, workflow… Trong bối cảnh này, QuickSuite là “mạch kết nối” giữa: Dữ liệu (data sources, QuickSight). Logic hành động (câu hỏi, rule, kịch bản tác vụ tự động). Sẵn sàng về hạ tầng AWS:\nBước đầu tiên là thiết lập tài khoản AWS, region, quyền truy cập, và các dịch vụ cần thiết. Điều này tạo nền tảng để sau đó có thể dễ dàng bật/tắt, thử nghiệm các dịch vụ mới như QuickSuite, Agentic workflows. Chiến Lược Hiện Đại Hóa \u0026amp; Triển Khai Lợi thế của người đi trước (early adopter):\nNhững doanh nghiệp/nhóm sớm tìm hiểu và làm chủ QuickSuite sẽ có lợi thế về năng suất, tốc độ ra quyết định và khả năng thử nghiệm mô hình kinh doanh mới. Quản lý chi phí thông minh:\nKết hợp tín dụng AWS LIFT với cách tiếp cận PoC nhỏ, rõ ràng mục tiêu. Giúp tăng tốc time-to-market nhưng vẫn giảm thiểu rủi ro tài chính. Ứng Dụng Vào Công Việc Tìm hiểu sâu hơn về QuickSuite:\nKhảo sát cách tích hợp QuickSight + QuickSuite Q vào quy trình phân tích dữ liệu hiện tại. Hướng tới xây dựng các “Analyst Agents” có thể tự động trả lời câu hỏi về KPI, xu hướng, báo cáo. Tận dụng chương trình AWS LIFT:\nXem xét điều kiện và đăng ký tham gia để nhận tín dụng AWS cho các dự án R\u0026amp;D hoặc PoC về AI/Agentic AI. Xác định use case nội bộ phù hợp với Agentic AI:\nRà soát các quy trình lặp lại nhiều bước (báo cáo, giám sát, phân loại yêu cầu…) để xem có thể chuyển hóa thành workflow của một tác tử AI hay không. Hợp tác với đối tác như Cloud Kinetics:\nThay vì tự xây 100% in-house, có thể cùng đối tác thiết kế kiến trúc chuẩn, tránh sai lầm từ đầu, nhất là với hệ thống phức tạp. Trải nghiệm trong event Tham dự workshop “Khám Phá Agentic AI – Amazon QuickSuite” tại Bitexco Financial Tower là một trải nghiệm chuyên nghiệp và nhiều chiều: vừa học lý thuyết, vừa thực hành, vừa kết nối cộng đồng.\nHọc hỏi từ các diễn giả có chuyên môn cao Được nghe trực tiếp chia sẻ từ AWS và Cloud Kinetics về tầm nhìn Agentic AI trong doanh nghiệp. Nội dung cân bằng giữa concept (Agentic AI là gì, vì sao quan trọng) và thực tế triển khai (dùng QuickSuite như thế nào, bắt đầu từ đâu). Trải nghiệm kỹ thuật thực tế Phiên hands-on ~90 phút giúp tôi: Trực tiếp thao tác với QuickSight + QuickSuite Q. Hiểu rõ hơn cách một “tác tử phân tích” có thể đọc dữ liệu và trả lời câu hỏi nghiệp vụ. Sự hỗ trợ “cầm tay chỉ việc” của chuyên gia AWS giúp tôi giải quyết ngay những khó khăn ban đầu khi làm quen với công cụ mới. Kết nối và hệ sinh thái Thời gian networking cho phép trao đổi với: Các anh/chị đang làm trong lĩnh vực cloud, data, AI. Đội ngũ Cloud Kinetics, hiểu rõ hơn vai trò của đối tác trong việc biến nền tảng AWS thành giải pháp cụ thể cho từng ngành. Bài học rút ra Agentic AI là tương lai của vận hành doanh nghiệp:\nSự chuyển dịch từ “trò chuyện với AI” sang “AI thực sự làm việc” sẽ mở ra nhiều mô hình tối ưu hóa mới. Tốc độ là yếu tố then chốt:\nCác công cụ như QuickSuite được thiết kế để triển khai nhanh, nên ai đi sớm sẽ có lợi thế về agility. Nguồn vốn thúc đẩy đổi mới:\nChương trình AWS LIFT cho thấy bài toán không còn chỉ là “chi phí có cho phép không”, mà là “chúng ta có dám và có kịp tận dụng cơ hội hay không”. Tóm lại, workshop đã giúp tôi hiểu rõ hơn về Agentic AI, cách AWS hiện thực hóa nó qua Amazon QuickSuite, và những nguồn lực (công cụ, đối tác, tài chính) mà AWS cung cấp để doanh nghiệp có thể bắt đầu hành trình ứng dụng AI một cách thực tế và bền vững.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/5-workshop/5.1-objectives--scope/",
	"title": "Objectives &amp; Scope",
	"tags": [],
	"description": "",
	"content": "Phần này xác định mục đích, mục tiêu học tập và phạm vi của workshop được xây dựng xoay quanh một Nền tảng phân tích clickstream theo lô (batch-based Clickstream Analytics Platform) cho một website thương mại điện tử bán các sản phẩm máy tính.\nNền tảng được triển khai trên AWS và sử dụng:\nNext.js trên AWS Amplify Hosting (front-end, Server-Side Rendering). Amazon CloudFront (phân phối nội dung toàn cầu). Amazon Cognito (xác thực người dùng). Amazon API Gateway và AWS Lambda (ingest clickstream và ETL). Amazon S3 (lưu trữ dữ liệu clickstream thô). Amazon VPC với các public subnet và private subnet (cô lập mạng). PostgreSQL trên Amazon EC2 (OLTP và Data Warehouse). R Shiny Server (các dashboard phân tích). Bối cảnh nghiệp vụ (Business Context) Hệ thống mục tiêu là một website thương mại điện tử bán các sản phẩm liên quan đến máy tính (laptop, màn hình, phụ kiện, v.v.).\nDoanh nghiệp mong muốn:\nHiểu cách người dùng tương tác với website (các trang đã truy cập, sản phẩm đã xem, sự kiện thêm vào giỏ hàng, các lần thử thanh toán). Đo lường các phễu chuyển đổi (conversion funnel) (từ xem sản phẩm đến mua hàng). Xác định các sản phẩm bán chạy nhất và các khoảng thời gian có hoạt động cao. Thực hiện được những điều trên mà không ảnh hưởng đến cơ sở dữ liệu vận hành và không phơi bày các thành phần phân tích nội bộ ra Internet công cộng. Vì vậy, nền tảng sẽ tách biệt xử lý giao dịch trực tuyến (OLTP) khỏi phân tích, và thu thập dữ liệu clickstream trong một môi trường phân tích chuyên biệt.\nMục tiêu học tập (Learning Objectives) Sau khi hoàn thành tất cả các phần (5.1–5.6), người đọc sẽ có thể:\nHiểu biết về kiến trúc Mô tả được kiến trúc tổng thể của một nền tảng phân tích clickstream theo lô trên AWS. Giải thích sự khác nhau giữa: Miền hướng tới người dùng (user-facing domain) (Amplify, CloudFront, Cognito, EC2 OLTP). Miền ingest \u0026amp; data lake (API Gateway, Lambda Ingest, S3 Raw bucket). Miền phân tích \u0026amp; data warehouse (ETL Lambda, PostgreSQL DW, Shiny). Lý giải được vì sao OLTP và Analytics được tách biệt cả về logic lẫn hạ tầng vật lý, và điều này giúp giảm rủi ro cho workload vận hành như thế nào. Kỹ năng thực hành Kích hoạt và kiểm tra luồng ingest clickstream từ frontend vào API Gateway → Lambda Ingest → S3. Cấu hình Gateway VPC Endpoint cho S3 và cập nhật route table để các thành phần phân tích bên trong private subnet có thể truy cập S3 mà không cần dùng NAT Gateway. Cấu hình và kiểm thử một ETL Lambda chạy trong VPC với khả năng: Đọc các file JSON thô từ S3 Raw Clickstream bucket. Biến đổi (transform) event thành các bảng phân tích sẵn sàng cho SQL. Nạp dữ liệu vào PostgreSQL Data Warehouse đặt trên EC2 trong private subnet. Kết nối đến Data Warehouse và chạy các truy vấn SQL mẫu để kiểm tra pipeline (đếm số event, top sản phẩm, v.v.). Truy cập các dashboard R Shiny chạy trên cùng EC2 với Data Warehouse và diễn giải các biểu đồ chính (funnel, top sản phẩm, chuỗi thời gian). Nhận thức về bảo mật và chi phí Giải thích cách Gateway VPC Endpoint giữ traffic S3 trên mạng riêng của AWS. So sánh việc sử dụng Gateway VPC Endpoint với NAT Gateway về bảo mật, chi phí và độ phức tạp vận hành. Liệt kê các cơ chế bảo mật chính được sử dụng trong kiến trúc: Phân tách public subnet và private subnet. Security group giữa OLTP, ETL Lambda và Data Warehouse. Quyền hạn IAM tối thiểu cần thiết cho Lambda Ingest và ETL Lambda. Phạm vi của Workshop (Scope of the Workshop) Workshop tập trung vào ba nhóm khả năng cốt lõi của nền tảng:\nTriển khai luồng ingest clickstream\nGhi nhận tương tác của người dùng trong trình duyệt. Gửi event dạng JSON đến API Gateway. Lưu trữ event thô thành các file được phân vùng theo thời gian trong S3 Raw Clickstream bucket. Xây dựng lớp phân tích riêng tư (private analytics layer)\nCấu hình VPC, private subnet và S3 Gateway VPC Endpoint. Chạy ETL Lambda bên trong VPC để Lambda có thể: Đọc từ S3 qua kết nối riêng tư. Ghi dữ liệu vào PostgreSQL Data Warehouse trên EC2 private. Trực quan hóa phân tích với các dashboard Shiny\nTruy vấn các bảng phân tích từ R Shiny Server chạy trên cùng EC2 với Data Warehouse. Cung cấp các dashboard tương tác để phân tích funnel, hiệu suất sản phẩm và xu hướng theo thời gian. Workshop giả định rằng:\nPhần hạ tầng nền tảng (VPC, subnet, EC2 instance, IAM role, khung Lambda cơ bản, và S3 bucket) đã được provision sẵn, ví dụ thông qua Terraform hoặc CloudFormation. Trọng tâm là hiểu và kiểm chứng luồng dữ liệu và kết nối riêng tư, hơn là viết mã ETL hay mã frontend đạt chuẩn production từ đầu. Các chủ đề ngoài phạm vi (Out-of-Scope Topics) Để nội dung tập trung và có thể hoàn thành trong thời gian giới hạn, workshop không đề cập đến:\nCác pipeline streaming thời gian thực (ví dụ Amazon Kinesis, Kafka hoặc các dịch vụ streaming được quản lý). Các công nghệ data warehouse nâng cao như Amazon Redshift, Redshift Serverless hoặc kiến trúc Lakehouse. Các mô hình machine learning phức tạp hoặc mô hình phân đoạn người dùng (user segmentation) xây trên dữ liệu clickstream. Pipeline CI/CD ở mức production, triển khai blue/green, hay mô hình nhiều tài khoản AWS (multi-account). Tối ưu hóa sâu truy vấn SQL và thiết kế index vượt ngoài các ví dụ đơn giản. Các chủ đề này được xem là phần mở rộng trong tương lai của nền tảng và có thể được khám phá trong các công việc tiếp theo.\nĐối tượng mục tiêu (Target Audience) Workshop chủ yếu dành cho:\nSinh viên hoặc kỹ sư đã có hiểu biết cơ bản về AWS và muốn thấy cách nhiều dịch vụ kết hợp với nhau thành một giải pháp phân tích thực tế. Lập trình viên quen thuộc với JavaScript/TypeScript, SQL và môi trường Linux. Bất kỳ ai quan tâm đến việc thiết kế một kiến trúc phân tích an toàn, tiết kiệm chi phí, chủ yếu dựa trên các dịch vụ serverless và một footprint EC2 nhỏ. Người đọc không cần phải là chuyên gia về mạng hoặc data engineering; các phần sau (5.2–5.5) sẽ cung cấp các bước cụ thể, có hướng dẫn rõ ràng để giúp kiến trúc trở nên trực quan và có thể tái tạo.\nHình 5-1: Amplify hosting cho frontend thương mại điện tử\nẢnh chụp màn hình thể hiện ứng dụng Amplify đang host frontend Next.js của website thương mại điện tử, bao gồm nhánh chính (main branch), trạng thái lần triển khai gần nhất và URL CloudFront được sử dụng trong workshop này.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": " Cách Salesforce Business Technology sử dụng AWS Direct Connect SiteLink để kết nối toàn cầu đáng tin cậy Bởi Alexandra Huides và Corey Harris Jr – ngày 09 tháng 5 năm 2025, trong chuyên mục AWS Direct Connect SiteLink.\nGiới thiệu Salesforce Business Technology đã sử dụng AWS Direct Connect SiteLink để xây dựng kiến trúc mạng lai toàn cầu, đảm bảo kết nối linh hoạt, hiệu suất cao và đáng tin cậy.\nGiải pháp này giúp Salesforce mở rộng hạ tầng, giảm chi phí vận hành và tăng tốc độ đổi mới trong hành trình hiện đại hóa lên đám mây AWS.\nBài viết được thực hiện với sự hợp tác của Georgi Stoev và Ravi Patel – các chuyên gia kỹ thuật cấp cao tại Salesforce.\nTổng quan Salesforce là đối tác chiến lược của AWS và là công ty hàng đầu thế giới về quản lý quan hệ khách hàng (CRM).\nNhóm Business Technology chịu trách nhiệm xây dựng và vận hành các ứng dụng doanh nghiệp, hỗ trợ các mảng như tài chính, trung tâm dữ liệu, bảo mật, kho dữ liệu, và các máy ảo của Salesforce.\nVới quy mô toàn cầu, Salesforce cần một kiến trúc mạng:\nLinh hoạt và có khả năng mở rộng cao. Giảm thiểu độ trễ và thời gian ngừng hoạt động. Đảm bảo tính bảo mật và độ tin cậy cao. Tuy nhiên, các giải pháp mạng truyền thống dựa trên internet không thể đáp ứng yêu cầu nghiêm ngặt này.\nĐó là lý do AWS Direct Connect SiteLink được lựa chọn — cung cấp kết nối riêng tư, chuyên dụng, bỏ qua internet công cộng, giúp cải thiện bảo mật và độ trễ đáng kể.\nĐiều kiện tiên quyết Trước khi triển khai, nhóm kỹ thuật Salesforce đã nắm rõ các thành phần mạng AWS sau:\nAmazon Virtual Private Cloud (VPC) AWS Transit Gateway AWS Direct Connect Các dịch vụ này là nền tảng cho kiến trúc mạng lai toàn cầu, cho phép kết nối riêng tư và độ trễ thấp giữa nhiều vị trí Direct Connect — mà không cần đi qua các vùng AWS trung gian.\nAWS Direct Connect SiteLink AWS Direct Connect cung cấp kết nối mạng riêng giữa hạ tầng tại chỗ và AWS, giúp tối ưu hiệu năng, độ trễ và độ tin cậy.\nSiteLink là một tính năng mở rộng của Direct Connect, cho phép kết nối trực tiếp giữa các mạng tại chỗ thông qua đường trục mạng toàn cầu của AWS, giúp:\nGửi dữ liệu qua đường dẫn ngắn nhất, không cần qua vùng AWS. Tận dụng mạng AWS toàn cầu để truyền dữ liệu nhanh và an toàn. Thanh toán theo mức sử dụng thực tế, không cần thiết lập kết nối mới. Quy trình hoạt động:\nKết nối mạng tại chỗ đến AWS tại một trong hơn 100 điểm Direct Connect trên toàn cầu. Tạo Virtual Interface (VIF) trên kết nối đó và bật SiteLink. Khi các VIF được gắn vào cùng một Direct Connect Gateway (DXGW), dữ liệu sẽ được truyền trực tiếp giữa các vị trí, sử dụng đường trục AWS. Dấu ấn toàn cầu của Salesforce Business Technology Salesforce Business Technology quản lý 7 địa điểm chiến lược trên toàn cầu:\n3 ở Hoa Kỳ 3 ở Châu Á – Thái Bình Dương 1 ở Châu Âu Mạng được xây dựng trên đường trục riêng MPLS kết hợp với AWS Regions, hỗ trợ các luồng dữ liệu phức tạp giữa trung tâm dữ liệu và môi trường đám mây.\nTuy nhiên, các thách thức nảy sinh gồm:\nCơ sở hạ tầng tĩnh và khó mở rộng. Chi phí vận hành cao và phụ thuộc nhiều nhà cung cấp. Độ phức tạp định tuyến và sự cố kéo dài ở một số khu vực. Hình 1. Một mẫu kết nối trung tâm dữ liệu riêng toàn cầu sử dụng các mạch riêng.\nGiải pháp: SiteLink Để giải quyết vấn đề, Salesforce Business Technology đã hiện đại hóa hạ tầng mạng bằng cách triển khai SiteLink.\nMục tiêu chính:\nXây dựng mạng linh hoạt, có thể mở rộng theo nhu cầu. Giảm chi phí vận hành và độ phức tạp. Tăng khả năng phục hồi và bảo mật. Nhóm đã:\nTriển khai SiteLink trên các kết nối Direct Connect hiện có. Tạo các VIF chuyên dụng mới cho môi trường sản xuất và phát triển. Duy trì phân khúc toàn cầu, đáp ứng yêu cầu lưu trữ dữ liệu tại chỗ. Hình 2. Mẫu triển khai SiteLink toàn cầu cho Sản xuất và Phát triển.\nLợi ích đạt được Giải pháp SiteLink mang lại nhiều lợi ích vượt trội cho Salesforce:\nLợi ích Mô tả Đơn giản hóa quản lý mạng Loại bỏ độ phức tạp của định tuyến MPLS Layer 3 VPN, vẫn duy trì khả năng tách biệt lưu lượng. Cải thiện hiệu suất Tăng ổn định, giảm độ trễ trung bình 15% trên toàn cầu. Tối ưu hóa chi phí Tận dụng kết nối hiện có, thanh toán theo mức sử dụng. Bảo mật nâng cao Áp dụng mã hóa MACSec lớp 2 trên toàn bộ kết nối Direct Connect. Ngoài ra, SiteLink giúp:\nGiảm số điểm hỏng đơn lẻ (SPOF) và tăng độ tin cậy mạng. Tối ưu tuyến đường dữ liệu giữa các trung tâm dữ liệu. Giám sát toàn diện qua CloudWatch Network Monitor. “Với SiteLink, Salesforce Business Technology đã hợp lý hóa các hoạt động mạng và đảm bảo khả năng phục hồi tối đa cho kết nối toàn cầu. Chúng tôi có thể thiết lập kết nối giữa 7 trung tâm dữ liệu chỉ trong vài phút và mở rộng sang thị trường mới trong vài ngày.”\n— Ravi Patel, Giám đốc kỹ thuật cấp cao tại Salesforce.\nKết luận Việc áp dụng AWS Direct Connect SiteLink đã giúp Salesforce:\nThống nhất kiến trúc mạng trên toàn cầu. Hiện đại hóa hạ tầng, giảm chi phí và cải thiện hiệu suất. Chuẩn bị sẵn sàng cho quy mô mở rộng và đổi mới nhanh chóng. Để tìm hiểu thêm về AWS Direct Connect SiteLink, bạn có thể tham khảo tài liệu chính thức hoặc đặt câu hỏi trên AWS re:Post.\nGiới thiệu về các tác giả Alexandra Huides\nKiến trúc sư giải pháp chuyên gia mạng tại AWS.\nTập trung vào kiến trúc mạng quy mô lớn, hỗ trợ khách hàng áp dụng IPv6 và xây dựng môi trường linh hoạt. Ngoài công việc, cô yêu thích chèo thuyền, du lịch và đọc sách.\nCorey Harris Jr.\nKiến trúc sư giải pháp cấp cao tại AWS.\nLà chuyên gia về mạng và serverless, giúp khách hàng tối ưu hệ thống AWS. Ngoài công việc, anh yêu thích game, du lịch và thời gian bên gia đình.\nGeorgi Stoev\nKiến trúc sư kỹ thuật cấp cao tại Salesforce.\nVới hơn 20 năm kinh nghiệm trong lĩnh vực mạng, AI và bảo mật, anh đam mê công nghệ, nghiên cứu ong mật và khám phá thiên nhiên.\nRavi Patel\nGiám đốc kỹ thuật cấp cao tại Salesforce.\nCó hơn 15 năm kinh nghiệm xây dựng mạng linh hoạt và hiệu suất cao. Ngoài công việc, anh thích lướt sóng, leo núi, và phiêu lưu khám phá thế giới.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 2: Đi sâu vào các dịch vụ AWS, tập trung vào Compute, Networking và Storage. Làm quen với AWS EC2, S3, Lambda và Elastic Beanstalk. Thực hành tạo và quản lý các EC2 instance, làm việc với lưu trữ và triển khai ứng dụng web. Hiểu về AWS IAM để quản lý danh tính và quyền truy cập. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học cơ bản về AWS EC2 + Các loại EC2 instance + Nhóm bảo mật EC2 (Security Group) + Quản lý vòng đời các EC2 instance 15/09/2025 15/09/2025 Tài liệu học tập 3 - Học về AWS S3 + Tạo S3 Bucket + Quản lý object trong S3 + Kiểm soát quyền truy cập (ACL, Bucket policy) 16/09/2025 16/09/2025 Tài liệu học tập 4 - Học về AWS Lambda + Giới thiệu kiến trúc serverless và AWS Lambda + Tạo hàm Lambda đơn giản + Kích hoạt Lambda từ dịch vụ AWS khác 17/09/2025 17/09/2025 Tài liệu học tập 5 - Học về AWS Elastic Beanstalk + Tổng quan Elastic Beanstalk + Triển khai ứng dụng mẫu bằng Elastic Beanstalk 18/09/2025 18/09/2025 Tài liệu học tập 6 - Học về IAM (Identity and Access Management) + Tạo và quản lý IAM User, Group, Role + Gán policy và quản lý quyền truy cập 19/09/2025 19/09/2025 Tài liệu học tập 7 - Thực hành tổng hợp: + Labs cho EC2, S3, Lambda, Elastic Beanstalk + Rà soát lại các bước tạo, cấu hình, deploy 20/09/2025 20/09/2025 Tài liệu học tập Kết quả đạt được tuần 2: Đã tạo và quản lý được các EC2 instance (khởi tạo, dừng/xoá, xem thông tin). Nắm được cách cấu hình và sử dụng AWS S3 để lưu trữ và quản lý object (upload, xem, xoá, phân quyền). Đã tạo và kiểm tra hoạt động của một hàm AWS Lambda đơn giản, biết cách kích hoạt Lambda từ dịch vụ khác. Đã triển khai thành công một ứng dụng mẫu bằng AWS Elastic Beanstalk. Hiểu căn bản về AWS IAM, biết cách: Tạo IAM User, Group, Role Gán IAM Policy để kiểm soát quyền truy cập theo nguyên tắc “least privilege”. Hoàn thành một số bài lab thực hành tổng hợp cho EC2, S3, Lambda và Elastic Beanstalk, giúp củng cố kiến thức lý thuyết đã học. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/5-workshop/5.2-architecture-walkthrough/",
	"title": "Architecture Walkthrough",
	"tags": [],
	"description": "",
	"content": "Phần này cung cấp một cái nhìn tổng quan ở mức cao về kiến trúc tổng thể trước khi đi vào các bước thực hành chi tiết.\nMiền hướng tới người dùng (User-facing Domain) Frontend: Next.js được host trên AWS Amplify, phía trước là Amazon CloudFront. Xác thực: người dùng cuối đăng nhập thông qua Amazon Cognito User Pool. Cơ sở dữ liệu vận hành: PostgreSQL OLTP chạy trên một EC2 instance trong public subnet. Kết nối: Amplify kết nối tới EC2 OLTP thông qua Internet Gateway bằng Prisma, với biến môi trường DATABASE_URL trỏ đến endpoint public của EC2 instance. Trong thiết kế này, cơ sở dữ liệu OLTP được đặt trong public subnet một cách có chủ đích để giữ cho kết nối từ Amplify đơn giản. Trong một hệ thống đạt chuẩn production, OLTP thường sẽ nằm trong các private subnet phía sau một lớp API nội bộ.\nMiền ingest \u0026amp; data lake (Ingestion \u0026amp; Data Lake Domain) Frontend gửi các sự kiện HTTP tới Amazon API Gateway (HTTP API), route POST /clickstream.\nMột Lambda Ingest:\nKiểm tra tính hợp lệ (validate) của payload nhận được. Bổ sung (enrich) các metadata như timestamp, thông tin user/session, và ngữ cảnh sản phẩm. Ghi JSON thô vào S3 Raw Clickstream bucket theo cấu trúc thư mục được phân vùng theo thời gian: s3://\u0026lt;raw-bucket\u0026gt;/events/YYYY/MM/DD/HH/events-\u0026lt;uuid\u0026gt;.json Mẫu (pattern) này giữ cho dữ liệu thô bất biến và được phân vùng theo thời gian, rất thuận tiện cho các job ETL theo lô (batch ETL).\nMiền phân tích \u0026amp; data warehouse (Analytics \u0026amp; Data Warehouse Domain) Một ETL Lambda chạy trong VPC được đặt trong private subnet dành riêng cho analytics/ETL.\nETL Lambda đọc dữ liệu từ S3 thông qua S3 Gateway VPC Endpoint, sau đó:\nLàm sạch (clean) và chuẩn hóa (normalize) các event. Chuyển đổi log JSON thành các bảng phân tích thân thiện với SQL (bảng fact và dimension). Ghi dữ liệu vào PostgreSQL Data Warehouse host trên một EC2 instance trong một private subnet riêng biệt. Một R Shiny Server chạy trên cùng EC2 instance với Data Warehouse và kết nối qua localhost / private IP. Shiny render các dashboard tương tác dựa trên schema của Data Warehouse.\nHình 5-2: Các EC2 instance và các metric CloudWatch cơ bản\nẢnh chụp màn hình cho thấy hai EC2 instance được sử dụng trong workshop:\nSBW_EC2_Web_OLTP – instance public host cơ sở dữ liệu PostgreSQL OLTP. SBW_EC2_Shiny_DW – instance private host PostgreSQL Data Warehouse và Shiny Server. Bên dưới danh sách instance, console EC2 hiển thị các CloudWatch metric cơ bản như CPU utilization và network traffic, có thể dùng để xác minh tình trạng “khỏe mạnh” của các instance trong lúc chạy các lab của workshop.\nHình 5-3: Kiến trúc tổng thể nền tảng Clickstream Analytics\nSơ đồ minh họa:\nBên ngoài VPC: Amazon Cognito, Amazon CloudFront, AWS Amplify, Amazon API Gateway, Lambda Ingest và Amazon EventBridge. Bên trong VPC: Public Subnet – OLTP: EC2 PostgreSQL OLTP và Internet Gateway. Private Subnet – Analytics: EC2 PostgreSQL Data Warehouse và R Shiny Server (không có public IP). Private Subnet – ETL: ETL Lambda chạy trong VPC và S3 Gateway VPC Endpoint. Các mũi tên được đánh số (1)–(13) thể hiện các luồng chính: đăng nhập người dùng, duyệt web, ingest clickstream, ETL theo lô, nạp dữ liệu vào Data Warehouse và trực quan hóa bằng Shiny. Hình 5-4: Sơ đồ mạng VPC (OLTP \u0026amp; Analytics)\nSơ đồ minh họa một VPC duy nhất với hai subnet:\nPublic Subnet – OLTP (10.0.1.0/24), tô màu vàng, host EC2 PostgreSQL OLTP và kết nối tới Internet Gateway. Private Subnet – Analytics (10.0.2.0/24), tô màu xanh lá, host EC2 PostgreSQL Data Warehouse, R Shiny Server, ETL Lambda chạy trong VPC, và S3 Gateway VPC Endpoint (tất cả đều không có public IP). Route table của public subnet bao gồm route mặc định:\n0.0.0.0/0 → Internet Gateway (IGW) Route table của private subnet:\nCó route 10.0.0.0/16 → local cho traffic nội bộ trong VPC. Bao gồm một route tới S3 prefix list thông qua S3 Gateway VPC Endpoint. Không có bất kỳ route 0.0.0.0/0 nào và không sử dụng NAT Gateway. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "Team Super Beast Warrior(SBW) Batch-based Clickstream Analytics Platform 1. Tóm tắt Dự án này nhằm thiết kế và triển khai Batch-based Clickstream Analytics Platform cho một website thương mại điện tử chuyên về máy tính và phụ kiện (giao diện frontend của website được tích hợp một JavaScript SDK nhẹ để gửi dữ liệu hoạt động của người dùng như clicks, views, searches tới backend API) bằng cách sử dụng AWS Cloud Services. Hệ thống thu thập dữ liệu tương tác của người dùng (như clicks, searches, và page visits) từ website và lưu trữ chúng trong Amazon S3 dưới dạng raw logs. Cứ mỗi giờ, Amazon EventBridge sẽ kích hoạt AWS Lambda để xử lý và chuyển đổi dữ liệu trước khi nạp vào data warehouse được lưu trữ trên Amazon EC2.\nDữ liệu đã được xử lý sẽ được visualize thông qua R Shiny dashboards, giúp chủ cửa hàng có thể theo dõi business insights như hành vi khách hàng, mức độ phổ biến của sản phẩm, và xu hướng tương tác trên website.\nKiến trúc này tập trung vào batch analytics, ETL pipeline, và business intelligence, đồng thời đảm bảo bảo mật (security), khả năng mở rộng (scalability), và hiệu quả chi phí (cost efficiency) thông qua việc tận dụng các AWS managed services.\n2. Vấn đề đặt ra Vấn đề hiện tại là gì? Các website E-commerce tạo ra một lượng lớn clickstream data — bao gồm product views, cart actions, và search activities — chứa đựng nhiều business insights có giá trị.\nTuy nhiên, các cửa hàng small và medium-sized thường thiếu infrastructure và expertise cần thiết để collect, process, và analyze dữ liệu này một cách hiệu quả.\nKết quả là, họ gặp khó khăn trong việc:\nHiểu hành vi mua hàng của khách hàng (customer purchasing behavior) Xác định sản phẩm hoạt động hiệu quả nhất (top-performing products) Tối ưu hóa marketing campaigns và hiệu suất website (website performance) Ra quyết định về tồn kho (inventory) và giá cả (pricing) dựa trên dữ liệu (data-driven decisions) Giải pháp Dự án này giới thiệu một AWS-based batch clickstream analytics system, tự động collect dữ liệu tương tác của người dùng từ website mỗi giờ, process thông qua serverless functions, và lưu trữ vào central data warehouse trên Amazon EC2.\nKết quả được visualize bằng R Shiny dashboards, giúp chủ cửa hàng có được actionable insights về hành vi khách hàng (customer behavior) và cải thiện hiệu suất kinh doanh tổng thể (overall business performance).\nLợi ích và hoàn vốn đầu tư Data-driven decision making: Khám phá sở thích của khách hàng, sản phẩm phổ biến và xu hướng mua sắm. Scalable and modular design: Dễ dàng mở rộng để xử lý nhiều người dùng hơn hoặc tích hợp thêm các nguồn dữ liệu mới. Cost-efficient batch processing: Giảm chi phí tính toán liên tục bằng cách vận hành theo lịch trình hàng giờ. Business insight enablement: Giúp chủ cửa hàng tối ưu hóa chiến lược bán hàng và cải thiện doanh thu dựa trên phân tích có cơ sở dữ liệu. 3. Kiến trúc giải pháp Dịch vụ AWS sử dụng Amazon Cognito: Quản lý quá trình xác thực và phân quyền người dùng cho cả quản trị viên và khách hàng của website, đảm bảo quyền truy cập an toàn vào nền tảng e-commerce. Amazon S3: Hoạt động như một lớp lưu trữ dữ liệu tập trung — lưu trữ giao diện website tĩnh (static website front-end) và các clickstream logs thô được thu thập từ tương tác người dùng. Ngoài ra, nó còn tạm thời lưu trữ các batch files trước khi được xử lý và chuyển đến data warehouse. Amazon CloudFront: Phân phối nội dung website tĩnh trên toàn cầu với độ trễ thấp, cải thiện trải nghiệm người dùng và lưu trữ cache gần khách hàng hơn. Amazon API Gateway: Đóng vai trò là điểm đầu vào chính cho các API calls từ website, cho phép gửi dữ liệu an toàn (như clickstream hoặc browsing activity) vào AWS. AWS Lambda: Thực thi các serverless functions để tiền xử lý và tổ chức clickstream data được tải lên S3. Nó cũng xử lý các tác vụ chuyển đổi dữ liệu được EventBridge kích hoạt theo lịch trước khi nạp vào data warehouse. Amazon EventBridge: Lên lịch và điều phối các batch workflows — ví dụ, kích hoạt Lambda functions mỗi giờ để xử lý và di chuyển clickstream data từ S3 vào EC2 data warehouse. Amazon EC2 (Data Warehouse): Đóng vai trò là môi trường data warehouse, chạy PostgreSQL hoặc các cơ sở dữ liệu quan hệ khác phục vụ cho batch analytics, trend analysis và business reporting. Các instances này được triển khai trong private subnet của VPC để đảm bảo cô lập mạng và an toàn. R Shiny (on EC2): Lưu trữ các dashboards tương tác hiển thị các insights đã được xử lý theo batch, giúp doanh nghiệp phân tích hành vi khách hàng, sản phẩm phổ biến và cơ hội bán hàng. AWS IAM: Quản lý quyền truy cập và chính sách nhằm đảm bảo chỉ những người dùng và thành phần AWS được ủy quyền mới có thể tương tác với dữ liệu và dịch vụ. Amazon CloudWatch: Thu thập và giám sát các metrics, logs, và trạng thái của các scheduled jobs từ Lambda và EC2 để duy trì độ tin cậy và khả năng quan sát hiệu suất hệ thống. Amazon SNS: Gửi thông báo hoặc cảnh báo khi batch jobs hoàn thành, thất bại hoặc gặp lỗi, đảm bảo doanh nghiệp kịp thời nắm bắt tình trạng vận hành. 4. Triển khai End-to-end data flow Auth (Cognito) Trình duyệt xác thực với Amazon Cognito (Hosted UI hoặc JS SDK). ID token (JWT) được lưu trong bộ nhớ; SDK tự động gắn Authorization: Bearer \u0026lt;JWT\u0026gt; cho các API calls. Static web (CloudFront + S3) SPA/assets được lưu trữ trên S3; CloudFront đứng phía trước với OAC, gzip/brotli, HTTP/2, và WAF managed rules. Trang web tải một analytics SDK nhỏ thu thập các events và gửi đến API Gateway (bên dưới). Event ingest (API Gateway) POST /v1/events (HTTP API). CORS bị giới hạn theo site origin; JWT authorizer xác thực Cognito token (hoặc API key cho luồng anonymous). Các request được chuyển tiếp đến Lambda. Security \u0026amp; Ops IAM được cấu hình least-privilege cho từng thành phần. CloudWatch ghi log, metrics và cảnh báo trên API 5xx, Lambda errors, throttles, Shiny health. SNS gửi thông báo khi có alarms hoặc DLQ tăng. Processing \u0026amp; storage (Lambda → S3 batch buffer → EventBridge → Lambda (ETL) → PostgreSQL trên EC2 (data warehouse) → Shiny) Ingest Lambda xác thực và enrich các events, sau đó append-write các NDJSON objects vào S3 (partition theo date/hour). EventBridge (cron) kích hoạt ETL Lambda (batch) theo chu kỳ cố định (ví dụ: mỗi 60 phút). ETL Lambda đọc một phần dữ liệu từ các partitions của S3, loại bỏ trùng lặp, chuyển đổi và upsert vào PostgreSQL trên EC2 (truy cập qua VPC). R Shiny Server (trên EC2) đọc các curated tables và hiển thị dashboards cho admin. Data Contracts \u0026amp; Governance Event JSON (ingest)\n{ \u0026#34;event_id\u0026#34;: \u0026#34;uuid-v4\u0026#34;, \u0026#34;ts\u0026#34;: \u0026#34;2025-10-18T12:34:56.789Z\u0026#34;, \u0026#34;event_type\u0026#34;: \u0026#34;view|click|search|add_to_cart|checkout|purchase\u0026#34;, \u0026#34;session_id\u0026#34;: \u0026#34;uuid-v4\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;cognito-sub-or-null\u0026#34;, \u0026#34;anonymous_id\u0026#34;: \u0026#34;stable-anon-id\u0026#34;, \u0026#34;page_url\u0026#34;: \u0026#34;https://site/p/123\u0026#34;, \u0026#34;referrer\u0026#34;: \u0026#34;https://google.com\u0026#34;, \u0026#34;device\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;mobile|desktop|tablet\u0026#34; }, \u0026#34;geo\u0026#34;: { \u0026#34;country\u0026#34;: \u0026#34;VN\u0026#34;, \u0026#34;city\u0026#34;: null }, \u0026#34;ecom\u0026#34;: { \u0026#34;product_id\u0026#34;: \u0026#34;sku-123\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;Shoes\u0026#34;, \u0026#34;currency\u0026#34;: \u0026#34;USD\u0026#34;, \u0026#34;price\u0026#34;: 79.99, \u0026#34;qty\u0026#34;: 1, }, \u0026#34;props\u0026#34;: { \u0026#34;search_query\u0026#34;: \u0026#34;running shoes\u0026#34; }, } PII: không bao giờ gửi name/email/phone; mọi optional identifier (nếu có) sẽ được hash trong Lambda. Behaviour: tạo anonymous_id một lần, duy trì session_id (tự động roll sau 30 phút không hoạt động); gửi dữ liệu bằng navigator.sendBeacon với fetch retry fallback; tùy chọn offline buffer thông qua IndexedDB. S3 raw layout \u0026amp; retention\nBucket: s3://clickstream-raw/ Object format: NDJSON, tùy chọn GZIP. Partitioning: year=YYYY/month=MM/day=DD/hour=HH/ → events-\u0026lt;uuid\u0026gt;.ndjson.gz Optional manifest per batch: bao gồm processed watermark, object list, record counts, và hash. Lifecycle: raw → (30 days Standard/IA) → (365+ days Glacier/Flex). Idempotency: duy trì một compact staging table trong PostgreSQL (hoặc một small S3 key-value manifest) để theo dõi (track) last processed object/batch và ngăn chặn việc tải trùng (prevent double-load). Frontend SDK (Static site on S3 + CloudFront) Instrumentation\nJS snippet nhỏ được load trên toàn site (defer). Sinh anonymous_id một lần và lưu session_id trong localStorage; session reset sau 30 phút không hoạt động. Gửi events qua navigator.sendBeacon; fallback sang fetch với retry và jitter. Auth context\nNếu người dùng đăng nhập bằng Cognito, bao gồm user_id = idToken.sub để theo dõi funnel đăng nhập. Offline durability\nService Worker queue tùy chọn: khi offline, buffer events trong IndexedDB và gửi lại khi reconnect. Ingestion API (API Gateway → Lambda) API Gateway (HTTP API)\nRoute: POST /v1/events. JWT authorizer (Cognito user pool). Đối với anonymous pre-login events, sử dụng API key với usage-plan và rate limit nghiêm ngặt. WAF: AWS Managed Core + Bot Control; chặn non-site origins bằng strict CORS. Lambda (Node.js or Python)\nValidate theo JSON Schema (ajv/pydantic). Idempotency: cache event_id gần đây trong bộ nhớ (TTL ngắn) + dedupe ở mức batch trong ETL. Enrichment: xác định date/hour, phân tích UA, suy luận country từ CloudFront-Viewer-Country nếu có. Persist: PutObject vào đường dẫn S3 .../year=YYYY/month=MM/day=DD/hour=HH/.... Failure path: publish vào SQS DLQ; cảnh báo qua SNS nếu DLQ depth \u0026gt; 0. Batch Buffer (S3) Mục đích: buffer bền vững, chi phí thấp cho batch analytics. Write pattern: các object nhỏ mỗi request hoặc micro-batches (1–5 MB) với GZIP. Optional compactor gộp thành file ≥64MB để đọc hiệu quả hơn. Read pattern: ETL Lambda chỉ quét các partitions/objects mới kể từ watermark cuối. Schema-on-read: ETL áp dụng schema, xử lý dữ liệu đến trễ bằng cách reprocess một sliding window nhỏ (ví dụ: 2 giờ cuối) để điều chỉnh sessions. EC2 “data warehouse” node Mục đích: chạy ETL và lưu trữ analytical store được Shiny truy vấn. Hai lựa chọn:\nPostgres trên EC2 (khuyến nghị nếu nhóm quen SQL/window functions)\nInstance: t3.small/t4g.small; gp3 50–100GB. Schema: fact_events, fact_sessions, dim_date, dim_product. Security: trong private subnet của VPC; truy cập qua ALB/SSM Session Manager; snapshot tự động hàng ngày lên S3. ETL (Lambda, batch qua EventBridge cron):\nTrigger: rate(5 minutes) / cron(\u0026hellip;) tùy theo cost \u0026amp; freshness. Các bước: liệt kê S3 objects mới → đọc → validate/dedupe → transform (flatten JSON, cast types, thêm ingest_date, session_window_start/end) → upsert vào Postgres bằng COPY tới bảng tạm + merge, hoặc batched INSERT \u0026hellip; ON CONFLICT. Networking: Lambda kết nối vào private subnets của VPC để truy cập Postgres security group trên EC2. R Shiny Server on EC2 (admin analytics) Server\nEC2 (t3.small/t4g.small) với: R 4.4+, Shiny Server (open-source), Nginx reverse proxy, TLS qua ACM/ALB hoặc Let’s Encrypt. IAM instance profile (không dùng static keys). Security group chỉ cho phép HTTPS từ office/VPN hoặc Cognito-gated admin site. App (packages)\nCác package R sử dụng: shiny, shinydashboard/bslib, plotly, DT, dplyr, DBI + RPostgres hoặc duckdb, lubridate. Nếu truy vấn DynamoDB trực tiếp cho các small cards, có thể sử dụng paws.dynamodb (tùy chọn). Dashboards\nTraffic \u0026amp; Engagement: DAU/MAU, sessions, avg pages, bounce proxy. Funnels: view → add_to_cart → checkout → purchase với tỷ lệ chuyển đổi từng stage (stage conversion) và drop-off. Product Performance: views, CTR, ATC rate, revenue theo product/category. Acquisition: referrer, campaign, device, country. Reliability: Lambda error rate, DLQ depth, ETL lag, data freshness. Caching\nKết quả truy vấn được cache trong process (reactive values) hoặc materialized bởi ETL; cache keys dựa trên date range và filters. Security baseline IAM\nIngest Lambda: quyền s3:PutObject tới raw bucket (giới hạn theo prefix), s3:ListBucket trên các prefix cần thiết. ETL Lambda: quyền s3:GetObject/ListBucket trên raw prefixes; được phép lấy secrets từ SSM Parameter Store; không có quyền S3 rộng. EC2 roles: chỉ đọc/ghi vào DB/volumes của chính nó; có thể đọc từ S3 để backup. Shiny EC2: không ghi vào S3 raw; chỉ read-only tới Postgres khi cần. Network\nĐặt EC2 trong private subnets; truy cập công khai qua ALB (HTTPS 443). Lambda thực hiện ETL được join vào VPC để kết nối tới Postgres; Security Group (SG) áp dụng least-privilege (chỉ mở Postgres port từ ETL SG). Không mở rộng 0.0.0.0/0 tới các DB ports. Data\nMã hóa: EBS bằng KMS, S3 server-side encryption, RDS/PG TLS, secrets lưu trong SSM Parameter Store. Dữ liệu nhạy cảm: không có PII trong events; retention: raw S3 90–365 ngày (lifecycle), curated Postgres theo chính sách kinh doanh. Observability \u0026amp; alerting CloudWatch metrics/alarms\nAPI Gateway 5xx/latency, Lambda (ingest) errors/throttles, S3 PutObject failures, EventBridge schedule success rate, ETL duration/lag, DLQ depth, Shiny health check. SNS topics: gửi thông báo on-call qua email/SMS/Slack webhook. Structured logs: JSON logs từ Lambda \u0026amp; ETL (bao gồm request_id, event_type, status, ms, error_code). Watermark tracking: custom metric “DW Freshness (minutes since last successful upsert)”.\nCost Controls (stay near Free/low tier) HTTP API được sử dụng (chi phí thấp hơn), Lambda memory tối thiểu (256–512MB), nén requests. Batch thay vì realtime: dùng S3 làm buffer để loại bỏ chi phí ghi/đọc DynamoDB. S3 lifecycle: Standard → Standard-IA/Intelligent-Tiering → Glacier cho dữ liệu raw cũ; bật GZIP để giảm chi phí lưu trữ và truyền tải. Điều chỉnh cadence ETL (ví dụ: 15–60 phút) và chỉ xử lý các object mới; gộp các file nhỏ thành file lớn để giảm read I/O. Single small EC2 cho Shiny + DW ban đầu; sau đó scale vertically hoặc tách riêng khi cần. AWS Budgets với SNS alerts cho chi phí thực tế và dự báo. Deliverables Analytics SDK (TypeScript): hỗ trợ sessionization, beacon, và optional offline queue. API/Lambda (ingest): xử lý validation, enrichment, idempotency hints, và DLQ. S3 raw bucket spec: prefixing/partitioning, compression, lifecycle, kèm optional compactor. ETL Lambda (batch): kết hợp với EventBridge cron, watermarking, và upsert strategy vào PostgreSQL PostgreSQL schema: fact_events, fact_sessions, các dims, cùng indexes và vacuum/maintenance plan. R Shiny dashboard app: gồm 5 modules, triển khai với Nginx/ALB TLS setup. Runbook: bao gồm alarms, on-call, backups, disaster recovery, freshness SLO, và cost guardrails. 5. Kế hoạch triển khai Dự án theo tiến độ Tháng 1 – Học tập \u0026amp; Chuẩn bị Nghiên cứu nhiều dịch vụ AWS bao gồm compute, storage, analytics và security.\nHiểu các khái niệm chính của cloud architecture, data pipelines và serverless computing.\nTổ chức các cuộc họp nhóm để thống nhất mục tiêu dự án và phân công trách nhiệm cho từng thành viên.\nTháng 2 – Thiết kế kiến trúc \u0026amp; Prototyping Thiết kế kiến trúc tổng thể của dự án và xác định luồng dữ liệu giữa các thành phần.\nThiết lập các tài nguyên AWS ban đầu như S3, Lambda, API Gateway, EventBridge và EC2.\nThử nghiệm các công cụ mã nguồn mở cho việc visualization và reporting.\nKiểm thử mã mẫu và xác thực quy trình data ingestion và processing pipeline.\nTháng 3 – Triển khai \u0026amp; Kiểm thử Triển khai toàn bộ kiến trúc dựa trên bản thiết kế đã được phê duyệt.\nTích hợp tất cả các dịch vụ AWS và đảm bảo độ tin cậy của hệ thống.\nThực hiện kiểm thử hiệu năng và chức năng.\nHoàn thiện tài liệu và chuẩn bị dự án cho buổi thuyết trình.\n6. Ước tính chi phí Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng AWS Services\nAmazon Cognito (User Pools): 0.10 USD/tháng(1 monthly active user (MAU), 1 MAU đăng nhập qua SAML hoặc OIDC federation)\nAmazon S3\nS3 Standard: 0.17 USD/tháng (6 GB, 1,000 PUT requests, 1,000 GET requests, 6 GB Data returned, 6 GB Data scanned) Data Transfer: 0.00 USD/tháng (Outbound 6 TB, Inbound 6 TB) Amazon CloudFront (United States): 0.64 USD/tháng(6 GB Data transfer out to internet, 6 GB Data transfer out to origin, 10,000 HTTPS requests)\nAmazon API Gateway (HTTP APIs): 0.01 USD/tháng(10,000 HTTP API requests units)\nAmazon Lambda (Service settings): 0.00 USD/tháng(1,000,000 requests, 512 MB memory)\nAmazon CloudWatch (APIs): 0.03 USD/tháng(100 metrics GetMetricData, 1,000 metrics GetMetricWidgetImage, 1,000 API requests)\nAmazon SNS (Service settings): 0.02 USD/tháng(1,000,000 requests, 100,000 HTTP/HTTPS Notifications, 1,000 EMAIL/EMAIL-JSON Notifications, 100,000,000 QS Notifications, 100,000,000 Lambda deliveries, 100,000 Kinesis Data Firehose notifications)\nAmazon EC2 (EC2 specifications): 1.68 USD/tháng(1 instance, 730 Compute Savings Plans)\nAmazon EventBridge: 0.00 USD/tháng(1,000,000 events (AWS management events - EventBridge Event Bus Ingestion))\nTổng cộng: 2.65 USD/tháng, 31.8 USD/12 tháng\n7. Đánh giá rủi ro Risk Likelihood Impact Mitigation Strategy Chi phí cao vượt quá ngân sách ước tính Medium High Theo dõi chặt chẽ và tính toán tất cả các chi phí tiềm năng trên AWS. Giới hạn việc sử dụng các dịch vụ AWS có chi phí cao và thay thế bằng các giải pháp đơn giản, tiết kiệm chi phí nhưng cung cấp chức năng tương tự. Các vấn đề tiềm ẩn trong việc truyền dữ liệu hoặc tích hợp dịch vụ giữa các thành phần AWS Medium Medium Thực hiện step-by-step validation trước khi triển khai chính thức. Thử nghiệm sớm, sử dụng các managed AWS services, và liên tục giám sát hiệu suất thông qua Amazon CloudWatch. Rủi ro trong thu thập hoặc xử lý dữ liệu (ví dụ: tương tác người dùng quá mức, mạng không ổn định, thiếu hoặc trùng lặp sự kiện) High Medium Áp dụng data validation, temporary buffering, và schema enforcement để đảm bảo tính nhất quán. Sử dụng structured logging và alarms để phát hiện và xử lý lỗi khi ingest dữ liệu. Người dùng ít hoặc không sử dụng analytics dashboard Low High Tổ chức các buổi internal training và tận dụng các communication channels hiện có để nâng cao nhận thức. Khuyến khích việc sử dụng bằng cách trình bày các practical benefits và actionable insights của hệ thống. 8. Kết quả kỳ vọng Hiểu Hành Vi và Hành Trình Khách Hàng Hệ thống ghi lại toàn bộ hành trình khách hàng — bao gồm các trang mà người dùng truy cập, sản phẩm mà họ xem, thời gian họ ở lại, và điểm họ rời khỏi trang web.\nBằng cách phân tích session duration, bounce rate, và navigation paths, doanh nghiệp có thể đánh giá mức độ tương tác của người dùng và trải nghiệm tổng thể.\nĐiều này cung cấp nền tảng dữ liệu đáng tin cậy để cải thiện giao diện website, tối ưu bố cục trang, và nâng cao overall customer satisfaction.\nXác Định Sản Phẩm Phổ Biến và Xu Hướng Người Tiêu Dùng Dựa trên clickstream data được thu thập và xử lý trên AWS, hệ thống xác định các sản phẩm được xem nhiều nhất và mua nhiều nhất.\nCác sản phẩm ít được chú ý cũng được theo dõi, cho phép doanh nghiệp đánh giá hiệu quả của product listings, điều chỉnh giá cả hoặc hình ảnh sản phẩm, và lập kế hoạch tồn kho hiệu quả hơn.\nHơn nữa, hệ thống hỗ trợ phát hiện shopping trends theo khoảng thời gian, khu vực, hoặc loại thiết bị — giúp đưa ra quyết định kinh doanh kịp thời và dựa trên dữ liệu.\nTối Ưu Chiến Lược Marketing và Bán Hàng Dữ liệu hành vi của khách hàng được transform (chuyển đổi) thành business insights (thông tin kinh doanh chuyên sâu) và được trình bày thông qua R Shiny dashboards.\nVới các kết quả phân tích này, doanh nghiệp có thể:\nXác định chính xác target customer segments cho các nỗ lực marketing Tùy chỉnh các chiến dịch quảng cáo và khuyến mãi cho các nhóm sản phẩm hoặc đối tượng khách hàng cụ thể Đánh giá hiệu quả của các sáng kiến marketing thông qua các chỉ số tương tác và chuyển đổi có thể đo lường Kết quả là, marketing and sales strategies trở nên dựa trên bằng chứng và chính xác hơn, hỗ trợ ra quyết định tốt hơn và cải thiện hiệu suất kinh doanh.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": " Giải pháp Nhà máy điện thông minh của TCS trên AWS giúp các tiện ích tối ưu hóa hoạt động và thúc đẩy chuyển đổi năng lượng như thế nào Bởi Alakh Srivastava, Rajesh Natesan, Siva Thangavel và Yogesh Chaturvedi – ngày 19 tháng 3 năm 2025, trong chuyên mục Amazon DocumentDB, Amazon ECS, Amazon S3, AWS IoT Core, AWS Step Functions, Năng lượng (Dầu khí), Industries.\nTổng quan về giải pháp Các công nghệ kỹ thuật số tiên tiến đang cách mạng hóa ngành năng lượng, cho phép các tổ chức đạt được các mục tiêu bền vững đồng thời giảm chi phí và khí thải carbon.\nTheo McKinsey, chuyển đổi kỹ thuật số trong lĩnh vực năng lượng có thể mở ra 1,6 nghìn tỷ USD giá trị vào năm 2035, giúp giảm 20–30% chi phí vận hành và 5% lượng khí thải carbon.\nKhi ngành công nghiệp tiến tới mô hình phát điện phân tán tích hợp năng lượng tái tạo, các doanh nghiệp cần những giải pháp thông minh như lưới điện số, AI điều phối năng lượng, và nền tảng giám sát thời gian thực.\nGiải pháp Nhà máy điện thông minh (Smart Power Plant) của TCS ra đời để đáp ứng điều đó — mang lại hiệu suất tăng 0,5%, giảm 8% NOx, và cải thiện 8–10% độ chính xác dự báo phát điện tái tạo.\nĐược xây dựng trên nền tảng AWS, giải pháp này tận dụng sức mạnh của AI/ML để xử lý dữ liệu thời gian thực từ hàng nghìn cảm biến năng lượng trên nhiều địa điểm.\nBài viết này trình bày cách TCS và AWS cùng hợp tác mang lại hiệu quả vận hành vượt trội và kết quả kinh doanh bền vững cho ngành năng lượng.\nKiến trúc giải pháp và luồng dữ liệu Kiến trúc của giải pháp được thiết kế theo luồng dữ liệu khép kín, tận dụng các dịch vụ AWS để quản lý, xử lý và phân tích thông tin một cách toàn diện.\nHình 1. Kiến trúc tổng thể của giải pháp Nhà máy điện thông minh trên AWS.\nNhập dữ liệu: Thu thập dữ liệu từ OPC-UA (thiết bị công nghiệp), hệ thống lịch sử tại chỗ và hồ dữ liệu Amazon S3.\nMỗi tổ máy có thể gửi tới 4.000 giá trị cảm biến mỗi phút. Tiếp nhận và điều phối: AWS IoT Core tiếp nhận luồng dữ liệu và kích hoạt AWS Step Functions để điều phối tự động. Xử lý dữ liệu: Các AWS Lambda functions thực hiện làm sạch, tính toán KPI và tạo cảnh báo. Lưu trữ: Amazon DocumentDB lưu dữ liệu có cấu trúc (KPI, cảnh báo), Amazon S3 lưu dữ liệu cảm biến thô và kết quả huấn luyện. Đào tạo mô hình ML: Thực hiện trong Amazon SageMaker, mô hình được lưu trong Amazon Elastic Container Registry (ECR). Suy luận thời gian thực: Mô hình được triển khai qua Amazon ECS cho TCS InTwin (engine phân tích online). Triển khai ứng dụng: Giao diện front-end/back-end chạy container trên Amazon ECS đảm bảo mở rộng linh hoạt. Các chức năng chính Giải pháp Nhà máy điện thông minh của TCS mang đến bốn khả năng cốt lõi giúp thay đổi cách các nhà máy vận hành:\nHình 2. Bốn năng lực cốt lõi của giải pháp.\nBản sao kỹ thuật số AI tự học (Self-learning Digital Twin):\nKết hợp dữ liệu thực và mô hình AI vật lý để liên tục thích nghi với điều kiện hoạt động, đảm bảo dự đoán chính xác và tiết kiệm chi phí.\nGiải pháp mở và có thể mở rộng:\nCó thể tích hợp với hệ thống nhà máy hiện có hoặc mô hình AI riêng, kiến trúc mở và có khả năng giải thích.\nBàn làm việc kỹ thuật số low-code:\nCho phép tạo và quản lý mô hình AI nhanh chóng, hỗ trợ tạo KPI, FMEA và các use case cụ thể.\nNền tảng dựng sẵn:\nCác mô-đun có thể cấu hình sẵn cho từng nhà máy, giúp rút ngắn thời gian triển khai và mở rộng quy mô dễ dàng.\nCác trường hợp sử dụng thực tế Dự báo phát điện mặt trời Sử dụng mô hình ML và phân tích nâng cao để dự đoán sản lượng năng lượng tái tạo.\nTại một trang trại gió ngoài khơi ở Anh, độ chính xác dự báo tăng 15,1%, doanh thu tăng 6%.\nTối ưu hóa quá trình đốt cháy trong sản xuất nhiệt Tại một nhà máy Nhật Bản, AI giúp cải thiện 0,5% hiệu suất, giảm 8% NOx, tiết kiệm 2,5 triệu USD/năm.\nBảo trì dự đoán linh kiện tuabin khí Tại một nhà máy Úc, mô hình dự đoán hỏng hóc trước 8–12 tháng, giảm 20% chi phí bảo trì và thời gian ngừng hoạt động.\nLợi ích kinh doanh Giải pháp của TCS giúp doanh nghiệp năng lượng:\nLợi ích Tác động Giảm chi phí vận hành Cắt giảm tới 20% chi phí bảo trì và vận hành. Dự đoán hỏng hóc chính xác Độ chính xác dự báo lỗi lên đến 85%. Tối ưu hóa KPI và giảm khí thải Cải thiện hiệu suất đồng thời giảm phát thải carbon. Hỗ trợ lực lượng lao động AI hỗ trợ ra quyết định, giảm phụ thuộc vào kinh nghiệm cá nhân. Ngoài ra, việc tích hợp AWS giúp loại bỏ các silo dữ liệu, nâng cao năng suất và tạo nền tảng chuẩn hóa cho các nhà máy điện trong tương lai.\nKết luận Giải pháp Nhà máy điện thông minh TCS trên AWS đang định hình tương lai bền vững của ngành năng lượng.\nThông qua AI và phân tích nâng cao, nền tảng này giúp tối ưu hiệu suất, bảo trì dự đoán, và tích hợp liền mạch năng lượng tái tạo.\nTCS – với chuyên môn sâu và đội ngũ chuyên gia được AWS chứng nhận – đã chứng minh khả năng triển khai thành công trên nhiều loại hình nhà máy, từ nhiệt điện truyền thống đến năng lượng tái tạo quy mô lớn.\nĐể tìm hiểu thêm, hãy xem bài đăng gốc của TCS về Giải pháp Nhà máy điện thông minh trên AWS.\nGiới thiệu về các tác giả Alakh Srivastava\nGiám đốc sản phẩm toàn cầu – Thực hành Nhà máy điện thông minh, TCS.\nHơn 20 năm kinh nghiệm trong chuyển đổi kỹ thuật số ngành điện, chuyên về năng lượng tái tạo, AI và IoT công nghiệp.\nRajesh Natesan\nTrưởng nhóm Kỹ thuật chính – Nhóm Nhà máy điện thông minh, TCS.\n20 năm kinh nghiệm trong IoT, AI/ML và kiến trúc hệ thống năng lượng quy mô lớn.\nSiva Thangavel\nKiến trúc sư giải pháp đối tác tại AWS.\nCung cấp giải pháp kiến trúc tối ưu cho đối tác và khách hàng doanh nghiệp trong nhiều ngành công nghiệp.\nYogesh Chaturvedi\nKiến trúc sư giải pháp chính tại AWS – lĩnh vực Năng lượng và Tiện ích.\nTập trung giúp khách hàng giải quyết thách thức bằng công nghệ đám mây. Ngoài công việc, anh yêu thích đi bộ đường dài, du lịch và thể thao.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 3: Tập trung vào Networking trong AWS, đặc biệt là VPC và Route 53. Thiết lập mạng an toàn và cấu hình tên miền trong AWS. Học về Security Groups, NACLs và VPN. Thực hành labs cho các dịch vụ mạng và cấu hình bảo mật. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học về AWS VPC (Virtual Private Cloud) + Tổng quan về VPC + Tạo VPC, Subnet, Route Table 22/09/2025 22/09/2025 Tài liệu học tập 3 - Học về Amazon Route 53 + Quản lý tên miền với Route 53 + Cài đặt và quản lý bản ghi DNS 23/09/2025 23/09/2025 Tài liệu học tập 4 - Học về Security Groups và NACLs (Network ACL) + Cấu hình Security Group cho EC2 + Cấu hình NACL cho subnet 24/09/2025 24/09/2025 Tài liệu học tập 5 - Học về VPN trong AWS + Khái niệm Site-to-Site VPN + Tạo và cấu hình Site-to-Site VPN, routing lưu lượng 25/09/2025 25/09/2025 Tài liệu học tập 6 - Thực hành labs tổng hợp: + VPC, Route 53, VPN, Security Groups và NACLs + Kiểm tra lại cấu hình bảo mật và kết nối mạng giữa các tài nguyên 26/09/2025 26/09/2025 Tài liệu học tập Kết quả đạt được tuần 3: Đã tạo và cấu hình được một VPC với các subnet, route table và internet gateway. Cài đặt Route 53 để quản lý tên miền và các bản ghi DNS cơ bản (A, CNAME, …). Cấu hình Security Groups và NACLs để kiểm soát lưu lượng vào/ra ở mức instance và subnet. Thiết lập Site-to-Site VPN phục vụ kết nối an toàn giữa mạng on-premises (giả lập) và VPC trên AWS. Hoàn thành các bài lab thực hành về Networking và Security trên AWS, củng cố hiểu biết về kiến trúc mạng và các lớp bảo mật trong AWS. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Cách iFood xây dựng nền tảng để chạy hàng trăm mô hình machine learning với Amazon SageMaker Inference Blog này giới thiệu cách iFood sử dụng Amazon SageMaker Inference để vận hành hàng trăm mô hình machine learning trên quy mô lớn. Bài viết trình bày cách iFood tự động hóa quy trình huấn luyện, triển khai và giám sát mô hình, đồng thời tối ưu chi phí và hiệu suất với các tính năng như zero-scale endpoints và multi-model GPU serving.\nBlog 2 - Cách Salesforce Business Technology sử dụng AWS Direct Connect SiteLink để kết nối toàn cầu đáng tin cậy Blog này mô tả cách Salesforce Business Technology triển khai AWS Direct Connect SiteLink để xây dựng kiến trúc mạng toàn cầu đáng tin cậy. Bài viết chia sẻ cách SiteLink giúp Salesforce hợp nhất mạng giữa bảy địa điểm, giảm độ trễ, tăng cường bảo mật và đơn giản hóa vận hành bằng cách tận dụng AWS global backbone.\nBlog 3 - Giải pháp Nhà máy điện thông minh của TCS trên AWS giúp các tiện ích tối ưu hóa hoạt động và thúc đẩy chuyển đổi năng lượng như thế nào Blog này giới thiệu cách Tata Consultancy Services (TCS) triển khai Smart Power Plant trên AWS, giúp các công ty năng lượng tối ưu hiệu suất, giảm khí thải và thúc đẩy chuyển đổi năng lượng bền vững. Giải pháp sử dụng AI/ML, IoT và digital twin để phân tích dữ liệu theo thời gian thực, dự đoán sự cố và tối ưu quá trình phát điện. Bài viết cũng trình bày các trường hợp sử dụng thực tế như dự báo năng lượng tái tạo, tối ưu quá trình đốt cháy và bảo trì dự đoán, mang lại hiệu quả kinh tế và giảm phát thải carbon.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/5-workshop/5.3-implementing-clickstream-ingestion/",
	"title": "Implementing Clickstream Ingestion",
	"tags": [],
	"description": "",
	"content": "Phần này mô tả chi tiết cách các sự kiện clickstream được tạo ra trong trình duyệt, gửi tới Amazon API Gateway, được xử lý bởi Lambda Ingest, và cuối cùng được lưu dưới dạng các file JSON thô trong S3 Raw Clickstream bucket.\nĐường ingest là điểm vào của toàn bộ nền tảng phân tích: nếu sự kiện không được thu thập hoặc lưu trữ đúng ở bước này, thì các bước ETL phía sau và các dashboard sẽ không còn đáng tin cậy.\nSinh sự kiện ở frontend (Frontend event generation) Frontend của site thương mại điện tử được xây bằng Next.js và host trên AWS Amplify. Một module tracking phía client chịu trách nhiệm thu thập hành vi của người dùng và gửi chúng dưới dạng các sự kiện clickstream.\nCác hành vi điển hình nên được ghi lại bao gồm:\nPage view: trang landing, trang danh mục, trang kết quả tìm kiếm, trang chi tiết sản phẩm. Tương tác với sản phẩm: click vào thẻ sản phẩm, xem chi tiết sản phẩm, thêm/bớt sản phẩm vào/khỏi giỏ hàng. Các bước checkout: bắt đầu checkout, nhập thông tin giao hàng, đặt hàng. Thông tin session và danh tính: user ID (nếu đã đăng nhập), session ID, login state, client ID. Mã tracking ở phía frontend thường thực hiện các bước sau:\nLắng nghe các sự kiện trong UI (ví dụ: page load, button click).\nTạo một payload JSON với tối thiểu các trường:\nevent_id – định danh duy nhất cho event. event_name – ví dụ: \u0026quot;page_view\u0026quot;, \u0026quot;product_view\u0026quot;, \u0026quot;add_to_cart\u0026quot;. event_timestamp – timestamp phía client (ISO 8601 hoặc epoch). user_id / identity_source – nếu người dùng đã đăng nhập (ví dụ: Cognito user sub). session_id / client_id – định danh session hoặc trình duyệt. product_id, product_name, product_category, v.v. cho các event liên quan tới sản phẩm. page_url, referrer, các trường utm_* để gắn nguồn traffic (tuỳ chọn). Gửi payload JSON qua HTTPS tới endpoint của API Gateway (xem mục 5.3.2).\nVí dụ một payload JSON tối thiểu được gửi từ trình duyệt:\n{ \u0026#34;event_name\u0026#34;: \u0026#34;product_view\u0026#34;, \u0026#34;event_timestamp\u0026#34;: \u0026#34;2025-12-04T15:23:45.123Z\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;user_123\u0026#34;, \u0026#34;login_state\u0026#34;: \u0026#34;logged_in\u0026#34;, \u0026#34;session_id\u0026#34;: \u0026#34;session_abc\u0026#34;, \u0026#34;client_id\u0026#34;: \u0026#34;browser_xyz\u0026#34;, \u0026#34;product_id\u0026#34;: \u0026#34;SKU-12345\u0026#34;, \u0026#34;product_name\u0026#34;: \u0026#34;Gaming Laptop 15 inch\u0026#34;, \u0026#34;product_category\u0026#34;: \u0026#34;Laptops\u0026#34;, \u0026#34;product_price\u0026#34;: 1299.0, \u0026#34;page_url\u0026#34;: \u0026#34;/products/sku-12345\u0026#34; } Payload có thể được mở rộng dần khi yêu cầu phân tích phát triển.\nLuồng API Gateway và Lambda Ingest API Gateway HTTP API Endpoint ingest được expose bằng Amazon API Gateway (HTTP API) với route ví dụ:\nMethod: POST Path: /clickstream Các đặc điểm chính:\nEndpoint chấp nhận payload JSON từ trình duyệt. CORS được cấu hình để cho phép domain frontend (CloudFront / Amplify) gọi đến. Route được tích hợp với Lambda function (Lambda proxy integration). Hình 5-5: API Gateway route cho POST /clickstream\nẢnh chụp màn hình cho thấy cấu hình HTTP API cho endpoint ingest clickstream.\nResource /clickstream expose một route POST duy nhất, được tích hợp với Lambda clickstream-ingest.\nTrong workshop này không cấu hình authorizer để nội dung tập trung vào ingest dữ liệu thay vì xác thực.\nLambda Ingest function Lambda Ingest chịu trách nhiệm cho các việc sau:\nParse request\nĐọc body từ event mà API Gateway gửi vào. Kiểm tra body có chứa một JSON object hoặc mảng các object hợp lệ hay không. Validate \u0026amp; enrich cơ bản\nĐảm bảo các trường bắt buộc (ví dụ: event_name, event_timestamp) tồn tại. Nếu timestamp phía client bị thiếu, gắn thêm timestamp phía server. Thêm các metadata như: API Gateway request ID. Source IP hoặc user agent (nếu cần). Batch và ghi vào S3\nTạo key trong Raw Clickstream bucket theo pattern phân vùng theo thời gian, ví dụ:\ns3://\u0026lt;raw-bucket\u0026gt;/events/YYYY/MM/DD/HH/events-\u0026lt;uuid\u0026gt;.json Ghi các event nhận được dưới dạng JSON array hoặc NDJSON (newline-delimited JSON), tuỳ định dạng đã chọn.\nLogging và xử lý lỗi\nGhi log các lỗi validate hoặc event sai format vào CloudWatch Logs. Trả về status code HTTP phù hợp cho API Gateway (ví dụ: 200 khi thành công, 400 khi payload không hợp lệ). Ví dụ S3 object key cho một batch event được ghi nhận lúc 15:00 ngày 04/12/2025:\nevents/2025/12/04/15/events-a1b2c3d4.json Hình 5-6: Tổng quan Lambda Ingest\nẢnh chụp màn hình hiển thị function clickstream-lambda-ingest trong AWS Lambda console.\nSơ đồ minh hoạ việc function được trigger bởi HTTP API Gateway và sử dụng cấu hình nhẹ (128 MB memory, timeout ngắn) – đủ để validate payload JSON, enrich metadata và ghi các batch event vào S3 Raw Clickstream bucket.\nKiểm thử thủ công từ frontend và Postman Để xác nhận pipeline ingest hoạt động như mong đợi, ta thực hiện hai kiểu kiểm thử bổ sung.\nKiểm thử end-to-end từ frontend thật Mở domain CloudFront của ứng dụng thương mại điện tử, ví dụ:\nhttps://dxxxxxxxx.cloudfront.net Đăng nhập qua Amazon Cognito bằng một tài khoản test.\nThực hiện một chuỗi hành động, chẳng hạn:\nMở trang chủ và một trang danh mục. Xem chi tiết hai hoặc ba sản phẩm. Thêm ít nhất một sản phẩm vào giỏ hàng rồi xoá ra. Bắt đầu flow checkout và đi tới bước xác nhận cuối cùng (việc đặt đơn hàng thật là tuỳ chọn). Dùng Developer Tools của trình duyệt (tab Network) để kiểm tra:\nCác request đang được gửi tới POST /clickstream. Request body chứa các trường JSON mong đợi như event_name, product_id, session_id, v.v. Status code trả về từ API Gateway là 200. Kiểm thử trực tiếp bằng Postman hoặc Thunder Client Để kiểm thử có kiểm soát, bạn cũng có thể gửi các event synthetic bằng API client:\nMethod: POST\nURL:\nhttps://\u0026lt;api-id\u0026gt;.execute-api.\u0026lt;region\u0026gt;.amazonaws.com/clickstream Header:\nContent-Type: application/json Body:\n{ \u0026#34;event_name\u0026#34;: \u0026#34;page_view\u0026#34;, \u0026#34;event_timestamp\u0026#34;: \u0026#34;2025-12-04T16:00:00.000Z\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;test_user_manual\u0026#34;, \u0026#34;login_state\u0026#34;: \u0026#34;anonymous\u0026#34;, \u0026#34;session_id\u0026#34;: \u0026#34;session_manual_001\u0026#34;, \u0026#34;client_id\u0026#34;: \u0026#34;postman_client\u0026#34;, \u0026#34;page_url\u0026#34;: \u0026#34;/manual-test\u0026#34; } Cách làm này hữu ích để kiểm thử xử lý lỗi, các rule validate, hoặc các edge case mà không phụ thuộc vào code frontend.\nKiểm tra dữ liệu trong S3 Raw Clickstream bucket Sau khi đã gửi event, bước tiếp theo là xác minh chúng đã được lưu thành công vào S3.\nMở Amazon S3 Console và chọn Raw Clickstream bucket, ví dụ:\nclickstream-raw-\u0026lt;account\u0026gt;-\u0026lt;region\u0026gt; Điều hướng theo cấu trúc prefix:\nevents/YYYY/MM/DD/HH/ Ví dụ:\nevents/2025/12/04/15/ Xác nhận rằng đã có một hoặc nhiều object với tên tương tự:\nevents-a1b2c3d4.json events-f9e8d7c6.json được tạo ra.\nTải một trong các file này về và mở bằng text editor (VS Code, Notepad++, v.v.):\nKiểm tra JSON có hợp lệ hay không. Kiểm tra các trường như event_name, event_timestamp, user_id, session_id, product_id, v.v. có khớp với các thao tác bạn đã thực hiện trên website hay không. Đảm bảo nhiều event được nhóm lại hợp lý (ví dụ: một mảng các JSON object). Ghi chú lại:\nKích thước file xấp xỉ (KB/MB). Số lượng event trong mỗi file. Tần suất xuất hiện file mới (tuỳ thuộc vào cách Lambda Ingest batch và ghi). Những quan sát này sẽ hữu ích khi tinh chỉnh kích thước batch ETL và lịch chạy ở các phần sau.\nHình 5-7: Các object JSON clickstream thô trong S3 bucket\nẢnh chụp màn hình hiển thị Raw Clickstream bucket tại prefix sâu nhất theo giờ.\nNhiều object JSON được tạo bởi Lambda Ingest, mỗi object đại diện cho một batch các sự kiện clickstream trong giờ đó.\nTên file sử dụng pattern dựa trên UUID (ví dụ: event-a8bdf0c0-...json), và cột Size cho biết nhanh số lượng event tương đối trong mỗi file.\nTổng kết và mối liên hệ với các thành phần downstream Kết thúc phần này, bạn nên đã có:\nMột đường ingest hoạt động từ browser → API Gateway → Lambda Ingest → S3 Raw bucket. Xác minh rằng event có cấu trúc đúng và chứa đủ metadata cần thiết. Xác nhận Raw Clickstream bucket đang sử dụng layout phân vùng theo thời gian, phù hợp cho xử lý theo lô. Trong phần tiếp theo (5.4), trọng tâm sẽ chuyển sang lớp phân tích riêng tư (private analytics layer), nơi một ETL Lambda chạy trong VPC đọc các file JSON thô này qua S3 Gateway VPC Endpoint, transform chúng và nạp vào PostgreSQL Data Warehouse.\nHình 5-8: Luồng ingest từ trình duyệt tới S3 Raw bucket\nSơ đồ minh hoạ chuỗi:\nTrình duyệt (user actions) → CloudFront → Amplify (ứng dụng Next.js). Tracking ở frontend gửi các request HTTP tới Amazon API Gateway (HTTP API) trên route POST /clickstream. API Gateway gọi Lambda Ingest, function này validate và enrich event. Lambda Ingest ghi các object JSON dạng batch vào S3 Raw Clickstream bucket theo key phân vùng thời gian, chẳng hạn events/YYYY/MM/DD/HH/events-\u0026lt;uuid\u0026gt;.json. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 4: Hiểu về các dịch vụ cơ sở dữ liệu trên AWS (RDS, DynamoDB). Học cách triển khai và quản lý các instance cơ sở dữ liệu. Tìm hiểu về sao lưu, khôi phục, mở rộng quy mô và tối ưu hóa hiệu suất cơ sở dữ liệu. Thực hành labs với RDS và DynamoDB. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học về AWS RDS + Tạo một RDS instance + Sao lưu và bảo trì RDS 29/09/2025 29/09/2025 Tài liệu học tập 3 - Học về Amazon DynamoDB + Giới thiệu về DynamoDB + Làm việc với bảng và dữ liệu 30/09/2025 30/09/2025 Tài liệu học tập 4 - Tìm hiểu cơ chế sao lưu (backup) và khôi phục dữ liệu (restore) trong RDS 01/10/2025 01/10/2025 Tài liệu học tập 5 - Tìm hiểu về tối ưu hóa hiệu suất cơ sở dữ liệu trong AWS (RDS \u0026amp; DynamoDB) 02/10/2025 02/10/2025 Tài liệu học tập 6 - Thực hành labs cho RDS và DynamoDB + Tạo / sửa / xóa database, bảng, dữ liệu + Test backup \u0026amp; restore 03/10/2025 03/10/2025 Tài liệu học tập Kết quả đạt được tuần 4: Đã triển khai và cấu hình được các RDS instance (tạo, chỉnh sửa, dừng/xoá). Làm quen với DynamoDB và thực hành thao tác với bảng, item, và truy vấn dữ liệu. Hiểu cơ chế sao lưu tự động và thủ công trong RDS, cũng như quy trình khôi phục dữ liệu. Nắm được một số nguyên tắc cơ bản để tối ưu hiệu suất cơ sở dữ liệu trên AWS (chọn instance type, storage, IOPS, index…). Hoàn thành các lab thực hành với RDS và DynamoDB, củng cố kiến thức về database trên AWS. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": "Sự kiện 1 Tên sự kiện: Vietnam Cloud Day 2025\nThời gian tổ chức: 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Bến Nghé, Quận 1, Thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nMô tả ngắn gọn nội dung và hoạt động chính trong sự kiện:\nVietnam Cloud Day là sự kiện thường niên do AWS tổ chức, quy tụ chuyên gia, doanh nghiệp và cộng đồng công nghệ để chia sẻ về các xu hướng mới trong điện toán đám mây, AI, dữ liệu lớn và bảo mật.\nChương trình bao gồm các phiên thảo luận chiến lược, các track chuyên sâu theo ngành (FSI, viễn thông, bán lẻ, bất động sản…), các phiên chia sẻ về kiến trúc hiện đại (microservices, event-driven, serverless) và trình bày case study thực tế từ Techcombank, Honda, Masterise, TymeX,… tạo cái nhìn toàn diện về hành trình hiện đại hóa trên nền tảng AWS.\nKết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án):\n- Hiểu rõ hơn vai trò của Cloud \u0026amp; GenAI trong chiến lược chuyển đổi số quốc gia và trong các ngành trọng điểm.\n- Nắm bắt các mô hình kiến trúc hiện đại như DDD, microservices, event-driven, serverless và cách lựa chọn dịch vụ compute phù hợp (EC2, ECS, Fargate, Lambda).\n- Nhận thức sâu hơn về tầm quan trọng của chiến lược dữ liệu, bảo mật “security by design” và tư duy “migrate to operate” thay vì chỉ “lift-and-shift”.\n- Hình thành nhiều ý tưởng áp dụng vào dự án học tập/cá nhân (ví dụ: thiết kế hệ thống trên AWS, tích hợp Amazon Q Developer vào quy trình DevOps) và mở rộng network với cộng đồng kỹ sư Cloud.\nSự kiện 2 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian tổ chức: 07/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, Thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nMô tả ngắn gọn nội dung và hoạt động chính trong sự kiện:\nWorkshop tập trung vào chủ đề Agentic AI và hệ sinh thái Amazon QuickSuite, làm rõ sự khác biệt giữa Generative AI truyền thống và Agentic AI có khả năng hành động tự chủ.\nNgười tham dự được giới thiệu lần đầu về QuickSuite tại Việt Nam, bao gồm sự kết hợp giữa Amazon QuickSight và QuickSuite Q để xây dựng các “Analyst Agents” có thể đọc dữ liệu, trả lời câu hỏi nghiệp vụ và đề xuất hành động phù hợp.\nChương trình cũng giới thiệu gói hỗ trợ tài chính AWS LIFT (tín dụng lên tới 80.000 USD) nhằm giảm rào cản chi phí khi thử nghiệm các giải pháp AI/Agentic AI.\nPhần hands-on kéo dài khoảng 90 phút giúp người tham dự trực tiếp thao tác với QuickSight + QuickSuite Q dưới sự hướng dẫn của chuyên gia AWS và đối tác Cloud Kinetics, đồng thời có cơ hội trao đổi, networking với cộng đồng làm về cloud, data và AI.\nKết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án):\n- Hiểu rõ hơn khái niệm Agentic AI, sự chuyển dịch từ “AI chỉ trả lời” sang “AI thực sự làm việc thay con người” và các kịch bản ứng dụng trong doanh nghiệp.\n- Nắm được các thành phần chính của Amazon QuickSuite, cách kết hợp QuickSight và QuickSuite Q để xây dựng các tác tử phân tích dữ liệu (analyst agents).\n- Nhận thức được vai trò của chương trình AWS LIFT trong việc hỗ trợ tài chính cho các PoC/R\u0026amp;D về AI, từ đó có thể đề xuất áp dụng cho các dự án trong tương lai.\n- Cải thiện kỹ năng thiết kế use case cho Agentic AI (lựa chọn các quy trình lặp lại, nhiều bước, dựa trên dữ liệu) và hình thành thêm ý tưởng áp dụng vào học tập/dự án như tự động báo cáo, giám sát chỉ số hoặc gợi ý tối ưu vận hành.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/5-workshop/5.4-building-the-private-analytics-layer/",
	"title": "Building the Private Analytics Layer",
	"tags": [],
	"description": "",
	"content": "Phần này giải thích chi tiết cách triển khai lớp phân tích riêng tư (private analytics layer) để toàn bộ ETL theo lô có thể chạy hoàn toàn bên trong các private subnet, mà không cần phơi bày các thành phần nội bộ ra Internet công cộng.\nLớp phân tích riêng tư bao gồm:\nMột Lambda ETL có VPC (VPC-enabled ETL Lambda) chạy trong private subnet. Một S3 Gateway VPC Endpoint cho phép Lambda ETL truy cập S3 qua mạng riêng AWS. Một PostgreSQL Data Warehouse chạy trên EC2 instance trong một private subnet riêng. Những thành phần này kết hợp lại tạo thành xương sống của pipeline xử lý theo lô:\nS3 Raw Clickstream bucket → ETL Lambda (trong VPC) → PostgreSQL Data Warehouse (EC2, private subnet)\nThiết kế mạng cho lớp phân tích (Networking design for the analytics layer) VPC được chia logic thành các subnet với vai trò khác nhau:\nPublic Subnet – OLTP (10.0.1.0/24)\nChứa EC2 PostgreSQL OLTP. Có route 0.0.0.0/0 → Internet Gateway (IGW) để truy cập Internet hai chiều. Private Subnet – Analytics (10.0.2.0/24)\nChứa EC2 Data Warehouse và R Shiny Server. Không có route tới Internet Gateway và không có NAT Gateway. Chỉ có các route nội bộ trong VPC và kết nối tới các private subnet khác. Private Subnet – ETL (10.0.3.0/24)\nChứa Lambda ETL trong VPC và S3 Gateway VPC Endpoint. Cũng không có route 0.0.0.0/0 và không có NAT Gateway. Có thể truy cập S3 một cách riêng tư qua Gateway Endpoint. Thiết kế này đảm bảo rằng:\nData Warehouse và R Shiny không thể truy cập trực tiếp từ Internet công cộng. Lambda ETL chỉ có thể truy cập S3 và Data Warehouse thông qua mạng riêng của AWS. Không cần NAT Gateway, giúp giảm chi phí và đơn giản hoá cấu trúc mạng. Tạo và cấu hình S3 Gateway VPC Endpoint S3 Gateway VPC Endpoint cho phép tài nguyên trong private subnet truy cập S3 mà không cần dùng public IP.\nHình 5-9: S3 Gateway VPC Endpoint gắn với các private route table\nẢnh chụp màn hình hiển thị Gateway VPC Endpoint cho dịch vụ Amazon S3 (com.amazonaws.ap-southeast-1.s3) trong VPC của workshop.\nEndpoint có trạng thái Available và được gắn với hai private route table, vốn tương ứng với các subnet Analytics và ETL.\nCấu hình này đảm bảo traffic từ Lambda ETL và EC2 Data Warehouse tới S3 luôn đi trong mạng nội bộ AWS, không cần NAT Gateway.\nBước 1 – Tạo Gateway Endpoint Mở VPC Console trong AWS Management Console.\nĐiều hướng tới Endpoints → bấm Create endpoint.\nỞ mục Service category, chọn AWS services.\nTrong ô tìm kiếm, nhập s3 và chọn mục:\ncom.amazonaws.\u0026lt;region\u0026gt;.s3 Ở Endpoint type, chọn Gateway.\nỞ VPC, chọn VPC của project, nơi chứa các subnet analytics và ETL.\nTrong Route tables, chọn route table gắn với ETL private subnet (10.0.3.0/24) và, nếu muốn, thêm route table của Analytics private subnet (10.0.2.0/24) nếu bạn cũng muốn EC2 Data Warehouse truy cập S3 riêng tư.\nỞ phần Policy, trong workshop có thể bắt đầu với Full access:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Sau này có thể siết lại để chỉ cho phép một bucket hoặc prefix cụ thể.\nBấm Create endpoint.\nBước 2 – Kiểm tra các route table Sau khi endpoint được tạo, AWS sẽ tự động thêm route vào các route table đã chọn.\nTrong VPC Console, mở Route tables.\nChọn route table dùng cho ETL private subnet.\nỞ tab Routes, kiểm tra:\nCó route local:\n10.0.0.0/16 → local Có route dùng prefix-list tới S3, trỏ tới endpoint mới:\npl-xxxxxxxx → vpce-xxxxxxxx (Gateway Endpoint to S3) Không có route:\n0.0.0.0/0 → igw-xxxxxxx Không có NAT Gateway.\nNhư vậy, các private subnet không gửi traffic trực tiếp ra Internet, nhưng vẫn truy cập được S3 qua Gateway Endpoint.\nCấu hình Lambda ETL bên trong VPC Lambda ETL phải được đặt trong VPC để có thể:\nTruy cập S3 thông qua Gateway Endpoint. Kết nối tới PostgreSQL Data Warehouse trong Analytics private subnet. Bước 1 – Gắn Lambda vào VPC Mở Lambda Console và chọn function ETL, ví dụ:\nclickstream-etl-lambda Vào tab Configuration → mục Network (hoặc Environment → VPC tuỳ UI).\nBấm Edit và thiết lập:\nVPC: VPC của project. Subnets: chọn ETL private subnet (10.0.3.0/24) (có thể chọn nhiều subnet ở các AZ khác nhau để tăng khả dụng). Security groups: chọn security group: Cho phép outbound tới S3 (qua Gateway Endpoint). Cho phép outbound tới EC2 Data Warehouse (port 5432). Lưu cấu hình. Ở lần chạy tiếp theo, Lambda sẽ tạo các ENI (elastic network interface) trong subnet đã chọn.\nBước 2 – Quyền IAM cho Lambda ETL Execution role của Lambda ETL cần có:\nQuyền đọc từ Raw Clickstream S3 bucket, ví dụ:\n{ \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::clickstream-raw-\u0026lt;account\u0026gt;-\u0026lt;region\u0026gt;\u0026#34;, \u0026#34;arn:aws:s3:::clickstream-raw-\u0026lt;account\u0026gt;-\u0026lt;region\u0026gt;/events/*\u0026#34; ] } Quyền ghi log vào CloudWatch Logs (thường được thêm sẵn).\nKhông cần các quyền quản trị hạ tầng khác (giữ role ở mức tối thiểu cần thiết).\nBước 3 – Cấu hình kết nối cơ sở dữ liệu Trong phần environment variables của Lambda ETL, lưu các biến:\nDW_HOST – private IP hoặc hostname của EC2 Data Warehouse. DW_PORT – thường là 5432. DW_USER / DW_PASSWORD – tài khoản có quyền insert vào các bảng DW. DW_DATABASE – tên database analytics. Mã Lambda sẽ sử dụng các biến này để tạo kết nối (ví dụ thông qua thư viện client PostgreSQL).\nCài đặt logic ETL Mỗi lần chạy (được lên lịch qua EventBridge hoặc invoke thủ công), Lambda ETL thực hiện các bước ở mức cao như sau:\nXác định khoảng thời gian / prefix S3 cần xử lý\nVí dụ: toàn bộ object dưới events/YYYY/MM/DD/HH/ cho giờ gần nhất. Liệt kê các object S3 tương ứng\nDùng ListObjectsV2 trên Raw Clickstream bucket với prefix đã chọn. Đọc và parse các event\nVới mỗi object, gọi GetObject và parse nội dung JSON. Validate các trường quan trọng (event name, timestamp, user/session ID, product ID). Transform sang schema phân tích\nMap JSON thô sang các bảng quan hệ, ví dụ:\ndim_users – thuộc tính ở cấp người dùng. dim_products – thuộc tính ở cấp sản phẩm. fact_events – từng event riêng lẻ, có khoá ngoại tới users và products. fact_sessions – thông tin tổng hợp theo session. Áp dụng các rule nghiệp vụ đơn giản, như:\nSuy ra ngày và giờ từ timestamp. Chuẩn hoá tên event. Loại bỏ event test hoặc sai format. Ghi vào Data Warehouse\nMở một transaction tới PostgreSQL Data Warehouse. Dùng các lệnh INSERT dạng batch hoặc cơ chế bulk-load (tuỳ triển khai). Commit nếu thành công; rollback nếu có lỗi. Đánh dấu tiến độ (tuỳ chọn)\nLưu trạng thái đã xử lý (ví dụ: giờ cuối cùng đã ETL) trong một bảng control hoặc một prefix metadata trên S3 để tránh xử lý trùng. Ví dụ một bảng fact đơn giản cho events:\nCREATE TABLE IF NOT EXISTS fact_events ( event_id UUID PRIMARY KEY, event_timestamp TIMESTAMPTZ NOT NULL, event_name TEXT NOT NULL, user_id TEXT, session_id TEXT, client_id TEXT, product_id TEXT, page_url TEXT, traffic_source TEXT, created_at TIMESTAMPTZ DEFAULT NOW() ); Lambda ETL sẽ insert dữ liệu vào fact_events dựa trên các file JSON đã đọc từ S3.\nHình 5-10: Cấu hình VPC cho Lambda ETL\nẢnh chụp màn hình hiển thị function SBW_Lamda_ETL được gắn với SBW_Project-vpc.\nLambda sử dụng hai private subnet (mỗi subnet ở một Availability Zone) và một security group riêng (sg_Lamda_ETL) để kiểm soát toàn bộ truy cập mạng.\nCấu hình này cho phép function truy cập S3 Gateway VPC Endpoint và EC2 Data Warehouse mà không cần phơi bày Lambda ra Internet công cộng.\nSecurity group và kết nối (Security groups and connectivity) Để đảm bảo chỉ cho phép các luồng traffic cần thiết:\nSecurity Group cho EC2 Data Warehouse (SG-DW)\nInbound: Cho phép 5432/tcp từ security group của Lambda ETL (không từ 0.0.0.0/0). Outbound: Cho phép tất cả outbound (hoặc siết chặt hơn nếu cần cho mục đích update/monitoring). Security Group cho Lambda ETL (SG-ETL)\nInbound: Không cần (Lambda không nhận kết nối inbound). Outbound: Cho phép traffic tới: Private IP của EC2 Data Warehouse ở port 5432. S3 Gateway VPC Endpoint (thường chỉ cần cho phép all outbound trong VPC). Thiết lập này đảm bảo rằng:\nChỉ Lambda ETL mới nói chuyện được với Data Warehouse (không có truy cập trực tiếp từ Internet). EC2 Data Warehouse không mở cổng tuỳ ý cho các kết nối inbound khác. Kiểm thử pipeline ETL end-to-end Để xác nhận lớp phân tích riêng tư hoạt động đúng:\nSinh các event mới\nThực hiện lại các bước ở Mục 5.3 để tạo clickstream mới (page view, product view, add-to-cart, checkout). Trigger Lambda ETL\nCách A: Chờ EventBridge rule chạy theo lịch (ví dụ mỗi 30 phút). Cách B: Trong EventBridge console, chọn rule ETL (ví dụ clickstream-etl-schedule) và bấm Run now. Cách C: Trong Lambda console, dùng nút Test với một test event tối giản để invoke Lambda ETL thủ công. Kiểm tra CloudWatch Logs\nMở log group của Lambda ETL trong CloudWatch Logs. Xác minh rằng: Lambda đã liệt kê và đọc các object S3 thành công. Số lượng event đã xử lý khớp với kỳ vọng. Kết nối tới Data Warehouse và các lệnh insert được thực thi không lỗi. Kiểm tra dữ liệu trong Data Warehouse\nKết nối vào EC2 Data Warehouse bằng Session Manager hoặc SSH.\nTừ đó, sử dụng psql hoặc client SQL bất kỳ để chạy các truy vấn ví dụ:\nSELECT event_name, COUNT(*) AS total_events FROM fact_events GROUP BY event_name ORDER BY total_events DESC; SELECT product_id, COUNT(*) AS view_count FROM fact_events WHERE event_name = \u0026#39;product_view\u0026#39; GROUP BY product_id ORDER BY view_count DESC LIMIT 10; Xác nhận rằng số lượng và top sản phẩm khớp tương đối với hành vi mà bạn đã thực hiện trên website.\nTóm tắt Sau phần này, bạn đã:\nCấu hình S3 Gateway VPC Endpoint để các private subnet có thể truy cập S3 mà không cần NAT Gateway. Gắn Lambda ETL vào VPC và đảm bảo nó truy cập được cả S3 và Data Warehouse qua kết nối riêng tư. Cài đặt logic ETL để đọc file JSON clickstream thô, transform và nạp chúng vào PostgreSQL Data Warehouse trong private subnet. Kiểm chứng đầy đủ đường đi dữ liệu bằng cách xem log và chạy truy vấn SQL. Trong phần tiếp theo (5.5), bạn sẽ sử dụng các dashboard R Shiny chạy trên EC2 Data Warehouse để trực quan hoá dữ liệu đã xử lý và xây dựng các view phân tích tương tác.\nHình 5-11: Lớp phân tích riêng tư với Lambda ETL, Data Warehouse và S3 Gateway Endpoint\nSơ đồ cho thấy pipeline ETL theo lô chạy hoàn toàn bên trong Analytics private subnet:\nEventBridge (góc dưới bên phải) trigger Lambda ETL theo lịch. Lambda ETL đọc các file clickstream thô từ S3 Raw Clickstream bucket thông qua S3 Gateway VPC Endpoint (không cần Internet/NAT). Lambda ETL ghi dữ liệu đã transform vào EC2 PostgreSQL Data Warehouse, và R Shiny Server chạy trên cùng instance đọc dữ liệu này để hiển thị các dashboard phân tích. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 5: Học về AWS CloudWatch để giám sát và quản lý các dịch vụ AWS. Tìm hiểu về AWS CloudTrail và AWS Config để theo dõi và quản lý thay đổi trong môi trường AWS. Thực hành cấu hình và giám sát tài nguyên trên AWS. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học về AWS CloudWatch + Cấu hình và giám sát tài nguyên AWS với CloudWatch + Tạo cảnh báo (Alarms) và biểu đồ (Dashboards) 06/10/2025 06/10/2025 Tài liệu học tập 3 - Học về AWS CloudTrail + Giám sát hành động và sự kiện của người dùng trên AWS + Phân tích log sự kiện CloudTrail 07/10/2025 07/10/2025 Tài liệu học tập 4 - Học về AWS Config + Theo dõi thay đổi cấu hình và lịch sử tài nguyên AWS 08/10/2025 08/10/2025 Tài liệu học tập 5 - Thực hành cấu hình và giám sát với CloudWatch + Tạo CloudWatch Alarm + Giám sát EC2 và các tài nguyên khác qua metric \u0026amp; log 09/10/2025 09/10/2025 Tài liệu học tập 6 - Thực hành với CloudTrail và AWS Config + Phân tích sự kiện CloudTrail + Quản lý thay đổi cấu hình với AWS Config 10/10/2025 10/10/2025 Tài liệu học tập Kết quả đạt được tuần 5: Đã cấu hình và giám sát các tài nguyên AWS sử dụng AWS CloudWatch (EC2, RDS, …). Tạo được các cảnh báo (alarms) và biểu đồ (dashboards) để theo dõi hiệu suất và trạng thái hệ thống. Hiểu cách sử dụng AWS CloudTrail để theo dõi các sự kiện và hành động của người dùng trong tài khoản AWS. Sử dụng AWS Config để theo dõi và quản lý các thay đổi cấu hình tài nguyên AWS theo thời gian. Củng cố kiến thức về giám sát, logging và audit trong môi trường AWS, phục vụ cho việc vận hành hệ thống an toàn và ổn định. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/5-workshop/5.5-visualizing-analytics-with-shiny-dashboards/",
	"title": "Visualizing Analytics with Shiny Dashboards",
	"tags": [],
	"description": "",
	"content": "Trong các phần trước, bạn đã ingest các sự kiện clickstream vào S3 Raw Clickstream bucket và sử dụng một Lambda ETL có gắn VPC (VPC-enabled ETL Lambda) để nạp dữ liệu đã được xử lý vào PostgreSQL Data Warehouse trong private subnet.\nPhần này tập trung vào “chặng cuối” của pipeline:\nXác nhận rằng job ETL đã nạp đủ và đúng dữ liệu vào Data Warehouse. Sử dụng R Shiny dashboards chạy trên cùng EC2 với Data Warehouse để khám phá hành vi người dùng, các phễu (funnel) và hiệu suất sản phẩm. Mục tiêu không chỉ là “xem vài biểu đồ”, mà là kết nối từng trực quan hoá với mô hình dữ liệu bên dưới và các câu hỏi nghiệp vụ.\nTrigger batch ETL và kiểm tra dữ liệu trong Data Warehouse Trước khi mở dashboard, hãy đảm bảo Data Warehouse đã được cập nhật dữ liệu mới.\nBước 1 – Sinh các sự kiện clickstream mới Mở domain CloudFront của ứng dụng thương mại điện tử, ví dụ:\nhttps://dxxxxxxxx.cloudfront.net Đăng nhập bằng một user test qua Amazon Cognito.\nThực hiện một phiên duyệt web “giống thật”, chẳng hạn:\nVào trang chủ và ít nhất một trang danh mục. Tìm kiếm sản phẩm hoặc lọc theo brand/category. Mở chi tiết từ ba sản phẩm trở lên. Thêm một–hai sản phẩm vào giỏ hàng. Xoá một sản phẩm, thay đổi số lượng, và đi tiếp vào flow checkout. Tuỳ chọn: hoàn thành đặt hàng để tạo các sự kiện purchase. Chờ khoảng 1–2 phút để đảm bảo tất cả event đã được gửi tới API Gateway → Lambda Ingest → S3 Raw Clickstream bucket.\nBước 2 – Chạy ETL job Có ba cách chính để chạy Lambda ETL:\nA. Chờ EventBridge chạy theo lịch\nNếu rule ETL đã được cấu hình chạy mỗi 15 hoặc 30 phút, bạn có thể đơn giản là chờ lần trigger tiếp theo. B. Trigger thủ công qua EventBridge\nMở console Amazon EventBridge.\nVào Rules và chọn rule ETL, ví dụ:\nclickstream-etl-schedule Chọn Actions → Run now để chạy rule ngay lập tức.\nC. Trigger thủ công qua Lambda console\nMở Lambda Console và chọn function ETL, ví dụ:\nclickstream-etl-lambda Ở tab Test, tạo hoặc dùng lại một test event (payload {} là đủ nếu code bỏ qua input).\nBấm Test để invoke Lambda ETL.\nBước 3 – Kiểm tra ETL trong CloudWatch Logs Mở CloudWatch Logs trong AWS console.\nĐiều hướng tới log group của Lambda ETL.\nMở log stream mới nhất và tìm các dòng như:\n“Listing S3 objects under prefix events/YYYY/MM/DD/HH/ …” “Read N files, parsed M events.” “Inserted K rows into fact_events, L rows into dim_products, …” Bất kỳ error hoặc stack trace nào (nếu có). Nếu gặp lỗi, hãy kiểm tra:\nQuyền IAM cho S3 và database. Cấu hình VPC (subnet, route table, Gateway Endpoint). Kết nối tới database (host, port, thông tin đăng nhập). Hình 5-12: CloudWatch logs cho lần chạy ETL gần nhất\nẢnh chụp màn hình hiển thị log stream trong CloudWatch cho một lần chạy gần đây của Lambda ETL.\nCác entry INIT_START, START, END và REPORT xác nhận function chạy thành công, thời lượng và memory usage nằm trong phạm vi mong đợi.\nViệc kiểm tra log giúp đảm bảo Data Warehouse đã có dữ liệu mới trước khi mở Shiny dashboard.\nBước 4 – Kiểm tra dữ liệu bằng truy vấn SQL Sau khi ETL chạy thành công, hãy xác minh Data Warehouse đã được cập nhật.\nKết nối vào EC2 Data Warehouse bằng Session Manager hoặc SSH (qua bastion host hoặc VPN). Từ trong instance, dùng psql hoặc một client SQL bất kỳ để kết nối tới PostgreSQL DW. Chạy một số truy vấn cơ bản:\n-- 1. Tổng số event trong bảng fact SELECT COUNT(*) AS total_events FROM fact_events; -- 2. Số event theo loại (page view, product view, add-to-cart, ...) SELECT event_name, COUNT(*) AS total_events FROM fact_events GROUP BY event_name ORDER BY total_events DESC; -- 3. Top 10 sản phẩm được xem nhiều nhất SELECT product_id, product_name, COUNT(*) AS view_count FROM fact_events WHERE event_name = \u0026#39;product_view\u0026#39; GROUP BY product_id, product_name ORDER BY view_count DESC LIMIT 10; Kiểm tra sâu hơn (tuỳ chọn):\n-- 4. Dạng funnel đơn giản: từ product view đến add-to-cart SELECT product_id, SUM(CASE WHEN event_name = \u0026#39;product_view\u0026#39; THEN 1 ELSE 0 END) AS product_views, SUM(CASE WHEN event_name = \u0026#39;add_to_cart\u0026#39; THEN 1 ELSE 0 END) AS add_to_cart_events FROM fact_events GROUP BY product_id ORDER BY product_views DESC LIMIT 10; So sánh kết quả với phiên test:\nBạn đã xem ít nhất chừng đó sản phẩm chưa? Các sản phẩm bạn tương tác có nằm trong top danh sách không? Nếu bạn hoàn tất một đơn hàng, bạn có nhìn thấy các event liên quan trong dữ liệu không? Truy cập Shiny dashboards (từ EC2 private) R Shiny Server chạy trên instance EC2 private chung với Data Warehouse và không có public IP. Để truy cập an toàn, bạn thường sử dụng port forwarding.\nTuỳ chọn A – Port forwarding qua SSH Đảm bảo bạn có quyền SSH tới EC2 (trực tiếp hoặc qua bastion host).\nTrên máy local, chạy lệnh SSH để forward một port local (ví dụ 3838) tới Shiny Server trên EC2:\nssh -i /path/to/your-key.pem -L 3838:localhost:3838 ec2-user@\u0026lt;bastion-or-dw-ec2-host\u0026gt; Giữ session SSH này mở.\nMở trình duyệt trên máy local và truy cập:\nhttp://localhost:3838/ hoặc app cụ thể, ví dụ:\nhttp://localhost:3838/clickstream-analytics Tuỳ chọn B – AWS Systems Manager Session Manager (port forwarding) Nếu không muốn mở SSH từ Internet, bạn có thể dùng Session Manager với port forwarding:\nCài và cấu hình Session Manager plugin cho AWS CLI.\nDùng lệnh tương tự:\naws ssm start-session --target \u0026lt;instance-id\u0026gt; --document-name AWS-StartPortForwardingSession --parameters \u0026#39;{\u0026#34;portNumber\u0026#34;:[\u0026#34;3838\u0026#34;],\u0026#34;localPortNumber\u0026#34;:[\u0026#34;3838\u0026#34;]}\u0026#39; Tương tự SSH, mở trình duyệt và truy cập:\nhttp://localhost:3838/ Tham khảo thêm tài liệu AWS nếu cần các bước chi tiết.\nKhám phá các dashboard Sau khi truy cập được trang chủ Shiny hoặc app cụ thể, bạn sẽ thấy một hoặc nhiều dashboard được xây trên Data Warehouse.\nMột số view thường gặp:\nDashboard Phễu / Hành trình người dùng (Funnel / User Journey) Hiển thị cách người dùng đi qua các bước chính, ví dụ:\npage_view → 2. product_view → 3. add_to_cart → 4. checkout_start → 5. purchase Các trực quan hoá phổ biến:\nBiểu đồ funnel với số lượng ở từng bước. Tỷ lệ rơi rụng (drop-off) giữa các bước liên tiếp. Bộ lọc theo khoảng thời gian, loại thiết bị, nguồn traffic. Câu hỏi bạn có thể trả lời:\nCó bao nhiêu người dùng bắt đầu từ product view và đi tới bước checkout? Người dùng rơi rụng chủ yếu ở đâu (trước add-to-cart, hay trong quá trình checkout)? Phễu có thay đổi theo thời gian hoặc theo từng nguồn traffic không? Dashboard Hiệu suất sản phẩm (Product Performance) Tập trung vào các chỉ số ở cấp sản phẩm:\nSản phẩm được xem nhiều nhất (product_view). Sản phẩm có nhiều event add-to-cart hoặc purchase. Tỷ lệ chuyển đổi theo sản phẩm (add-to-cart / views, purchase / views). Trực quan hoá thường gặp:\nBiểu đồ cột xếp hạng sản phẩm theo view hoặc purchase. Bảng hiển thị tên sản phẩm, category và các chỉ số tương tác chính. Bộ lọc theo category, brand, khoảng giá… Câu hỏi bạn có thể trả lời:\nSản phẩm nào thu hút nhiều lượt xem nhưng chuyển đổi thấp? Category hoặc brand nào hoạt động tốt nhất? Có sản phẩm nào gần như không được xem và có thể cần được quảng bá thêm? Dashboard Chuỗi thời gian / Mức độ hoạt động (Time Series / Activity Over Time) Theo dõi cách hoạt động của người dùng thay đổi theo thời gian:\nSố event mỗi giờ hoặc mỗi ngày. Các đường riêng cho page view, product view, add-to-cart, purchase. Tuỳ chọn breakdown theo loại thiết bị hoặc nguồn traffic. Câu hỏi bạn có thể trả lời:\nThời điểm nào trong ngày có hoạt động duyệt web cao nhất? Có ngày nào trong tuần có tỷ lệ chuyển đổi tốt hơn không? Các chiến dịch hoặc chương trình khuyến mãi (nếu được ghi nhận) có trùng với các đỉnh (spike) hoạt động không? Liên hệ giữa dashboard và schema Data Warehouse Mỗi dashboard được vận hành bởi các truy vấn SQL chạy trên các bảng trong Data Warehouse, ví dụ:\nfact_events – dữ liệu event chi tiết. dim_products – thuộc tính sản phẩm (tên, category, brand, v.v.). dim_users – thuộc tính người dùng (đã đăng ký vs khách, segment, v.v.). fact_sessions hoặc fact_funnels – các bảng fact đã tổng hợp theo session/funnel (nếu có). Khi bạn tương tác với các filter trong Shiny (chọn khoảng thời gian, category, loại event…), app Shiny thường:\nXây dựng truy vấn SQL dựa trên tham số bạn chọn. Gửi truy vấn tới PostgreSQL. Nhận về kết quả đã tổng hợp. Render thành biểu đồ hoặc bảng trong trình duyệt. Bài tập gợi ý:\nMở mã nguồn app Shiny (các script R) trên EC2. Tìm các truy vấn SQL được dùng cho từng widget. So sánh những truy vấn đó với các truy vấn SQL thủ công mà bạn đã chạy ở trên. Điều này giúp bạn tự tin rằng:\nDashboard nhất quán với dữ liệu bên dưới. Bạn có thể tái tạo các con số chính bằng SQL nếu cần. Tổng kết Hoàn thành phần này, bạn đã:\nĐảm bảo batch ETL đã nạp dữ liệu clickstream mới vào PostgreSQL Data Warehouse. Xác nhận dữ liệu bằng cách chạy các truy vấn SQL trực tiếp (tổng số event, lượt xem sản phẩm, các chỉ số funnel cơ bản). Truy cập R Shiny dashboards chạy trên EC2 private thông qua port forwarding an toàn. Khám phá các dashboard về hành trình người dùng, hiệu suất sản phẩm và hoạt động theo thời gian. Kết nối các trực quan Shiny với schema và truy vấn trong Data Warehouse. Trong phần tiếp theo (5.6 Summary \u0026amp; Clean up), bạn sẽ tóm tắt lại các điểm chính từ workshop và rà soát những tài nguyên AWS cần dừng hoặc xoá để tránh phát sinh chi phí không cần thiết.\nHình 5-13: Shiny dashboard cho phân tích clickstream\nẢnh chụp màn hình Shiny dashboard được xây trên PostgreSQL Data Warehouse:\nPhễu hành trình người dùng từ product view đến purchase. Biểu đồ chuỗi thời gian số event mỗi ngày (page view, product view, add-to-cart, purchase). Bảng top sản phẩm hiển thị các item có tương tác và chuyển đổi cao nhất. Bộ lọc ở phía trên (khoảng ngày, loại event, thiết bị, nguồn traffic) để phân tích theo nhiều lát cắt khác nhau. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Đảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư, khả năng mở rộng cao và bảo mật giữa VPC của bạn với các dịch vụ AWS được hỗ trợ, cũng như với các dịch vụ do bên thứ ba hoặc chính bạn cung cấp. Lưu lượng luôn đi trên hạ tầng mạng nội bộ của AWS thay vì Internet công cộng, giúp giảm bề mặt tấn công và đơn giản hóa bài toán bảo mật.\nTrong workshop này, bạn sẽ học cách thiết kế và triển khai một kiến trúc hybrid cho phép truy cập an toàn đến Amazon S3 từ:\nCác workload chạy trong VPC (ứng dụng, batch job, analytic job,…). Hạ tầng tại chỗ (on‑premises) kết nối lên AWS thông qua AWS Direct Connect hoặc VPN. Bạn sẽ thực hành tạo, cấu hình và kiểm thử các loại VPC endpoint khác nhau để truy cập S3 mà không cần dùng Internet Gateway hoặc NAT Gateway.\nCụ thể, chúng ta sẽ làm việc với hai loại endpoint để truy cập Amazon S3:\nGateway endpoint – Cho phép VPC gửi lưu lượng đến Amazon S3 bằng cách thêm thành phần “điểm cuối” vào route table của các subnet. Lưu lượng từ subnet tới S3 sẽ được định tuyến nội bộ thông qua endpoint này mà không đi qua Internet. Interface endpoint – Tạo một hoặc nhiều Elastic Network Interface (ENI) trong VPC, mỗi ENI có private IP và được liên kết với một dịch vụ được hỗ trợ thông qua AWS PrivateLink. Lưu lượng tới S3 sử dụng endpoint này sẽ được resolve qua DNS và đi hoàn toàn trên mạng riêng của AWS, kể cả khi được truy cập từ môi trường on‑premises thông qua Direct Connect hoặc VPN. Sau khi hoàn thành workshop, bạn sẽ hiểu rõ sự khác nhau giữa hai loại endpoint, thời điểm nên sử dụng từng loại, cũng như các tác động về bảo mật và chi phí khi thiết kế đường truy cập hybrid đến S3.\nNội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 6: Tìm hiểu về AWS Auto Scaling và Elastic Load Balancing (ELB) để đảm bảo ứng dụng có thể mở rộng và phân phối tải hiệu quả. Học về AWS Elastic Container Service (ECS) và AWS Fargate. Thực hành triển khai ứng dụng container trên ECS và sử dụng Auto Scaling để tự động điều chỉnh tài nguyên. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học về AWS Auto Scaling + Cấu hình Auto Scaling cho EC2 + Thiết lập chính sách mở rộng (scale-out) và thu hẹp (scale-in) 12/10/2025 12/10/2025 Tài liệu học tập 3 - Học về Elastic Load Balancer (ELB) + Cấu hình và sử dụng ELB để phân phối tải giữa các EC2 instance / service 13/10/2025 13/10/2025 Tài liệu học tập 4 - Học về AWS ECS và AWS Fargate + Giới thiệu kiến trúc ECS, Task, Service + Giới thiệu Fargate và mô hình chạy container không quản lý server 14/10/2025 14/10/2025 Tài liệu học tập 5 - Thực hành triển khai ứng dụng trên ECS \u0026amp; Fargate + Triển khai ứng dụng container đơn giản trên ECS + Sử dụng Fargate để chạy container 15/10/2025 15/10/2025 Tài liệu học tập 6 - Thực hành với Auto Scaling và ELB cho ứng dụng trên ECS + Cấu hình Auto Scaling cho ECS Service + Tích hợp với ELB để phân phối tải 16/10/2025 16/10/2025 Tài liệu học tập Kết quả đạt được tuần 6: Đã cấu hình AWS Auto Scaling và Elastic Load Balancing cho ứng dụng chạy trên EC2 / ECS. Làm quen với AWS ECS và AWS Fargate, hiểu cách tổ chức Cluster – Task – Service. Thực hành triển khai ứng dụng container trên ECS, sử dụng Fargate để chạy container mà không cần quản lý máy chủ. Hiểu cách kết hợp ELB + Auto Scaling + ECS để xây dựng hệ thống có khả năng tự động mở rộng, phân phối tải và vận hành ổn định. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập tại Amazon Web Services (AWS) từ 08/09/2025 đến 05/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng những kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi tham gia vào dự án Batch-based Clickstream Analytics Platform cho một website thương mại điện tử bán sản phẩm máy tính., với các nhiệm vụ chính như:\nTìm hiểu và triển khai các dịch vụ AWS như Amazon S3, AWS Lambda, Amazon EventBridge, Amazon EC2, AWS Amplify, Amazon Cognito để phục vụ bài toán thu thập và xử lý dữ liệu clickstream.\nHỗ trợ xây dựng pipeline thu thập, lưu trữ và xử lý dữ liệu clickstream theo mô hình batch, trong đó dữ liệu hành vi người dùng trên website được ghi nhận, đưa vào S3 và xử lý định kỳ bằng Lambda/EventBridge trước khi nạp vào hệ thống phân tích.\nTham gia cấu hình hạ tầng trên AWS, kết nối với cơ sở dữ liệu PostgreSQL/Supabase và tích hợp với ứng dụng frontend (Next.js) của website thương mại điện tử.\nViết tài liệu kỹ thuật, báo cáo tiến độ và trao đổi thường xuyên với mentor/team để cập nhật tình hình và thống nhất hướng triển khai.\nThông qua đó, tôi cải thiện rõ rệt các kỹ năng về lập trình, thiết kế hệ thống, làm việc với dịch vụ cloud, xây dựng pipeline xử lý dữ liệu batch, viết báo cáo, làm việc nhóm và giao tiếp trong môi trường chuyên nghiệp.\nVề tác phong, tôi luôn cố gắng hoàn thành nhiệm vụ được giao, tuân thủ quy trình làm việc của team và chủ động trao đổi khi gặp khó khăn để đảm bảo chất lượng công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ☐ ✅ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ☐ ✅ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ☐ ✅ ☐ Cần cải thiện Nâng cao tính kỷ luật và kỹ năng quản lý thời gian, chấp hành nghiêm túc nội quy, deadline trong mọi môi trường làm việc. Rèn luyện thêm tư duy giải quyết vấn đề, đặc biệt là kỹ năng phân tích nguyên nhân gốc rễ và so sánh nhiều phương án trước khi lựa chọn giải pháp. Cải thiện kỹ năng giao tiếp: trình bày ngắn gọn, rõ ràng hơn trong các buổi họp, chủ động chia sẻ khó khăn/thắc mắc với mentor và các thành viên trong nhóm. Nhìn chung, tôi đánh giá kỳ thực tập tại AWS là một trải nghiệm rất ý nghĩa, giúp tôi trưởng thành hơn cả về chuyên môn lẫn tác phong làm việc, đồng thời nhận ra những điểm cần tiếp tục rèn luyện trong chặng đường sắp tới.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/5-workshop/5.6-summary--clean-up/",
	"title": "Summary &amp; Clean up",
	"tags": [],
	"description": "",
	"content": "Phần cuối cùng này sẽ:\nTóm tắt lại các khái niệm và thành phần chính mà bạn đã làm việc xuyên suốt workshop. Nhấn mạnh cách chúng kết hợp với nhau thành một Nền tảng phân tích Clickstream theo lô (Batch-based Clickstream Analytics Platform) hoàn chỉnh. Cung cấp một checklist dọn dẹp (clean-up) để bạn có thể dừng hoặc xoá các tài nguyên AWS và tránh chi phí không cần thiết sau khi kết thúc thực hành. Tóm tắt những điểm chính đã học Xuyên suốt các Mục 5.1–5.5, bạn đã xây dựng và kiểm chứng một pipeline phân tích đầu–cuối cho một website thương mại điện tử bán các sản phẩm máy tính.\nKiến trúc và thiết kế Từ 5.1 Objectives \u0026amp; Scope và 5.2 Architecture Walkthrough, bạn đã học cách:\nMô tả các khối chức năng cốt lõi của nền tảng:\nFrontend \u0026amp; miền hướng tới người dùng (user-facing domain):\nỨng dụng Next.js trên AWS Amplify Hosting. Phân phối qua Amazon CloudFront. Xác thực người dùng bằng Amazon Cognito. Miền ingest \u0026amp; data lake:\nAmazon API Gateway (HTTP API) làm endpoint ingest clickstream. Lambda Ingest để validate và enrich event. S3 Raw Clickstream bucket lưu trữ log JSON được phân vùng theo thời gian. Miền Analytics \u0026amp; Data Warehouse:\nVPC với public OLTP subnet và các private subnet cho Analytics + ETL. PostgreSQL Data Warehouse trên EC2 trong Analytics private subnet. R Shiny Server cùng EC2 đó để hiển thị dashboard phân tích. Lambda ETL có gắn VPC trong ETL private subnet. Giải thích vì sao nền tảng tách biệt:\nWorkload OLTP (Operational) (đơn hàng, tồn kho, người dùng thời gian thực) và Workload Analytics (Read-heavy) (phân tích funnel, hiệu suất sản phẩm, chuỗi thời gian). Việc tách biệt này cải thiện hiệu năng, độ ổn định và bảo mật cho hệ thống.\nĐường ingest: Frontend → API Gateway → S3 Từ 5.3 Implementing Clickstream Ingestion, bạn đã:\nTriển khai và/hoặc hiểu một luồng tracking trong đó:\nTrình duyệt thu thập các event page view, product view, add-to-cart và checkout. Event được tuần tự hoá thành payload JSON chứa metadata về người dùng, session và sản phẩm. Frontend gọi POST /clickstream trên API Gateway. Thấy được cách Lambda Ingest:\nParse các event nhận được.\nThực thi validate tối thiểu và gắn thêm metadata phía server.\nGhi các object JSON dạng batch vào S3 Raw Clickstream bucket sử dụng prefix phân vùng, ví dụ:\nevents/YYYY/MM/DD/HH/events-\u0026lt;uuid\u0026gt;.json Thực hành kiểm thử thủ công bằng cả:\nFrontend thật (thông qua Developer Tools của trình duyệt), và Các API client như Postman hoặc Thunder Client. Lớp phân tích riêng tư: Gateway Endpoint, Lambda ETL, Data Warehouse Từ 5.4 Building the Private Analytics Layer, bạn đã:\nCấu hình S3 Gateway VPC Endpoint, đảm bảo rằng:\nCác private subnet không cần public IP hoặc NAT Gateway để truy cập S3. Traffic giữa Lambda ETL và S3 luôn chạy trên mạng riêng nội bộ của AWS. Gắn Lambda ETL vào VPC bằng cách:\nChọn ETL private subnet và security group phù hợp. Cấp cho IAM execution role của Lambda các quyền tối thiểu để đọc từ Raw bucket và ghi log vào CloudWatch. Cài đặt logic ETL để:\nLiệt kê các object S3 trong một khoảng thời gian nhất định. Parse các event clickstream JSON thô. Transform chúng thành các cấu trúc quan hệ (ví dụ: fact_events, dim_products). Nạp dữ liệu vào PostgreSQL Data Warehouse trên EC2 trong Analytics private subnet. Kiểm chứng kết nối và bảo mật thông qua:\nSecurity group chỉ cho phép Lambda ETL kết nối tới Data Warehouse trên port 5432. Route table trong private subnet chỉ chứa các route local + prefix-list tới S3, không có 0.0.0.0/0. Phân tích và trực quan hoá với Shiny Từ 5.5 Visualizing Analytics with Shiny Dashboards, bạn đã:\nTrigger job ETL (qua EventBridge hoặc thủ công) và kiểm tra tính mới của dữ liệu bằng các truy vấn SQL:\nĐếm tổng số event. Phân bố event theo loại. Top sản phẩm được xem nhiều nhất. Các chỉ số funnel đơn giản. Truy cập R Shiny dashboards chạy trên EC2 private cùng với Data Warehouse bằng cách forward port an toàn:\nSSH tunnel, hoặc AWS Systems Manager Session Manager. Khám phá các dashboard mô tả:\nPhễu và hành trình người dùng (page view → product view → add-to-cart → checkout → purchase). Hiệu suất sản phẩm (top sản phẩm theo lượt xem và đơn hàng). Xu hướng theo thời gian (số event theo giờ/ngày). Kết nối các biểu đồ trong Shiny với các truy vấn SQL và bảng trong Data Warehouse, xác nhận rằng:\nDashboard nhất quán với dữ liệu. Bạn có thể kiểm tra lại các chỉ số quan trọng bằng SQL khi cần. Checklist dọn dẹp (Clean-up) các tài nguyên AWS Sau khi hoàn thành workshop, nên dọn dẹp tài nguyên để tránh chi phí phát sinh. Cách xử lý cụ thể tuỳ thuộc vào việc môi trường này là:\nMột môi trường lab/demo ngắn hạn, hay Một môi trường phát triển/staging cần giữ lại lâu dài. Quan trọng: Trước khi xoá bất kỳ thứ gì, hãy đảm bảo rằng không có ai khác đang sử dụng cùng AWS account hoặc các tài nguyên chung.\nEC2 instances EC2 OLTP (Public Subnet)\nNếu không còn cần cơ sở dữ liệu vận hành: Dừng instance để ngưng chi phí compute, hoặc Terminate để xoá vĩnh viễn. Trước khi terminate, cân nhắc: Chụp snapshot volume hoặc backup cuối. Dùng pg_dump hoặc công cụ tương tự để xuất dữ liệu quan trọng. EC2 Data Warehouse + Shiny (Private Subnet)\nNếu chỉ dùng cho workshop: Dừng hoặc terminate sau khi đã export kết quả phân tích hoặc schema cần giữ. Nếu dự định mở rộng lớp analytics sau này: Có thể giữ instance nhưng cần: Gỡ bỏ các service không dùng (các app Shiny thử nghiệm). Đảm bảo security group vẫn chặt chẽ (không inbound rộng). Lambda functions và EventBridge rules Lambda Ingest\nNếu bạn không còn gửi clickstream event: Có thể xoá function để giao diện console gọn gàng hơn. Nếu vẫn muốn dùng để thử nghiệm tiếp: Giữ lại, nhưng cân nhắc tạm thời tắt frontend hoặc sửa cấu hình. Lambda ETL\nNếu EC2 Data Warehouse đã dừng hoặc xoá: Disable hoặc xoá Lambda ETL (và EventBridge rule đi kèm) để tránh các lần invoke thất bại. EventBridge ETL schedule\nVào Amazon EventBridge → Rules. Disable hoặc xoá rule (ví dụ clickstream-etl-schedule) để nó không kích hoạt ETL nữa. S3 buckets và dữ liệu Raw Clickstream S3 bucket\nQuyết định có giữ lại dữ liệu raw hay không:\nVới lab ngắn hạn, bạn có thể xoá các prefix events/YYYY/MM/DD/HH/ được tạo trong lúc test. Với dự án dài hạn, giữ lại bucket nhưng: Cân nhắc bật S3 lifecycle policy để: Chuyển dữ liệu cũ sang storage class rẻ hơn, hoặc Xoá sau N ngày. Các bucket khác cho project\nNếu có các bucket chỉ phục vụ workshop (log, artifact, screenshots…), hãy rà soát và xoá nếu không cần nữa. Lưu ý: Chi phí S3 có thể tăng dần theo thời gian; nên định kỳ kiểm tra nội dung bucket và rule lifecycle.\nVPC Endpoint và thành phần mạng S3 Gateway VPC Endpoint\nNếu VPC không còn dùng cho analytics: Có thể xoá Gateway Endpoint. Nếu VPC vẫn dùng chung cho các workload khác: Có thể giữ lại để dùng tiếp. Route table, subnet, VPC\nVới VPC dành riêng cho lab: Có thể xoá toàn bộ VPC (xoá luôn subnet, route table, endpoint đi kèm) sau khi chắc chắn không còn EC2, RDS hay tài nguyên quan trọng nào phụ thuộc. Với VPC dùng chung: Chỉ xoá các subnet/route table tạo riêng cho workshop, tránh ảnh hưởng môi trường khác. CloudWatch Logs và monitoring CloudWatch Logs cho Lambda và API Gateway\nLog group có thể lớn dần theo thời gian. Đặt retention policy phù hợp (7, 30, 90 ngày) cho: Lambda Ingest. Lambda ETL. API Gateway access log. CloudWatch Alarms và metric\nNếu bạn tạo các alarm riêng cho môi trường này (ví dụ: alarm lỗi ingest hoặc ETL): Disable hoặc xoá khi decommission môi trường. Hình 5-14: CloudWatch alarms cho nền tảng clickstream\nẢnh chụp màn hình hiển thị một tập các CloudWatch alarms cho đường ingest và Data Warehouse, bao gồm:\nAlarm latency và tỉ lệ 4xx/5xx của API. Alarm duration và throttling cho Lambda Ingest. Alarm status check và CPU utilization cho EC2 Data Warehouse. Phần lớn alarm ở trạng thái OK hoặc Insufficient data, cho thấy hệ thống đang “khỏe mạnh” và có thể được tắt/xoá an toàn sau workshop.\nIAM roles và policies Lambda execution roles\nRà soát các IAM role tạo cho:\nLambda Ingest. Lambda ETL. Nếu không còn cần:\nGỡ các policy đính kèm. Xoá role để tránh tích luỹ các IAM identity không dùng đến. User/role test\nNếu bạn tạo IAM user hoặc role chỉ để test trong workshop: Xoá hoặc siết chặt permission. Amplify, Cognito và API Gateway Amplify app\nNếu frontend Next.js chỉ dùng cho workshop: Xoá Amplify app và các branch/environment tương ứng. Cognito User Pool\nXoá các user test hoặc xoá toàn bộ User Pool nếu nó chỉ phục vụ workshop. API Gateway HTTP API\nXoá API ingest clickstream nếu không còn dùng, nhất là khi nó được tạo riêng cho lab. Nên giữ lại những gì cho các bước kế tiếp? Nếu bạn dự định mở rộng project sau workshop, hãy cân nhắc giữ lại:\nCode repository:\nFrontend Next.js (bao gồm tracking logic). Lambda Ingest và Lambda ETL. Mã Shiny app. File hạ tầng như Terraform/CloudFormation. Schema Data Warehouse và một tập dữ liệu mẫu nhỏ:\nMột EC2 instance nhỏ với database chứa vài nghìn event là đủ để tiếp tục phát triển dashboard và truy vấn mà không cần ingest volume lớn. Sơ đồ kiến trúc và ghi chú:\nCác sơ đồ dùng trong Hình 5-1 đến 5-6 (và các hình ở phần 5.3–5.5). Lý do thiết kế (ví dụ: dùng Gateway Endpoint thay vì NAT Gateway). Những tài sản này sẽ giúp bạn tiếp tục project hoặc chuyển đổi nó thành giải pháp nâng cao hơn (ví dụ: chuyển sang Amazon Redshift Serverless hoặc thêm Streaming real-time).\nLời kết Workshop này đã minh hoạ cách:\nThiết kế và triển khai một kiến trúc phân tích an toàn, tiết kiệm chi phí và dễ mở rộng trên AWS. Thu thập event clickstream từ một frontend thương mại điện tử thực tế. Xây dựng một quy trình ETL riêng tư đọc từ S3 và nạp dữ liệu vào một Data Warehouse riêng. Trực quan hoá hành vi người dùng và hiệu suất sản phẩm bằng R Shiny, mà không cần phơi bày backend analytics ra Internet công cộng. Giờ đây bạn đã có một “bản mẫu” (reference) cho việc xây dựng các nền tảng phân tích tương tự, cùng một nền tảng kiến thức vững chắc để thực hiện các nâng cấp trong tương lai như:\nStreaming real-time (Kinesis / Kafka). Mô hình phân bổ (attribution) nâng cao và phân đoạn người dùng. Di chuyển Data Warehouse sang các dịch vụ quản lý như Amazon Redshift. Hình 5-15: Danh sách tài nguyên cần rà soát sau workshop Sơ đồ hoặc bảng trong hình này nên liệt kê, với mỗi dịch vụ AWS:\nLoại tài nguyên (EC2, S3, Lambda, EventBridge, API Gateway, VPC Endpoint, …). Ví dụ tên tài nguyên cụ thể. Hành động khuyến nghị sau workshop (Keep / Stop / Delete / Set retention). "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": "Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 7: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 20/10/2025 20/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 21/08/2025 21/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 22/08/2025 22/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 23/08/2025 23/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 24/08/2025 24/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 7: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 8: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 27/10/2025 27/10/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; nhớ làm 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 8: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 9: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 9: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 10: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 10: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 11: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 11: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "\r⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nMục tiêu tuần 12: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 12: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]