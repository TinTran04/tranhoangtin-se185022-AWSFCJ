[
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": " Cách iFood xây dựng nền tảng để chạy hàng trăm mô hình machine learning với Amazon SageMaker Inference Bởi Daniel Vieira, Debora Fanin, Gopi Mudiyala và Saurabh Trikande – ngày 08 tháng 4 năm 2025, trong chuyên mục Nâng cao (300), Amazon SageMaker Data \u0026amp; AI Governance, Customer Solutions.\nGiới thiệu Có trụ sở chính tại São Paulo, Brazil, iFood là một công ty tư nhân quốc gia và là công ty hàng đầu trong lĩnh vực công nghệ thực phẩm ở Mỹ Latinh, xử lý hàng triệu đơn đặt hàng hàng tháng. iFood nổi bật với chiến lược kết hợp công nghệ tiên tiến vào hoạt động của mình. Với sự hỗ trợ của AWS, iFood đã phát triển cơ sở hạ tầng suy luận machine learning (ML) mạnh mẽ, sử dụng các dịch vụ như Amazon SageMaker để tạo và triển khai các mô hình ML một cách hiệu quả. Sự hợp tác này đã cho phép iFood không chỉ tối ưu hóa các quy trình nội bộ mà còn cung cấp các giải pháp sáng tạo cho các đối tác giao hàng và nhà hàng của mình.\nNền tảng ML của iFood bao gồm một tập hợp các công cụ, quy trình và workflow được phát triển với các mục tiêu chính:\nĐẩy nhanh quá trình phát triển và đào tạo các mô hình AI/ML, làm cho chúng đáng tin cậy và dễ tái tạo hơn. Đảm bảo rằng việc triển khai các mô hình này vào sản xuất là đáng tin cậy, có thể mở rộng và có thể truy xuất nguồn gốc. Tạo điều kiện thuận lợi cho việc thử nghiệm, giám sát và đánh giá các mô hình trong sản xuất một cách minh bạch, dễ tiếp cận và tiêu chuẩn hóa. Hình 1. Minh họa tổng quan — iFood và ứng dụng AI/ML trong hệ thống sản phẩm.\nMục tiêu và cách tiếp cận Để đạt được những mục tiêu trên, iFood tận dụng SageMaker để đơn giản hóa việc huấn luyện và triển khai mô hình. Việc tích hợp các tính năng của SageMaker trong cơ sở hạ tầng của iFood tự động hóa các bước quan trọng — từ tạo dataset huấn luyện, huấn luyện mô hình, triển khai mô hình vào production đến liên tục theo dõi hiệu suất.\nBài viết này trình bày cách iFood sử dụng SageMaker để cải tiến toàn bộ vòng đời ML — từ huấn luyện đến suy luận — đồng thời mô tả những thay đổi kiến trúc và các khả năng mà đội ngũ đã phát triển.\nSuy luận AI tại iFood iFood khai thác nền tảng AI/ML để nâng cao trải nghiệm khách hàng trên nhiều điểm tiếp xúc. Một số trường hợp sử dụng điển hình:\nĐề xuất cá nhân hóa — Mô hình phân tích lịch sử đặt hàng, sở thích và ngữ cảnh để đề xuất nhà hàng và món ăn phù hợp, giúp tăng mức độ hài lòng và số lượng đơn hàng. Theo dõi đơn hàng thông minh — Hệ thống dự đoán thời gian giao hàng theo thời gian thực bằng cách kết hợp dữ liệu giao thông, thời gian chuẩn bị nhà hàng và vị trí shipper, từ đó thông báo chủ động cho khách. Dịch vụ khách hàng tự động — Chatbot AI xử lý hàng nghìn yêu cầu phổ biến mỗi ngày, cung cấp phản hồi nhanh và có thể truy xuất dữ liệu liên quan để hỗ trợ cá nhân hóa. Hỗ trợ mua sắm hàng tạp hóa — Ứng dụng tích hợp mô hình ngôn ngữ giúp khách hàng tạo danh sách mua sắm từ yêu cầu bằng giọng nói hoặc văn bản. Nhờ những sáng kiến này, iFood có thể dự đoán nhu cầu, tối ưu hoá quy trình và cung cấp trải nghiệm nhất quán cho người dùng.\nTổng quan về giải pháp (Kiến trúc kế thừa) Sơ đồ dưới đây minh họa kiến trúc kế thừa của iFood, trong đó các nhóm Data Science và Engineering có workflow tách biệt — chính điều này gây ra thách thức khi triển khai mô hình ML thời gian thực vào production.\nHình 2. Kiến trúc kế thừa — mô tả luồng dữ liệu và rào cản giữa các nhóm.\nTrước đây, các nhà khoa học dữ liệu thường phát triển mô hình trong notebook, tinh chỉnh và xuất bản artifact. Các kỹ sư sau đó phải tích hợp các artifact này vào hệ thống production, dẫn tới độ trễ và lỗi tích hợp. Để khắc phục, iFood đã phát triển một nền tảng ML nội bộ nhằm hợp nhất quy trình từ phát triển đến triển khai, tạo trải nghiệm liền mạch cho cả hai bên.\nKiến trúc cập nhật và ML Go! Một trong các khả năng cốt lõi của nền tảng ML của iFood là cung cấp cơ sở hạ tầng để phục vụ dự đoán. Nền tảng nội bộ (gọi là ML Go!) chịu trách nhiệm triển khai quy trình, quản lý SageMaker Endpoints và Jobs. ML Go! hỗ trợ cả dự đoán ngoại tuyến (batch) và dự đoán thời gian thực (online), đồng thời quản lý lifecycle của mô hình (registry, versioning, monitoring).\nHình 3. Kiến trúc cập nhật — bao gồm pipeline, model registry và component cho inference.\nNền tảng cung cấp:\nML pipelines tự động (SageMaker Pipelines) để huấn luyện và tái huấn luyện mô hình. ML Go! CI/CD để đẩy artifact, build Docker image, và kích hoạt pipeline. SageMaker Model Registry để versioning và quản lý mô hình. Cơ chế monitoring để phát hiện drift và cảnh báo hiệu năng suy giảm. Kiến trúc cuối cùng: inference components \u0026amp; ML Go! Gateway Một cải tiến lớn là khái niệm trừu tượng hóa để kết nối với SageMaker (Endpoints \u0026amp; Jobs) gọi là ML Go! Gateway, cùng với tách biệt “inference components” trong endpoint — giúp phân chia mối quan tâm, tăng tốc phân phối và quản lý tài nguyên hiệu quả hơn. Các endpoint giờ đây quản lý nhiều thành phần suy luận (component-based inference), và ML Go! CI/CD chỉ lo phần quảng bá phiên bản mô hình (model promotion), không can thiệp sâu vào tầng hạ tầng.\nHình 4. Kiến trúc cuối cùng — inference components, ML Go! Gateway và tích hợp với service accounts.\nTrong cấu trúc mới:\nEndpoints có thể chứa nhiều component inference, cho phép phân tải công việc, chia theo tải hoặc chức năng. ML Go! Dispatcher/ Gateway đóng vai trò chuyển tiếp yêu cầu tới đúng endpoint hoặc job. CI/CD xử lý artifacts (Docker images, configs), SageMaker Pipeline orchestrates training → evaluation → registry → deployment. Sử dụng SageMaker Inference Model Serving Containers Tiêu chuẩn hóa môi trường bằng container là yếu tố quyết định của nền tảng ML hiện đại. SageMaker cung cấp các container dựng sẵn cho TensorFlow, PyTorch, XGBoost… đồng thời cho phép đưa container tùy chỉnh.\niFood tập trung sử dụng container tùy chỉnh (custom containers) để:\nChuẩn hóa mã ML (không dùng trực tiếp notebook vào production). Đóng gói dependency, thư viện và logic inference trong image (ví dụ: BruceML scaffolding). Dễ dàng tái tạo môi trường huấn luyện và phục vụ, theo dõi kết quả và debug. BruceML giúp chuẩn hóa cách viết mã huấn luyện và phục vụ, tạo scaffold tương thích với SageMaker (autotuning, deployment hooks, monitoring).\nTự động hóa triển khai và đào tạo lại (ML pipelines \u0026amp; CI/CD) iFood dùng SageMaker Pipelines để xây dựng CI/CD cho ML: pipelines chịu trách nhiệm orchestrate toàn bộ luồng dữ liệu — từ data preprocessing, training, evaluation, tới promotion vào Model Registry và deployment. ML Go! CI/CD tích hợp với hệ thống CI/CD của tổ chức để:\nĐẩy artifact (code + container image). Kích hoạt pipeline huấn luyện và đánh giá. Tự động đăng ký mô hình đạt chuẩn vào Model Registry. Triển khai hoặc promote mô hình lên endpoint phù hợp (online / batch). Tùy theo SLA:\nBatch inference: sử dụng SageMaker Transform jobs cho dự đoán quy mô lớn. Real-time inference: triển khai mô hình tới SageMaker Endpoint với cấu hình container/instance phù hợp. SageMaker Pipelines giúp tự động hóa và điều phối các workflow phức tạp, giảm sai sót và rút ngắn vòng lặp phát triển.\nChạy suy luận ở các định dạng SLA khác nhau iFood tận dụng nhiều phương thức suy luận để đáp ứng các yêu cầu khác nhau:\nReal-time endpoints cho các tác vụ cần latency thấp (user-facing). Batch transform jobs cho xử lý dữ liệu quy mô lớn, tính toán gợi ý định kỳ. Asynchronous inference (SageMaker Asynchronous Inference) cho các tác vụ suy luận tốn thời gian. Multi-model endpoints (GPU) để host nhiều mô hình trên cùng một GPU endpoint, tối ưu sử dụng tài nguyên. Những cải tiến hợp tác giữa iFood và đội SageMaker Inference bao gồm:\nTối ưu hóa chi phí và hiệu suất cho inference (giảm ~50% chi phí cho một số workloads, giảm ~20% latency trung bình khi dùng inference components). Cải tiến autoscaling để xử lý spikes hiệu quả hơn (rút ngắn thời gian scale, cải thiện phát hiện scale events). Hỗ trợ triển khai LLM / Foundation Models (FM) dễ dàng hơn. Tính năng scale-to-zero cho endpoints giúp tiết kiệm chi phí khi không có traffic. Multi-model GPU endpoints giúp giảm chi phí cơ sở hạ tầng cho trường hợp nhiều mô hình. Tối ưu hóa và đóng gói mô hình Một số điểm kỹ thuật iFood tập trung:\nChuẩn hóa container cho cả training và serving. Tự động hóa build/publish images lên registry (ECR). Đóng gói LLM / FM để triển khai nhanh hơn. Hỗ trợ autoscaling và scale-to-zero cho môi trường dev/test và low-traffic workloads. Lợi ích đạt được \u0026amp; tác động Những lợi ích iFood thu được:\nGiảm thời gian đưa mô hình vào production (faster time-to-market). Tăng khả năng tái sử dụng pipeline \u0026amp; artifacts giữa các nhóm. Hạ chi phí vận hành nhờ tối ưu GPU/multi-model và scale-to-zero. Cải thiện độ ổn định và khả năng quản lý mô hình ở quy mô lớn. Kết luận Sử dụng các khả năng của SageMaker, iFood đã chuyển đổi cách tiếp cận ML/AI: xây dựng nền tảng ML tập trung (ML Go!), tự động hóa luồng dữ liệu, chuẩn hóa container và hợp tác cùng nhóm SageMaker Inference để tối ưu tính hiệu quả, chi phí và khả năng mở rộng. Việc này đã giúp iFood:\nThu hẹp khoảng cách giữa Data Science và Engineering. Triển khai hàng trăm mô hình ML một cách đáng tin cậy. Tạo nền tảng tham chiếu cho các tổ chức muốn ứng dụng inference ở quy mô lớn. “Tại iFood, chúng tôi đi đầu trong việc áp dụng công nghệ AI và máy học biến đổi\u0026hellip; Các bài học đã học được hỗ trợ chúng tôi trong việc tạo ra nền tảng nội bộ, có thể đóng vai trò như một kế hoạch chi tiết cho các tổ chức khác\u0026hellip;”\n– Daniel Vieira, Giám đốc Nền tảng ML tại iFood.\nGiới thiệu về các tác giả Daniel Vieira — Giám đốc Kỹ thuật Học máy tại iFood. Có nền tảng khoa học máy tính (BSc \u0026amp; MSc, UFMG) và hơn một thập kỷ kinh nghiệm về kỹ thuật phần mềm và nền tảng ML. Thích âm nhạc, triết học và cà phê.\nDebora Fanin — Giám đốc giải pháp khách hàng cấp cao, AWS (Brazil). Chuyên quản lý chuyển đổi khách hàng doanh nghiệp, thiết kế các chiến lược áp dụng đám mây hiệu quả về chi phí.\nSaurabh Trikande — Giám đốc sản phẩm cấp cao, Amazon Bedrock \u0026amp; SageMaker Inference. Tập trung vào dân chủ hóa AI và giải pháp suy luận ở quy mô lớn.\nGopi Mudiyala — Giám đốc tài khoản kỹ thuật cấp cao, AWS. Hỗ trợ khách hàng ngành dịch vụ tài chính và đam mê máy học.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.1-week1/",
	"title": "Worklog Tuần 1",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 1: Làm quen với nhóm và môi trường học tập tại First Cloud Journey (FCJ). Hiểu tổng quan về dịch vụ AWS và các nhóm dịch vụ cơ bản. Biết cách tạo tài khoản AWS Free Tier và kích hoạt $200 credit. Làm quen với AWS Management Console để sử dụng các dịch vụ cơ bản. Cài đặt và thiết lập AWS CLI để thao tác với tài nguyên AWS bằng dòng lệnh. Thực hành một số bài lab cơ bản như tạo tài khoản, thiết lập MFA, ngân sách, và tìm hiểu EC2. Các công việc cần triển khai trong tuần này Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tạo tài khoản AWS Free Tier - Thực hiện 5 bước để nhận $200 credit: + Sử dụng mô hình nền tảng trong Amazon Bedrock playground + Tạo cơ sở dữ liệu Amazon RDS + Tạo ứng dụng web bằng AWS Lambda + Thiết lập ngân sách chi phí với AWS Budgets + Khởi chạy một phiên bản máy chủ bằng Amazon EC2 08/09/2025 08/09/2025 AWS Free Tier 3 - Xem và học các Module giới thiệu AWS (YouTube): + Module 01-01 - Điện toán đám mây là gì? + Module 01-02 - Điều gì tạo nên sự khác biệt của AWS? + Module 01-03 - Bắt đầu hành trình lên mây như thế nào + Module 01-04 - Hạ tầng toàn cầu của AWS + Module 01-05 - Công cụ quản lý AWS Services + Module 01-06 - Tối ưu hóa chi phí và làm việc với AWS + Module 01-07 - Thực hành và nghiên cứu bổ sung 09/09/2025 09/09/2025 Tài liệu học tập 4 - Thực hành (YouTube): + Module 01-Lab01-01 - Tạo tài khoản AWS + Module 01-Lab01-02 - Thiết lập thiết bị MFA ảo + Module 01-Lab01-03 - Tạo nhóm quản trị và người dùng quản trị + Module 01-Lab01-04 - Hỗ trợ xác thực tài khoản + Module 01-Lab07-01 - Tạo ngân sách bằng mẫu (Template) + Module 01-Lab07-02 - Hướng dẫn tạo ngân sách chi phí + Module 01-Lab07-03 - Tạo ngân sách sử dụng (Usage Budget) trong AWS + Module 01-Lab07-04 - Tạo ngân sách Dành riêng (Reservation Instance - RI) + Module 01-Lab07-05 - Tạo ngân sách Gói tiết kiệm (Savings Plans) + Module 01-Lab07-06 - Dọn dẹp ngân sách (Clean Up Budgets) + Module 01-Lab09-01 - Các gói hỗ trợ AWS + Module 01-Lab09-02 - Các loại yêu cầu hỗ trợ + Module 01-Lab09-03 - Thay đổi gói hỗ trợ + Module 01-Lab09-04 - Quản lý các yêu cầu hỗ trợ 10/09/2025 10/09/2025 Tài liệu học tập 5 - Tìm hiểu EC2 cơ bản (thực hành): + EC2 là gì? + AMI (Amazon Machine Image) + EBS (Elastic Block Store) + Elastic IP + Các cách kết nối SSH vào EC2 + Tạo và quản lý phiên bản EC2 11/09/2025 11/09/2025 Tài liệu học tập Kết quả đạt được tuần 1: Đã tạo tài khoản AWS Free Tier thành công và kích hoạt được $200 credit. Biết đăng nhập và sử dụng giao diện AWS Management Console, tìm kiếm và truy cập các dịch vụ cơ bản. Cài đặt và cấu hình AWS CLI thành công trên máy tính cá nhân, bao gồm: Thiết lập Access Key, Secret Key, Region mặc định. Làm quen với các module học lý thuyết và lab hướng dẫn trên YouTube, gồm: Tổng quan điện toán đám mây và AWS Hạ tầng toàn cầu của AWS Quản lý tài khoản và ngân sách chi phí Giới thiệu về EC2 và cách tạo instance Bắt đầu hiểu cách tạo, khởi chạy và kết nối tới EC2 instance. Biết cách thiết lập ngân sách bằng AWS Budgets để theo dõi chi phí sử dụng. Hoàn thành các bước cấu hình bảo mật cơ bản (thiết lập MFA, người dùng quản trị IAM). "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/",
	"title": "Báo cáo thực tập",
	"tags": [],
	"description": "",
	"content": "Báo cáo thực tập Thông tin sinh viên: Họ và tên: Trần Hoàng Tín\nSố điện thoại: 0936091757\nEmail: tinthse185022@fpt.edu.vn\nTrường: Đại học FPT Hồ Chí Minh\nNgành: Công nghệ thông tin\nLớp: SE185022\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/",
	"title": "Nhật ký công việc",
	"tags": [],
	"description": "",
	"content": "Tuần 1: Worklog Tuần 1\nTuần 2: Worklog Tuần 2\nTuần 3: Worklog Tuần 3\nTuần 4: Worklog Tuần 4\nTuần 5: Worklog Tuần 5\nTuần 6: Worklog Tuần 6\nTuần 7: Worklog Tuần 7\nTuần 8: Worklog Tuần 8\nTuần 9: Worklog Tuần 9\nTuần 10: Worklog Tuần 10\nTuần 11: Worklog Tuần 11\nTuần 12: Worklog Tuần 12\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/4-eventparticipated/4.1-event1/",
	"title": "Sự kiện 1",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders” Thông tin sự kiện Tên sự kiện: AWS Cloud Day Vietnam – AI Edition 2025 (Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders) Ngày: 18 tháng 9 năm 2025 Địa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, Thành phố Hồ Chí Minh Vai trò: Người tham dự Mục Đích Của Sự Kiện Sự kiện AWS Cloud Day Vietnam – AI Edition 2025 được định vị là một cuộc tụ họp quan trọng của cộng đồng công nghệ và kinh doanh tại Việt Nam. Mục tiêu chính là thúc đẩy quá trình chuyển đổi số bằng cách tận dụng sức mạnh kết hợp của Điện toán đám mây (Cloud Computing) và Trí tuệ nhân tạo (AI).\nCác mục tiêu có thể được khái quát thành các trụ cột và ý nghĩa sau:\nKết nối cộng đồng công nghệ Việt Nam:\nTạo không gian gặp gỡ, trao đổi giữa doanh nghiệp, chuyên gia IT, lập trình viên và lãnh đạo ngành để cùng học hỏi về Cloud \u0026amp; AI.\nGiúp doanh nghiệp hiểu và ứng dụng thực tế Cloud \u0026amp; AI:\nTập trung vào các chủ đề như Gen AI, phân tích dữ liệu (data analytics), hiện đại hóa hệ thống (modernize workloads), và industry cloud cho từng ngành cụ thể.\nTrình diễn các câu chuyện thành công:\nGiới thiệu các case study như Xanh SM, Honda Việt Nam, Masterise Group, Techcombank, TymeX, F88… cho thấy Cloud \u0026amp; AI có thể chuyển hóa vận hành doanh nghiệp như thế nào.\nThúc đẩy phát triển kinh tế số và đổi mới sáng tạo:\nGóp phần hiện thực hóa chiến lược chuyển đổi số quốc gia, đưa Cloud \u0026amp; AI trở thành nền tảng cho tăng trưởng kinh tế.\nXây dựng nền tảng giao lưu – kết nối – hợp tác lâu dài:\nTạo cầu nối giữa công nghệ – doanh nghiệp – lãnh đạo ngành, hướng đến hợp tác bền vững trong kỷ nguyên số.\nBốn trụ cột chiến lược được nhấn mạnh Phổ cập AI tạo sinh (GenAI) cho doanh nghiệp\nĐưa GenAI vượt ra khỏi tính “hào nhoáng” ban đầu để đi vào ứng dụng thực tế. Chứng minh cách doanh nghiệp có thể biến các mô hình AI chung chung thành các giải pháp nhận biết ngữ cảnh, gắn với chiến lược dữ liệu. Xóa bỏ ranh giới giữa Kinh doanh và CNTT\nĐặc biệt trong lĩnh vực Dịch vụ Tài chính (FSI). Cloud không chỉ là hạ tầng, mà là động lực tạo giá trị kinh doanh, cho phép mô hình Ecosystem Banking và Embedded Finance. Tăng tốc hiện đại hóa theo đặc thù ngành\nXây dựng lộ trình riêng cho từng ngành: Bán lẻ, Năng lượng, Viễn thông, Bất động sản, Khu vực công,… Nhấn mạnh rằng hiện đại hóa không có “một công thức chung”, mà phải dựa vào đặc điểm từng hệ thống và chiến lược doanh nghiệp. Củng cố an ninh và khả năng phục hồi\nĐề cao tư duy “security by design” – bảo mật từ khâu thiết kế. Tích hợp bảo mật vào suốt vòng đời ứng dụng, từ phát triển đến vận hành thực tế. Danh Sách Diễn Giả Sự kiện quy tụ 24 diễn giả từ cơ quan nhà nước, đại sứ quán, các tổ chức tài chính – ngân hàng, công nghệ và đối tác AWS. Một số diễn giả tiêu biểu:\nH.E. Pham Duc Long – Thứ trưởng Bộ Khoa học và Công nghệ, Việt Nam H.E. Marc E. Knapper – Đại sứ Hoa Kỳ tại Việt Nam Jaime Valles – Phó Chủ tịch, Tổng Giám đốc khu vực Châu Á Thái Bình Dương \u0026amp; Nhật Bản, AWS Jeff Johnson – Managing Director ASEAN, AWS Dr Jens Lottner – CEO, Techcombank Dieter Botha – CEO, TymeX Trang Phung – CEO, U2U Network Vu Van – Đồng sáng lập \u0026amp; CEO, ELSA Corp Nguyen Hoa Binh – Chủ tịch, Nexttech Group Cùng nhiều lãnh đạo và chuyên gia khác từ F88, Masterise Group, VTV Digital, Honda Việt Nam, Mobifone, Katalon, Renova Cloud, TechX Corp,… Nội Dung Nổi Bật 1. Sự hội tụ chiến lược: Chính sách và lãnh đạo Sự bảo trợ của Chính phủ:\nBài phát biểu khai mạc của Thứ trưởng Bộ KH\u0026amp;CN và Đại sứ Hoa Kỳ cho thấy sự ủng hộ mạnh mẽ đối với hạ tầng số và hệ sinh thái Cloud – AI tại Việt Nam.\nTọa đàm Lãnh đạo (Leadership Panel):\nCác lãnh đạo như Jeff Johnson (AWS), Vu Van (ELSA), Nguyen Hoa Binh (Nexttech)… nhấn mạnh vai trò của con người và văn hóa đổi mới trong việc thúc đẩy chuyển đổi số, chứ không chỉ là vấn đề công nghệ.\n2. Nhóm 1: Dịch vụ Tài chính (FSI) – Mô hình ngân hàng mới Đổi mới trong Ngân hàng \u0026amp; Bảo hiểm:\nTechcombank, Bảo Việt Holdings và các tổ chức tài chính chia sẻ hành trình chuyển dịch sang mô hình Ngân hàng Hệ sinh thái (Ecosystem Banking) và Tài chính Nhúng (Embedded Finance).\nTriển khai XGenAI:\nTechX trình bày về nền tảng XGenAI xây dựng trên AWS, thể hiện cách GenAI được dùng để cá nhân hóa trải nghiệm khách hàng, tối ưu chăm sóc và gợi ý dịch vụ tài chính.\n3. Nhóm 2: Hiện đại hóa đa ngành Honda Việt Nam:\nChia sẻ chi tiết lộ trình di chuyển hệ thống SAP lên AWS, không chỉ dừng ở “lift-and-shift” mà còn hướng tới thay đổi mô hình vận hành, tối ưu chi phí và độ linh hoạt.\nVTV Digital \u0026amp; Mobifone:\nTrình bày hành trình số hóa từ “Tầm nhìn đến Giá trị” trong ngành truyền thông số và viễn thông.\nMasterise Group:\nNhấn mạnh việc di chuyển hàng trăm workload VMware lên AWS, cho thấy quy mô và độ phức tạp trong quá trình hiện đại hóa hạ tầng bất động sản.\n4. Nhóm 3 \u0026amp; 4: Dữ liệu, AI và DevOps Chiến lược dữ liệu (Data Strategy):\nCác chuyên gia từ Onebyzero, Techcom Securities nhấn mạnh rằng “dữ liệu là yếu tố khác biệt then chốt” cho GenAI; chất lượng đầu ra AI phụ thuộc trực tiếp vào chất lượng dữ liệu đầu vào.\nCuộc cách mạng DevOps:\nKatalon và Renova Cloud trình bày cách tích hợp GenAI vào vòng đời DevOps: tự động sinh mã, tự động sinh test cases, phân tích log và tối ưu CI/CD.\n5. Các ảnh hưởng tiêu cực của kiến trúc ứng dụng cũ Thời gian release sản phẩm lâu → Mất doanh thu, bỏ lỡ cơ hội thị trường. Hoạt động kém hiệu quả → Mất năng suất, tăng chi phí vận hành. Không tuân thủ quy định bảo mật → Rủi ro mất an ninh, ảnh hưởng uy tín thương hiệu. Những hạn chế này chính là động lực thúc đẩy việc hiện đại hóa kiến trúc ứng dụng.\n6. Chuyển đổi sang kiến trúc Microservices Sự kiện nhấn mạnh việc chuyển từ hệ thống nguyên khối (monolith) sang Microservices Architecture:\nHệ thống được modular hóa, mỗi chức năng là một dịch vụ độc lập. Các service giao tiếp qua sự kiện (event-driven). Ba trụ cột kiến trúc được nêu rõ:\nQueue Management: Xử lý tác vụ bất đồng bộ, giảm tải cho hệ thống chính. Caching Strategy: Tối ưu performance, giảm độ trễ truy vấn. Message Handling: Giao tiếp linh hoạt giữa các service, hỗ trợ mở rộng và phục hồi lỗi. 7. Domain-Driven Design (DDD) Phương pháp 4 bước:\nXác định domain events → sắp xếp timeline → identify actors → xác định bounded contexts.\nCase study “Bookstore”:\nĐược dùng để minh họa cách áp dụng DDD trong thực tế, từ mô hình hóa domain đến tách service.\nContext mapping – 7 patterns tích hợp:\nGiúp quản lý quan hệ giữa các bounded contexts (Partnership, Shared Kernel, Anti-corruption Layer,…).\n8. Event-Driven Architecture 3 patterns tích hợp chính:\nPublish/Subscribe Point-to-Point Streaming Lợi ích:\nLoose coupling giữa các service Scalability dễ dàng Resilience cao hơn khi có lỗi cục bộ So sánh Sync vs Async:\nDiễn giả phân tích rõ trade-offs: synchronous đơn giản nhưng dễ nghẽn; asynchronous phức tạp hơn nhưng linh hoạt và chịu tải tốt.\n9. Compute Evolution \u0026amp; Serverless Shared Responsibility Model:\nGiải thích vai trò AWS vs khách hàng trên các mô hình: EC2 → ECS → Fargate → Lambda.\nLợi ích Serverless:\nKhông cần quản lý server Tự động scale Trả tiền theo giá trị sử dụng thực (pay-for-value) Functions vs Containers:\nGợi ý tiêu chí lựa chọn (thời gian chạy, tính trạng thái, tần suất, độ phức tạp deployment,…).\n10. Amazon Q Developer Tự động hóa SDLC:\nHỗ trợ developer xuyên suốt từ planning → coding → testing → maintenance.\nCode transformation:\nHỗ trợ nâng cấp Java, hiện đại hóa .NET, và migration từ mainframe / legacy stack lên kiến trúc mới.\nAWS Transform Agents:\nCung cấp các agent chuyên biệt cho VMware, Mainframe, .NET…, giúp giảm thời gian và rủi ro khi hiện đại hóa ứng dụng.\nNhững Gì Học Được 1. Tư Duy Thiết K Kế \u0026amp; Chiến Lược Business-first approach:\nGiải pháp công nghệ phải xuất phát từ vấn đề kinh doanh, thay vì chạy theo xu hướng kỹ thuật.\nUbiquitous Language:\nNgôn ngữ chung giữa business và tech giúp giảm hiểu lầm, đẩy nhanh quá trình phân tích yêu cầu và thiết kế.\nResilience là tiêu chuẩn:\nHệ thống hiện đại cần thiết kế cho khả năng phục hồi ngay từ đầu, thay vì “vá” sau khi có sự cố.\n2. Kiến Trúc Kỹ Thuật Event storming:\nLà phương pháp hiệu quả để mô hình hóa quy trình nghiệp vụ thành các domain events, từ đó dẫn đến thiết kế DDD và kiến trúc event-driven.\nEvent-driven communication:\nViệc thay thế một phần giao tiếp synchronous bằng cơ chế event-driven giúp hệ thống linh hoạt, dễ mở rộng và giảm phụ thuộc.\nIntegration patterns:\nHiểu rõ khi nào dùng sync API, khi nào dùng pub/sub, khi nào nên dùng streaming (Kafka/Kinesis).\nCompute spectrum:\nBiết cách cân nhắc giữa VM, containers, serverless để chọn runtime phù hợp cho từng workload.\n3. Chiến Lược Hiện Đại Hóa Phased approach:\nKhông nên “đập đi làm lại” tất cả cùng lúc. Cần roadmap theo giai đoạn, ưu tiên các hệ thống có tác động lớn.\n7Rs framework:\nCó nhiều con đường để hiện đại hóa (Rehost, Replatform, Refactor, Rearchitect, Repurchase, Retire, Retain).\nMỗi ứng dụng cần được đánh giá riêng.\n“Migrate to Operate”:\nMục tiêu không chỉ là di chuyển lên cloud, mà là vận hành thông minh hơn sau khi di chuyển, liên tục tối ưu chi phí, hiệu năng và bảo mật.\nROI measurement:\nCần đo lường rõ ràng: giảm chi phí, tăng agility, rút ngắn time-to-market, cải thiện trải nghiệm khách hàng.\nỨng Dụng Vào Công Việc Áp dụng DDD cho project hiện tại:\nTổ chức các buổi event storming với team business để mô hình hóa domain và tách bounded contexts.\nRefactor Microservices:\nDùng bounded contexts để xác định ranh giới service, tránh microservices bị “chia vụn” hoặc overlap trách nhiệm.\nImplement Event-driven patterns:\nDần thay thế một số API synchronous bằng cơ chế async messaging, pub/sub, hoặc streaming.\nServerless Adoption:\nThử nghiệm triển khai một số use case bằng AWS Lambda hoặc Fargate để đánh giá lợi ích thực tế.\nKiểm toán độ sẵn sàng dữ liệu:\nTrước khi bắt đầu bất kỳ dự án GenAI nào, cần kiểm tra data quality, data governance và chiến lược dữ liệu tổng thể.\nThử nghiệm GenAI trong DevOps:\nSử dụng các công cụ như Amazon Q Developer để sinh mã, sinh test tự động, rút ngắn chu kỳ phát triển.\nTriển khai “Security by design”:\nÁp dụng các best practices về IAM, encryption, logging, monitoring ngay từ giai đoạn thiết kế hệ thống.\nTrải nghiệm trong sự kiện Tham dự AWS Cloud Day Vietnam – AI Edition 2025 mang lại cho tôi cái nhìn vừa chiến lược, vừa thực tiễn:\nHọc hỏi từ các diễn giả có chuyên môn cao Các bài chia sẻ của lãnh đạo ngân hàng, chuyên gia cloud, kiến trúc sư giải pháp giúp tôi hiểu rõ sự gắn kết giữa chiến lược kinh doanh và hạ tầng kỹ thuật. Những case study thực tế (Techcombank, Honda, Masterise, TymeX…) giúp tôi hình dung rõ ràng hơn về con đường chuyển đổi của từng ngành. Trải nghiệm kỹ thuật thực tế Các phiên về event storming, DDD, microservices, event-driven architecture giúp tôi kết nối kiến thức lý thuyết với kịch bản triển khai thực tế. Tôi đặc biệt ấn tượng với workshop “GenAI-powered App-DB Modernization”, nơi mô phỏng hành trình hiện đại hóa một ứng dụng monolith sang kiến trúc cloud-native. Ứng dụng công cụ hiện đại Lần đầu tiếp cận sâu với Amazon Q Developer trong bối cảnh SDLC thực tế, tôi thấy rõ tiềm năng sử dụng AI để tăng năng suất và giảm lặp lại công việc của developer. Việc tích hợp GenAI vào DevOps cho tôi cái nhìn mới về tương lai phát triển phần mềm. Kết nối và trao đổi Sự kiện là cơ hội tốt để trao đổi với các chuyên gia, anh chị làm trong ngành tài chính, công nghệ, cloud consulting,… Qua các cuộc thảo luận ngắn bên lề, tôi nhận ra rằng chuyển đổi số không chỉ là chuyện kỹ thuật, mà còn là thay đổi cách nghĩ, cách làm việc và văn hóa doanh nghiệp. Bài học rút ra Dữ liệu là yếu tố khác biệt then chốt: GenAI không thể phát huy hiệu quả nếu dữ liệu không được quản trị tốt. Hiện đại hóa là một hành trình liên tục: Không có “đích đến cố định”, mà là quá trình liên tục tối ưu và thích nghi. Bảo mật là việc của mọi người: Từ developer đến vận hành, từ lãnh đạo đến nhân viên, ai cũng phải ý thức về security. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/4-eventparticipated/4.2-event2/",
	"title": "Sự kiện 2",
	"tags": [],
	"description": "",
	"content": "Bài thu hoạch “Khám Phá Agentic AI – Amazon QuickSuite” Thông tin sự kiện Tên sự kiện: GenAI-powered App-DB Modernization workshop Ngày: Ngày 7 tháng 11 năm 2025 Địa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, Thành phố Hồ Chí Minh Vai trò: Người tham dự Mục Đích Của Sự Kiện Làm rõ khái niệm Agentic AI: sự chuyển dịch từ Generative AI thụ động sang AI Tác tử (Agentic) có khả năng hành động tự chủ. Giới thiệu và trình diễn trực tiếp Amazon QuickSuite lần đầu tiên tại Việt Nam. Thúc đẩy doanh nghiệp ứng dụng Agentic AI thông qua chương trình hỗ trợ tài chính AWS LIFT (tín dụng lên đến 80,000 USD). Cung cấp môi trường hands-on thực tế, giúp người tham dự trực tiếp xây dựng và trải nghiệm mô hình AI dưới sự hướng dẫn của chuyên gia AWS và đối tác. Danh Sách Diễn Giả Vivien Nguyen – Territory Manager (Quản lý Vùng), AWS Tung Cao – Solution Architect (Kiến trúc sư Giải pháp), AWS Đội ngũ Cloud Kinetics – Đối tác triển khai chiến lược của AWS tại Việt Nam Nội Dung Nổi Bật Sự thay đổi mô hình: Từ Generative AI đến Agentic AI Generative AI (AI Tạo sinh)\nTập trung vào việc tạo nội dung (văn bản, hình ảnh, mã nguồn,…) theo prompt của người dùng. Mang tính thụ động: chỉ phản hồi khi được hỏi. Agentic AI (AI Tác tử)\nTập trung vào sự tự chủ và khả năng hành động. Có thể nhận thức môi trường, lập kế hoạch, suy luận qua nhiều bước và tự động thực thi nhiệm vụ mà không cần con người can thiệp liên tục. Mục tiêu: xây dựng các hệ thống “AI làm việc thay mình”, chứ không chỉ “trò chuyện với AI”. Workshop giúp tôi hiểu rõ rằng Agentic AI là bước tiến từ “AI trả lời” sang “AI hành động”, rất phù hợp cho các tác vụ phức tạp và lặp lại trong doanh nghiệp.\nGiới thiệu Amazon QuickSuite Lần đầu demo trực tiếp tại Việt Nam:\nWorkshop đánh dấu buổi trình diễn live đầu tiên của Amazon QuickSuite với người dùng tại Việt Nam. Hệ sinh thái hợp nhất:\nKết nối chặt chẽ giữa: Amazon QuickSight – trực quan hóa và phân tích dữ liệu. QuickSuite Q – tương tác bằng ngôn ngữ tự nhiên, đặt câu hỏi và tạo insight. Từ đó hình thành các “Analyst Agents” có thể đọc dữ liệu, trả lời câu hỏi nghiệp vụ và đề xuất hành động. Tốc độ và tính linh hoạt (“Quick”):\nCho phép doanh nghiệp đi từ ý tưởng → prototype → thử nghiệm thực tế trong thời gian ngắn. Phù hợp với đội ngũ muốn thử nghiệm nhanh và cải thiện liên tục. Lấy dữ liệu làm trung tâm:\nQuickSuite được thiết kế cho khối lượng dữ liệu lớn, đảm bảo tác tử AI có đủ “chất liệu” để đưa ra quyết định chính xác và bám sát thực tế kinh doanh. Hệ sinh thái đối tác \u0026amp; hỗ trợ chiến lược AWS cung cấp nền tảng hạ tầng và dịch vụ AI/Analytics. Cloud Kinetics đóng vai trò: Tư vấn kiến trúc, bảo đảm giải pháp phù hợp với đặc thù từng doanh nghiệp. Hỗ trợ triển khai “bước cuối cùng” (last-mile) – biến công nghệ trừu tượng thành giải pháp cụ thể, chạy được trong môi trường thật. Mô hình “hai lớp hỗ trợ” (AWS + đối tác) giúp doanh nghiệp giảm rủi ro, nhất là khi bắt đầu với các công nghệ mới như Agentic AI.\nChương trình AWS LIFT – Hỗ trợ tài chính cho đổi mới Tín dụng lên tới 80,000 USD cho khách hàng đủ điều kiện, đặc biệt là doanh nghiệp mới, SMBs. Mục đích: Giảm rào cản chi phí khi thử nghiệm các hệ thống tính toán hiệu năng cao và các dự án R\u0026amp;D về AI. Cho phép doanh nghiệp tập trung vào ý tưởng và triển khai, thay vì lo lắng quá nhiều về chi phí hạ tầng ban đầu. Những Gì Học Được Tư Duy Thiết Kế Tập trung vào sự tự chủ của hệ thống:\nKhi thiết kế Agentic AI, mục tiêu là xây dựng các tác tử chủ động làm việc thay con người, ví dụ: Tự động tạo báo cáo định kỳ. Giám sát số liệu và gửi cảnh báo. Gợi ý điều chỉnh vận hành (như chuỗi cung ứng). Gắn AI với “nút thắt” vận hành cụ thể:\nKhông xây AI theo phong trào, mà bắt đầu từ những quy trình: Lặp đi lặp lại. Gồm nhiều bước thủ công. Dễ sai sót nếu con người tự làm. Kiến Trúc Kỹ Thuật Tiếp cận theo hệ sinh thái (ecosystem-based):\nMột tác tử hiệu quả cần kết nối với nhiều công cụ: nguồn dữ liệu, BI, API, workflow… Trong bối cảnh này, QuickSuite là “mạch kết nối” giữa: Dữ liệu (data sources, QuickSight). Logic hành động (câu hỏi, rule, kịch bản tác vụ tự động). Sẵn sàng về hạ tầng AWS:\nBước đầu tiên là thiết lập tài khoản AWS, region, quyền truy cập, và các dịch vụ cần thiết. Điều này tạo nền tảng để sau đó có thể dễ dàng bật/tắt, thử nghiệm các dịch vụ mới như QuickSuite, Agentic workflows. Chiến Lược Hiện Đại Hóa \u0026amp; Triển Khai Lợi thế của người đi trước (early adopter):\nNhững doanh nghiệp/nhóm sớm tìm hiểu và làm chủ QuickSuite sẽ có lợi thế về năng suất, tốc độ ra quyết định và khả năng thử nghiệm mô hình kinh doanh mới. Quản lý chi phí thông minh:\nKết hợp tín dụng AWS LIFT với cách tiếp cận PoC nhỏ, rõ ràng mục tiêu. Giúp tăng tốc time-to-market nhưng vẫn giảm thiểu rủi ro tài chính. Ứng Dụng Vào Công Việc Tìm hiểu sâu hơn về QuickSuite:\nKhảo sát cách tích hợp QuickSight + QuickSuite Q vào quy trình phân tích dữ liệu hiện tại. Hướng tới xây dựng các “Analyst Agents” có thể tự động trả lời câu hỏi về KPI, xu hướng, báo cáo. Tận dụng chương trình AWS LIFT:\nXem xét điều kiện và đăng ký tham gia để nhận tín dụng AWS cho các dự án R\u0026amp;D hoặc PoC về AI/Agentic AI. Xác định use case nội bộ phù hợp với Agentic AI:\nRà soát các quy trình lặp lại nhiều bước (báo cáo, giám sát, phân loại yêu cầu…) để xem có thể chuyển hóa thành workflow của một tác tử AI hay không. Hợp tác với đối tác như Cloud Kinetics:\nThay vì tự xây 100% in-house, có thể cùng đối tác thiết kế kiến trúc chuẩn, tránh sai lầm từ đầu, nhất là với hệ thống phức tạp. Trải nghiệm trong event Tham dự workshop “Khám Phá Agentic AI – Amazon QuickSuite” tại Bitexco Financial Tower là một trải nghiệm chuyên nghiệp và nhiều chiều: vừa học lý thuyết, vừa thực hành, vừa kết nối cộng đồng.\nHọc hỏi từ các diễn giả có chuyên môn cao Được nghe trực tiếp chia sẻ từ AWS và Cloud Kinetics về tầm nhìn Agentic AI trong doanh nghiệp. Nội dung cân bằng giữa concept (Agentic AI là gì, vì sao quan trọng) và thực tế triển khai (dùng QuickSuite như thế nào, bắt đầu từ đâu). Trải nghiệm kỹ thuật thực tế Phiên hands-on ~90 phút giúp tôi: Trực tiếp thao tác với QuickSight + QuickSuite Q. Hiểu rõ hơn cách một “tác tử phân tích” có thể đọc dữ liệu và trả lời câu hỏi nghiệp vụ. Sự hỗ trợ “cầm tay chỉ việc” của chuyên gia AWS giúp tôi giải quyết ngay những khó khăn ban đầu khi làm quen với công cụ mới. Kết nối và hệ sinh thái Thời gian networking cho phép trao đổi với: Các anh/chị đang làm trong lĩnh vực cloud, data, AI. Đội ngũ Cloud Kinetics, hiểu rõ hơn vai trò của đối tác trong việc biến nền tảng AWS thành giải pháp cụ thể cho từng ngành. Bài học rút ra Agentic AI là tương lai của vận hành doanh nghiệp:\nSự chuyển dịch từ “trò chuyện với AI” sang “AI thực sự làm việc” sẽ mở ra nhiều mô hình tối ưu hóa mới. Tốc độ là yếu tố then chốt:\nCác công cụ như QuickSuite được thiết kế để triển khai nhanh, nên ai đi sớm sẽ có lợi thế về agility. Nguồn vốn thúc đẩy đổi mới:\nChương trình AWS LIFT cho thấy bài toán không còn chỉ là “chi phí có cho phép không”, mà là “chúng ta có dám và có kịp tận dụng cơ hội hay không”. Tóm lại, workshop đã giúp tôi hiểu rõ hơn về Agentic AI, cách AWS hiện thực hóa nó qua Amazon QuickSuite, và những nguồn lực (công cụ, đối tác, tài chính) mà AWS cung cấp để doanh nghiệp có thể bắt đầu hành trình ứng dụng AI một cách thực tế và bền vững.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": " Cách Salesforce Business Technology sử dụng AWS Direct Connect SiteLink để kết nối toàn cầu đáng tin cậy Bởi Alexandra Huides và Corey Harris Jr – ngày 09 tháng 5 năm 2025, trong chuyên mục AWS Direct Connect SiteLink.\nGiới thiệu Salesforce Business Technology đã sử dụng AWS Direct Connect SiteLink để xây dựng kiến trúc mạng lai toàn cầu, đảm bảo kết nối linh hoạt, hiệu suất cao và đáng tin cậy.\nGiải pháp này giúp Salesforce mở rộng hạ tầng, giảm chi phí vận hành và tăng tốc độ đổi mới trong hành trình hiện đại hóa lên đám mây AWS.\nBài viết được thực hiện với sự hợp tác của Georgi Stoev và Ravi Patel – các chuyên gia kỹ thuật cấp cao tại Salesforce.\nTổng quan Salesforce là đối tác chiến lược của AWS và là công ty hàng đầu thế giới về quản lý quan hệ khách hàng (CRM).\nNhóm Business Technology chịu trách nhiệm xây dựng và vận hành các ứng dụng doanh nghiệp, hỗ trợ các mảng như tài chính, trung tâm dữ liệu, bảo mật, kho dữ liệu, và các máy ảo của Salesforce.\nVới quy mô toàn cầu, Salesforce cần một kiến trúc mạng:\nLinh hoạt và có khả năng mở rộng cao. Giảm thiểu độ trễ và thời gian ngừng hoạt động. Đảm bảo tính bảo mật và độ tin cậy cao. Tuy nhiên, các giải pháp mạng truyền thống dựa trên internet không thể đáp ứng yêu cầu nghiêm ngặt này.\nĐó là lý do AWS Direct Connect SiteLink được lựa chọn — cung cấp kết nối riêng tư, chuyên dụng, bỏ qua internet công cộng, giúp cải thiện bảo mật và độ trễ đáng kể.\nĐiều kiện tiên quyết Trước khi triển khai, nhóm kỹ thuật Salesforce đã nắm rõ các thành phần mạng AWS sau:\nAmazon Virtual Private Cloud (VPC) AWS Transit Gateway AWS Direct Connect Các dịch vụ này là nền tảng cho kiến trúc mạng lai toàn cầu, cho phép kết nối riêng tư và độ trễ thấp giữa nhiều vị trí Direct Connect — mà không cần đi qua các vùng AWS trung gian.\nAWS Direct Connect SiteLink AWS Direct Connect cung cấp kết nối mạng riêng giữa hạ tầng tại chỗ và AWS, giúp tối ưu hiệu năng, độ trễ và độ tin cậy.\nSiteLink là một tính năng mở rộng của Direct Connect, cho phép kết nối trực tiếp giữa các mạng tại chỗ thông qua đường trục mạng toàn cầu của AWS, giúp:\nGửi dữ liệu qua đường dẫn ngắn nhất, không cần qua vùng AWS. Tận dụng mạng AWS toàn cầu để truyền dữ liệu nhanh và an toàn. Thanh toán theo mức sử dụng thực tế, không cần thiết lập kết nối mới. Quy trình hoạt động:\nKết nối mạng tại chỗ đến AWS tại một trong hơn 100 điểm Direct Connect trên toàn cầu. Tạo Virtual Interface (VIF) trên kết nối đó và bật SiteLink. Khi các VIF được gắn vào cùng một Direct Connect Gateway (DXGW), dữ liệu sẽ được truyền trực tiếp giữa các vị trí, sử dụng đường trục AWS. Dấu ấn toàn cầu của Salesforce Business Technology Salesforce Business Technology quản lý 7 địa điểm chiến lược trên toàn cầu:\n3 ở Hoa Kỳ 3 ở Châu Á – Thái Bình Dương 1 ở Châu Âu Mạng được xây dựng trên đường trục riêng MPLS kết hợp với AWS Regions, hỗ trợ các luồng dữ liệu phức tạp giữa trung tâm dữ liệu và môi trường đám mây.\nTuy nhiên, các thách thức nảy sinh gồm:\nCơ sở hạ tầng tĩnh và khó mở rộng. Chi phí vận hành cao và phụ thuộc nhiều nhà cung cấp. Độ phức tạp định tuyến và sự cố kéo dài ở một số khu vực. Hình 1. Một mẫu kết nối trung tâm dữ liệu riêng toàn cầu sử dụng các mạch riêng.\nGiải pháp: SiteLink Để giải quyết vấn đề, Salesforce Business Technology đã hiện đại hóa hạ tầng mạng bằng cách triển khai SiteLink.\nMục tiêu chính:\nXây dựng mạng linh hoạt, có thể mở rộng theo nhu cầu. Giảm chi phí vận hành và độ phức tạp. Tăng khả năng phục hồi và bảo mật. Nhóm đã:\nTriển khai SiteLink trên các kết nối Direct Connect hiện có. Tạo các VIF chuyên dụng mới cho môi trường sản xuất và phát triển. Duy trì phân khúc toàn cầu, đáp ứng yêu cầu lưu trữ dữ liệu tại chỗ. Hình 2. Mẫu triển khai SiteLink toàn cầu cho Sản xuất và Phát triển.\nLợi ích đạt được Giải pháp SiteLink mang lại nhiều lợi ích vượt trội cho Salesforce:\nLợi ích Mô tả Đơn giản hóa quản lý mạng Loại bỏ độ phức tạp của định tuyến MPLS Layer 3 VPN, vẫn duy trì khả năng tách biệt lưu lượng. Cải thiện hiệu suất Tăng ổn định, giảm độ trễ trung bình 15% trên toàn cầu. Tối ưu hóa chi phí Tận dụng kết nối hiện có, thanh toán theo mức sử dụng. Bảo mật nâng cao Áp dụng mã hóa MACSec lớp 2 trên toàn bộ kết nối Direct Connect. Ngoài ra, SiteLink giúp:\nGiảm số điểm hỏng đơn lẻ (SPOF) và tăng độ tin cậy mạng. Tối ưu tuyến đường dữ liệu giữa các trung tâm dữ liệu. Giám sát toàn diện qua CloudWatch Network Monitor. “Với SiteLink, Salesforce Business Technology đã hợp lý hóa các hoạt động mạng và đảm bảo khả năng phục hồi tối đa cho kết nối toàn cầu. Chúng tôi có thể thiết lập kết nối giữa 7 trung tâm dữ liệu chỉ trong vài phút và mở rộng sang thị trường mới trong vài ngày.”\n— Ravi Patel, Giám đốc kỹ thuật cấp cao tại Salesforce.\nKết luận Việc áp dụng AWS Direct Connect SiteLink đã giúp Salesforce:\nThống nhất kiến trúc mạng trên toàn cầu. Hiện đại hóa hạ tầng, giảm chi phí và cải thiện hiệu suất. Chuẩn bị sẵn sàng cho quy mô mở rộng và đổi mới nhanh chóng. Để tìm hiểu thêm về AWS Direct Connect SiteLink, bạn có thể tham khảo tài liệu chính thức hoặc đặt câu hỏi trên AWS re:Post.\nGiới thiệu về các tác giả Alexandra Huides\nKiến trúc sư giải pháp chuyên gia mạng tại AWS.\nTập trung vào kiến trúc mạng quy mô lớn, hỗ trợ khách hàng áp dụng IPv6 và xây dựng môi trường linh hoạt. Ngoài công việc, cô yêu thích chèo thuyền, du lịch và đọc sách.\nCorey Harris Jr.\nKiến trúc sư giải pháp cấp cao tại AWS.\nLà chuyên gia về mạng và serverless, giúp khách hàng tối ưu hệ thống AWS. Ngoài công việc, anh yêu thích game, du lịch và thời gian bên gia đình.\nGeorgi Stoev\nKiến trúc sư kỹ thuật cấp cao tại Salesforce.\nVới hơn 20 năm kinh nghiệm trong lĩnh vực mạng, AI và bảo mật, anh đam mê công nghệ, nghiên cứu ong mật và khám phá thiên nhiên.\nRavi Patel\nGiám đốc kỹ thuật cấp cao tại Salesforce.\nCó hơn 15 năm kinh nghiệm xây dựng mạng linh hoạt và hiệu suất cao. Ngoài công việc, anh thích lướt sóng, leo núi, và phiêu lưu khám phá thế giới.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.2-week2/",
	"title": "Worklog Tuần 2",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 2: Đi sâu vào các dịch vụ AWS, tập trung vào Compute, Networking và Storage. Làm quen với AWS EC2, S3, Lambda và Elastic Beanstalk. Thực hành tạo và quản lý các EC2 instance, làm việc với lưu trữ và triển khai ứng dụng web. Hiểu về AWS IAM để quản lý danh tính và quyền truy cập. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học cơ bản về AWS EC2 + Các loại EC2 instance + Nhóm bảo mật EC2 (Security Group) + Quản lý vòng đời các EC2 instance 15/09/2025 15/09/2025 Tài liệu học tập 3 - Học về AWS S3 + Tạo S3 Bucket + Quản lý object trong S3 + Kiểm soát quyền truy cập (ACL, Bucket policy) 16/09/2025 16/09/2025 Tài liệu học tập 4 - Học về AWS Lambda + Giới thiệu kiến trúc serverless và AWS Lambda + Tạo hàm Lambda đơn giản + Kích hoạt Lambda từ dịch vụ AWS khác 17/09/2025 17/09/2025 Tài liệu học tập 5 - Học về AWS Elastic Beanstalk + Tổng quan Elastic Beanstalk + Triển khai ứng dụng mẫu bằng Elastic Beanstalk 18/09/2025 18/09/2025 Tài liệu học tập 6 - Học về IAM (Identity and Access Management) + Tạo và quản lý IAM User, Group, Role + Gán policy và quản lý quyền truy cập 19/09/2025 19/09/2025 Tài liệu học tập 7 - Thực hành tổng hợp: + Labs cho EC2, S3, Lambda, Elastic Beanstalk + Rà soát lại các bước tạo, cấu hình, deploy 20/09/2025 20/09/2025 Tài liệu học tập Kết quả đạt được tuần 2: Đã tạo và quản lý được các EC2 instance (khởi tạo, dừng/xoá, xem thông tin). Nắm được cách cấu hình và sử dụng AWS S3 để lưu trữ và quản lý object (upload, xem, xoá, phân quyền). Đã tạo và kiểm tra hoạt động của một hàm AWS Lambda đơn giản, biết cách kích hoạt Lambda từ dịch vụ khác. Đã triển khai thành công một ứng dụng mẫu bằng AWS Elastic Beanstalk. Hiểu căn bản về AWS IAM, biết cách: Tạo IAM User, Group, Role Gán IAM Policy để kiểm soát quyền truy cập theo nguyên tắc “least privilege”. Hoàn thành một số bài lab thực hành tổng hợp cho EC2, S3, Lambda và Elastic Beanstalk, giúp củng cố kiến thức lý thuyết đã học. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/2-proposal/",
	"title": "Bản đề xuất",
	"tags": [],
	"description": "",
	"content": "Team Super Beast Warrior(SBW) Batch-based Clickstream Analytics Platform 1. Tóm tắt Dự án này nhằm thiết kế và triển khai Batch-based Clickstream Analytics Platform cho một website thương mại điện tử chuyên về máy tính và phụ kiện (giao diện frontend của website được tích hợp một JavaScript SDK nhẹ để gửi dữ liệu hoạt động của người dùng như clicks, views, searches tới backend API) bằng cách sử dụng AWS Cloud Services. Hệ thống thu thập dữ liệu tương tác của người dùng (như clicks, searches, và page visits) từ website và lưu trữ chúng trong Amazon S3 dưới dạng raw logs. Cứ mỗi giờ, Amazon EventBridge sẽ kích hoạt AWS Lambda để xử lý và chuyển đổi dữ liệu trước khi nạp vào data warehouse được lưu trữ trên Amazon EC2.\nDữ liệu đã được xử lý sẽ được visualize thông qua R Shiny dashboards, giúp chủ cửa hàng có thể theo dõi business insights như hành vi khách hàng, mức độ phổ biến của sản phẩm, và xu hướng tương tác trên website.\nKiến trúc này tập trung vào batch analytics, ETL pipeline, và business intelligence, đồng thời đảm bảo bảo mật (security), khả năng mở rộng (scalability), và hiệu quả chi phí (cost efficiency) thông qua việc tận dụng các AWS managed services.\n2. Vấn đề đặt ra Vấn đề hiện tại là gì? Các website E-commerce tạo ra một lượng lớn clickstream data — bao gồm product views, cart actions, và search activities — chứa đựng nhiều business insights có giá trị.\nTuy nhiên, các cửa hàng small và medium-sized thường thiếu infrastructure và expertise cần thiết để collect, process, và analyze dữ liệu này một cách hiệu quả.\nKết quả là, họ gặp khó khăn trong việc:\nHiểu hành vi mua hàng của khách hàng (customer purchasing behavior) Xác định sản phẩm hoạt động hiệu quả nhất (top-performing products) Tối ưu hóa marketing campaigns và hiệu suất website (website performance) Ra quyết định về tồn kho (inventory) và giá cả (pricing) dựa trên dữ liệu (data-driven decisions) Giải pháp Dự án này giới thiệu một AWS-based batch clickstream analytics system, tự động collect dữ liệu tương tác của người dùng từ website mỗi giờ, process thông qua serverless functions, và lưu trữ vào central data warehouse trên Amazon EC2.\nKết quả được visualize bằng R Shiny dashboards, giúp chủ cửa hàng có được actionable insights về hành vi khách hàng (customer behavior) và cải thiện hiệu suất kinh doanh tổng thể (overall business performance).\nLợi ích và hoàn vốn đầu tư Data-driven decision making: Khám phá sở thích của khách hàng, sản phẩm phổ biến và xu hướng mua sắm. Scalable and modular design: Dễ dàng mở rộng để xử lý nhiều người dùng hơn hoặc tích hợp thêm các nguồn dữ liệu mới. Cost-efficient batch processing: Giảm chi phí tính toán liên tục bằng cách vận hành theo lịch trình hàng giờ. Business insight enablement: Giúp chủ cửa hàng tối ưu hóa chiến lược bán hàng và cải thiện doanh thu dựa trên phân tích có cơ sở dữ liệu. 3. Kiến trúc giải pháp Dịch vụ AWS sử dụng Amazon Cognito: Quản lý quá trình xác thực và phân quyền người dùng cho cả quản trị viên và khách hàng của website, đảm bảo quyền truy cập an toàn vào nền tảng e-commerce. Amazon S3: Hoạt động như một lớp lưu trữ dữ liệu tập trung — lưu trữ giao diện website tĩnh (static website front-end) và các clickstream logs thô được thu thập từ tương tác người dùng. Ngoài ra, nó còn tạm thời lưu trữ các batch files trước khi được xử lý và chuyển đến data warehouse. Amazon CloudFront: Phân phối nội dung website tĩnh trên toàn cầu với độ trễ thấp, cải thiện trải nghiệm người dùng và lưu trữ cache gần khách hàng hơn. Amazon API Gateway: Đóng vai trò là điểm đầu vào chính cho các API calls từ website, cho phép gửi dữ liệu an toàn (như clickstream hoặc browsing activity) vào AWS. AWS Lambda: Thực thi các serverless functions để tiền xử lý và tổ chức clickstream data được tải lên S3. Nó cũng xử lý các tác vụ chuyển đổi dữ liệu được EventBridge kích hoạt theo lịch trước khi nạp vào data warehouse. Amazon EventBridge: Lên lịch và điều phối các batch workflows — ví dụ, kích hoạt Lambda functions mỗi giờ để xử lý và di chuyển clickstream data từ S3 vào EC2 data warehouse. Amazon EC2 (Data Warehouse): Đóng vai trò là môi trường data warehouse, chạy PostgreSQL hoặc các cơ sở dữ liệu quan hệ khác phục vụ cho batch analytics, trend analysis và business reporting. Các instances này được triển khai trong private subnet của VPC để đảm bảo cô lập mạng và an toàn. R Shiny (on EC2): Lưu trữ các dashboards tương tác hiển thị các insights đã được xử lý theo batch, giúp doanh nghiệp phân tích hành vi khách hàng, sản phẩm phổ biến và cơ hội bán hàng. AWS IAM: Quản lý quyền truy cập và chính sách nhằm đảm bảo chỉ những người dùng và thành phần AWS được ủy quyền mới có thể tương tác với dữ liệu và dịch vụ. Amazon CloudWatch: Thu thập và giám sát các metrics, logs, và trạng thái của các scheduled jobs từ Lambda và EC2 để duy trì độ tin cậy và khả năng quan sát hiệu suất hệ thống. Amazon SNS: Gửi thông báo hoặc cảnh báo khi batch jobs hoàn thành, thất bại hoặc gặp lỗi, đảm bảo doanh nghiệp kịp thời nắm bắt tình trạng vận hành. 4. Triển khai End-to-end data flow Auth (Cognito) Trình duyệt xác thực với Amazon Cognito (Hosted UI hoặc JS SDK). ID token (JWT) được lưu trong bộ nhớ; SDK tự động gắn Authorization: Bearer \u0026lt;JWT\u0026gt; cho các API calls. Static web (CloudFront + S3) SPA/assets được lưu trữ trên S3; CloudFront đứng phía trước với OAC, gzip/brotli, HTTP/2, và WAF managed rules. Trang web tải một analytics SDK nhỏ thu thập các events và gửi đến API Gateway (bên dưới). Event ingest (API Gateway) POST /v1/events (HTTP API). CORS bị giới hạn theo site origin; JWT authorizer xác thực Cognito token (hoặc API key cho luồng anonymous). Các request được chuyển tiếp đến Lambda. Security \u0026amp; Ops IAM được cấu hình least-privilege cho từng thành phần. CloudWatch ghi log, metrics và cảnh báo trên API 5xx, Lambda errors, throttles, Shiny health. SNS gửi thông báo khi có alarms hoặc DLQ tăng. Processing \u0026amp; storage (Lambda → S3 batch buffer → EventBridge → Lambda (ETL) → PostgreSQL trên EC2 (data warehouse) → Shiny) Ingest Lambda xác thực và enrich các events, sau đó append-write các NDJSON objects vào S3 (partition theo date/hour). EventBridge (cron) kích hoạt ETL Lambda (batch) theo chu kỳ cố định (ví dụ: mỗi 60 phút). ETL Lambda đọc một phần dữ liệu từ các partitions của S3, loại bỏ trùng lặp, chuyển đổi và upsert vào PostgreSQL trên EC2 (truy cập qua VPC). R Shiny Server (trên EC2) đọc các curated tables và hiển thị dashboards cho admin. Data Contracts \u0026amp; Governance Event JSON (ingest)\n{ \u0026#34;event_id\u0026#34;: \u0026#34;uuid-v4\u0026#34;, \u0026#34;ts\u0026#34;: \u0026#34;2025-10-18T12:34:56.789Z\u0026#34;, \u0026#34;event_type\u0026#34;: \u0026#34;view|click|search|add_to_cart|checkout|purchase\u0026#34;, \u0026#34;session_id\u0026#34;: \u0026#34;uuid-v4\u0026#34;, \u0026#34;user_id\u0026#34;: \u0026#34;cognito-sub-or-null\u0026#34;, \u0026#34;anonymous_id\u0026#34;: \u0026#34;stable-anon-id\u0026#34;, \u0026#34;page_url\u0026#34;: \u0026#34;https://site/p/123\u0026#34;, \u0026#34;referrer\u0026#34;: \u0026#34;https://google.com\u0026#34;, \u0026#34;device\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;mobile|desktop|tablet\u0026#34; }, \u0026#34;geo\u0026#34;: { \u0026#34;country\u0026#34;: \u0026#34;VN\u0026#34;, \u0026#34;city\u0026#34;: null }, \u0026#34;ecom\u0026#34;: { \u0026#34;product_id\u0026#34;: \u0026#34;sku-123\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;Shoes\u0026#34;, \u0026#34;currency\u0026#34;: \u0026#34;USD\u0026#34;, \u0026#34;price\u0026#34;: 79.99, \u0026#34;qty\u0026#34;: 1, }, \u0026#34;props\u0026#34;: { \u0026#34;search_query\u0026#34;: \u0026#34;running shoes\u0026#34; }, } PII: không bao giờ gửi name/email/phone; mọi optional identifier (nếu có) sẽ được hash trong Lambda. Behaviour: tạo anonymous_id một lần, duy trì session_id (tự động roll sau 30 phút không hoạt động); gửi dữ liệu bằng navigator.sendBeacon với fetch retry fallback; tùy chọn offline buffer thông qua IndexedDB. S3 raw layout \u0026amp; retention\nBucket: s3://clickstream-raw/ Object format: NDJSON, tùy chọn GZIP. Partitioning: year=YYYY/month=MM/day=DD/hour=HH/ → events-\u0026lt;uuid\u0026gt;.ndjson.gz Optional manifest per batch: bao gồm processed watermark, object list, record counts, và hash. Lifecycle: raw → (30 days Standard/IA) → (365+ days Glacier/Flex). Idempotency: duy trì một compact staging table trong PostgreSQL (hoặc một small S3 key-value manifest) để theo dõi (track) last processed object/batch và ngăn chặn việc tải trùng (prevent double-load). Frontend SDK (Static site on S3 + CloudFront) Instrumentation\nJS snippet nhỏ được load trên toàn site (defer). Sinh anonymous_id một lần và lưu session_id trong localStorage; session reset sau 30 phút không hoạt động. Gửi events qua navigator.sendBeacon; fallback sang fetch với retry và jitter. Auth context\nNếu người dùng đăng nhập bằng Cognito, bao gồm user_id = idToken.sub để theo dõi funnel đăng nhập. Offline durability\nService Worker queue tùy chọn: khi offline, buffer events trong IndexedDB và gửi lại khi reconnect. Ingestion API (API Gateway → Lambda) API Gateway (HTTP API)\nRoute: POST /v1/events. JWT authorizer (Cognito user pool). Đối với anonymous pre-login events, sử dụng API key với usage-plan và rate limit nghiêm ngặt. WAF: AWS Managed Core + Bot Control; chặn non-site origins bằng strict CORS. Lambda (Node.js or Python)\nValidate theo JSON Schema (ajv/pydantic). Idempotency: cache event_id gần đây trong bộ nhớ (TTL ngắn) + dedupe ở mức batch trong ETL. Enrichment: xác định date/hour, phân tích UA, suy luận country từ CloudFront-Viewer-Country nếu có. Persist: PutObject vào đường dẫn S3 .../year=YYYY/month=MM/day=DD/hour=HH/.... Failure path: publish vào SQS DLQ; cảnh báo qua SNS nếu DLQ depth \u0026gt; 0. Batch Buffer (S3) Mục đích: buffer bền vững, chi phí thấp cho batch analytics. Write pattern: các object nhỏ mỗi request hoặc micro-batches (1–5 MB) với GZIP. Optional compactor gộp thành file ≥64MB để đọc hiệu quả hơn. Read pattern: ETL Lambda chỉ quét các partitions/objects mới kể từ watermark cuối. Schema-on-read: ETL áp dụng schema, xử lý dữ liệu đến trễ bằng cách reprocess một sliding window nhỏ (ví dụ: 2 giờ cuối) để điều chỉnh sessions. EC2 “data warehouse” node Mục đích: chạy ETL và lưu trữ analytical store được Shiny truy vấn. Hai lựa chọn:\nPostgres trên EC2 (khuyến nghị nếu nhóm quen SQL/window functions)\nInstance: t3.small/t4g.small; gp3 50–100GB. Schema: fact_events, fact_sessions, dim_date, dim_product. Security: trong private subnet của VPC; truy cập qua ALB/SSM Session Manager; snapshot tự động hàng ngày lên S3. ETL (Lambda, batch qua EventBridge cron):\nTrigger: rate(5 minutes) / cron(\u0026hellip;) tùy theo cost \u0026amp; freshness. Các bước: liệt kê S3 objects mới → đọc → validate/dedupe → transform (flatten JSON, cast types, thêm ingest_date, session_window_start/end) → upsert vào Postgres bằng COPY tới bảng tạm + merge, hoặc batched INSERT \u0026hellip; ON CONFLICT. Networking: Lambda kết nối vào private subnets của VPC để truy cập Postgres security group trên EC2. R Shiny Server on EC2 (admin analytics) Server\nEC2 (t3.small/t4g.small) với: R 4.4+, Shiny Server (open-source), Nginx reverse proxy, TLS qua ACM/ALB hoặc Let’s Encrypt. IAM instance profile (không dùng static keys). Security group chỉ cho phép HTTPS từ office/VPN hoặc Cognito-gated admin site. App (packages)\nCác package R sử dụng: shiny, shinydashboard/bslib, plotly, DT, dplyr, DBI + RPostgres hoặc duckdb, lubridate. Nếu truy vấn DynamoDB trực tiếp cho các small cards, có thể sử dụng paws.dynamodb (tùy chọn). Dashboards\nTraffic \u0026amp; Engagement: DAU/MAU, sessions, avg pages, bounce proxy. Funnels: view → add_to_cart → checkout → purchase với tỷ lệ chuyển đổi từng stage (stage conversion) và drop-off. Product Performance: views, CTR, ATC rate, revenue theo product/category. Acquisition: referrer, campaign, device, country. Reliability: Lambda error rate, DLQ depth, ETL lag, data freshness. Caching\nKết quả truy vấn được cache trong process (reactive values) hoặc materialized bởi ETL; cache keys dựa trên date range và filters. Security baseline IAM\nIngest Lambda: quyền s3:PutObject tới raw bucket (giới hạn theo prefix), s3:ListBucket trên các prefix cần thiết. ETL Lambda: quyền s3:GetObject/ListBucket trên raw prefixes; được phép lấy secrets từ SSM Parameter Store; không có quyền S3 rộng. EC2 roles: chỉ đọc/ghi vào DB/volumes của chính nó; có thể đọc từ S3 để backup. Shiny EC2: không ghi vào S3 raw; chỉ read-only tới Postgres khi cần. Network\nĐặt EC2 trong private subnets; truy cập công khai qua ALB (HTTPS 443). Lambda thực hiện ETL được join vào VPC để kết nối tới Postgres; Security Group (SG) áp dụng least-privilege (chỉ mở Postgres port từ ETL SG). Không mở rộng 0.0.0.0/0 tới các DB ports. Data\nMã hóa: EBS bằng KMS, S3 server-side encryption, RDS/PG TLS, secrets lưu trong SSM Parameter Store. Dữ liệu nhạy cảm: không có PII trong events; retention: raw S3 90–365 ngày (lifecycle), curated Postgres theo chính sách kinh doanh. Observability \u0026amp; alerting CloudWatch metrics/alarms\nAPI Gateway 5xx/latency, Lambda (ingest) errors/throttles, S3 PutObject failures, EventBridge schedule success rate, ETL duration/lag, DLQ depth, Shiny health check. SNS topics: gửi thông báo on-call qua email/SMS/Slack webhook. Structured logs: JSON logs từ Lambda \u0026amp; ETL (bao gồm request_id, event_type, status, ms, error_code). Watermark tracking: custom metric “DW Freshness (minutes since last successful upsert)”.\nCost Controls (stay near Free/low tier) HTTP API được sử dụng (chi phí thấp hơn), Lambda memory tối thiểu (256–512MB), nén requests. Batch thay vì realtime: dùng S3 làm buffer để loại bỏ chi phí ghi/đọc DynamoDB. S3 lifecycle: Standard → Standard-IA/Intelligent-Tiering → Glacier cho dữ liệu raw cũ; bật GZIP để giảm chi phí lưu trữ và truyền tải. Điều chỉnh cadence ETL (ví dụ: 15–60 phút) và chỉ xử lý các object mới; gộp các file nhỏ thành file lớn để giảm read I/O. Single small EC2 cho Shiny + DW ban đầu; sau đó scale vertically hoặc tách riêng khi cần. AWS Budgets với SNS alerts cho chi phí thực tế và dự báo. Deliverables Analytics SDK (TypeScript): hỗ trợ sessionization, beacon, và optional offline queue. API/Lambda (ingest): xử lý validation, enrichment, idempotency hints, và DLQ. S3 raw bucket spec: prefixing/partitioning, compression, lifecycle, kèm optional compactor. ETL Lambda (batch): kết hợp với EventBridge cron, watermarking, và upsert strategy vào PostgreSQL PostgreSQL schema: fact_events, fact_sessions, các dims, cùng indexes và vacuum/maintenance plan. R Shiny dashboard app: gồm 5 modules, triển khai với Nginx/ALB TLS setup. Runbook: bao gồm alarms, on-call, backups, disaster recovery, freshness SLO, và cost guardrails. 5. Kế hoạch triển khai Dự án theo tiến độ Tháng 1 – Học tập \u0026amp; Chuẩn bị Nghiên cứu nhiều dịch vụ AWS bao gồm compute, storage, analytics và security.\nHiểu các khái niệm chính của cloud architecture, data pipelines và serverless computing.\nTổ chức các cuộc họp nhóm để thống nhất mục tiêu dự án và phân công trách nhiệm cho từng thành viên.\nTháng 2 – Thiết kế kiến trúc \u0026amp; Prototyping Thiết kế kiến trúc tổng thể của dự án và xác định luồng dữ liệu giữa các thành phần.\nThiết lập các tài nguyên AWS ban đầu như S3, Lambda, API Gateway, EventBridge và EC2.\nThử nghiệm các công cụ mã nguồn mở cho việc visualization và reporting.\nKiểm thử mã mẫu và xác thực quy trình data ingestion và processing pipeline.\nTháng 3 – Triển khai \u0026amp; Kiểm thử Triển khai toàn bộ kiến trúc dựa trên bản thiết kế đã được phê duyệt.\nTích hợp tất cả các dịch vụ AWS và đảm bảo độ tin cậy của hệ thống.\nThực hiện kiểm thử hiệu năng và chức năng.\nHoàn thiện tài liệu và chuẩn bị dự án cho buổi thuyết trình.\n6. Ước tính chi phí Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng AWS Services\nAmazon Cognito (User Pools): 0.10 USD/tháng(1 monthly active user (MAU), 1 MAU đăng nhập qua SAML hoặc OIDC federation)\nAmazon S3\nS3 Standard: 0.17 USD/tháng (6 GB, 1,000 PUT requests, 1,000 GET requests, 6 GB Data returned, 6 GB Data scanned) Data Transfer: 0.00 USD/tháng (Outbound 6 TB, Inbound 6 TB) Amazon CloudFront (United States): 0.64 USD/tháng(6 GB Data transfer out to internet, 6 GB Data transfer out to origin, 10,000 HTTPS requests)\nAmazon API Gateway (HTTP APIs): 0.01 USD/tháng(10,000 HTTP API requests units)\nAmazon Lambda (Service settings): 0.00 USD/tháng(1,000,000 requests, 512 MB memory)\nAmazon CloudWatch (APIs): 0.03 USD/tháng(100 metrics GetMetricData, 1,000 metrics GetMetricWidgetImage, 1,000 API requests)\nAmazon SNS (Service settings): 0.02 USD/tháng(1,000,000 requests, 100,000 HTTP/HTTPS Notifications, 1,000 EMAIL/EMAIL-JSON Notifications, 100,000,000 QS Notifications, 100,000,000 Lambda deliveries, 100,000 Kinesis Data Firehose notifications)\nAmazon EC2 (EC2 specifications): 1.68 USD/tháng(1 instance, 730 Compute Savings Plans)\nAmazon EventBridge: 0.00 USD/tháng(1,000,000 events (AWS management events - EventBridge Event Bus Ingestion))\nTổng cộng: 2.65 USD/tháng, 31.8 USD/12 tháng\n7. Đánh giá rủi ro Risk Likelihood Impact Mitigation Strategy Chi phí cao vượt quá ngân sách ước tính Medium High Theo dõi chặt chẽ và tính toán tất cả các chi phí tiềm năng trên AWS. Giới hạn việc sử dụng các dịch vụ AWS có chi phí cao và thay thế bằng các giải pháp đơn giản, tiết kiệm chi phí nhưng cung cấp chức năng tương tự. Các vấn đề tiềm ẩn trong việc truyền dữ liệu hoặc tích hợp dịch vụ giữa các thành phần AWS Medium Medium Thực hiện step-by-step validation trước khi triển khai chính thức. Thử nghiệm sớm, sử dụng các managed AWS services, và liên tục giám sát hiệu suất thông qua Amazon CloudWatch. Rủi ro trong thu thập hoặc xử lý dữ liệu (ví dụ: tương tác người dùng quá mức, mạng không ổn định, thiếu hoặc trùng lặp sự kiện) High Medium Áp dụng data validation, temporary buffering, và schema enforcement để đảm bảo tính nhất quán. Sử dụng structured logging và alarms để phát hiện và xử lý lỗi khi ingest dữ liệu. Người dùng ít hoặc không sử dụng analytics dashboard Low High Tổ chức các buổi internal training và tận dụng các communication channels hiện có để nâng cao nhận thức. Khuyến khích việc sử dụng bằng cách trình bày các practical benefits và actionable insights của hệ thống. 8. Kết quả kỳ vọng Hiểu Hành Vi và Hành Trình Khách Hàng Hệ thống ghi lại toàn bộ hành trình khách hàng — bao gồm các trang mà người dùng truy cập, sản phẩm mà họ xem, thời gian họ ở lại, và điểm họ rời khỏi trang web.\nBằng cách phân tích session duration, bounce rate, và navigation paths, doanh nghiệp có thể đánh giá mức độ tương tác của người dùng và trải nghiệm tổng thể.\nĐiều này cung cấp nền tảng dữ liệu đáng tin cậy để cải thiện giao diện website, tối ưu bố cục trang, và nâng cao overall customer satisfaction.\nXác Định Sản Phẩm Phổ Biến và Xu Hướng Người Tiêu Dùng Dựa trên clickstream data được thu thập và xử lý trên AWS, hệ thống xác định các sản phẩm được xem nhiều nhất và mua nhiều nhất.\nCác sản phẩm ít được chú ý cũng được theo dõi, cho phép doanh nghiệp đánh giá hiệu quả của product listings, điều chỉnh giá cả hoặc hình ảnh sản phẩm, và lập kế hoạch tồn kho hiệu quả hơn.\nHơn nữa, hệ thống hỗ trợ phát hiện shopping trends theo khoảng thời gian, khu vực, hoặc loại thiết bị — giúp đưa ra quyết định kinh doanh kịp thời và dựa trên dữ liệu.\nTối Ưu Chiến Lược Marketing và Bán Hàng Dữ liệu hành vi của khách hàng được transform (chuyển đổi) thành business insights (thông tin kinh doanh chuyên sâu) và được trình bày thông qua R Shiny dashboards.\nVới các kết quả phân tích này, doanh nghiệp có thể:\nXác định chính xác target customer segments cho các nỗ lực marketing Tùy chỉnh các chiến dịch quảng cáo và khuyến mãi cho các nhóm sản phẩm hoặc đối tượng khách hàng cụ thể Đánh giá hiệu quả của các sáng kiến marketing thông qua các chỉ số tương tác và chuyển đổi có thể đo lường Kết quả là, marketing and sales strategies trở nên dựa trên bằng chứng và chính xác hơn, hỗ trợ ra quyết định tốt hơn và cải thiện hiệu suất kinh doanh.\nFile TEMPLETE DOCX: TẢI Proposal (DOCX) "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": " Giải pháp Nhà máy điện thông minh của TCS trên AWS giúp các tiện ích tối ưu hóa hoạt động và thúc đẩy chuyển đổi năng lượng như thế nào Bởi Alakh Srivastava, Rajesh Natesan, Siva Thangavel và Yogesh Chaturvedi – ngày 19 tháng 3 năm 2025, trong chuyên mục Amazon DocumentDB, Amazon ECS, Amazon S3, AWS IoT Core, AWS Step Functions, Năng lượng (Dầu khí), Industries.\nTổng quan về giải pháp Các công nghệ kỹ thuật số tiên tiến đang cách mạng hóa ngành năng lượng, cho phép các tổ chức đạt được các mục tiêu bền vững đồng thời giảm chi phí và khí thải carbon.\nTheo McKinsey, chuyển đổi kỹ thuật số trong lĩnh vực năng lượng có thể mở ra 1,6 nghìn tỷ USD giá trị vào năm 2035, giúp giảm 20–30% chi phí vận hành và 5% lượng khí thải carbon.\nKhi ngành công nghiệp tiến tới mô hình phát điện phân tán tích hợp năng lượng tái tạo, các doanh nghiệp cần những giải pháp thông minh như lưới điện số, AI điều phối năng lượng, và nền tảng giám sát thời gian thực.\nGiải pháp Nhà máy điện thông minh (Smart Power Plant) của TCS ra đời để đáp ứng điều đó — mang lại hiệu suất tăng 0,5%, giảm 8% NOx, và cải thiện 8–10% độ chính xác dự báo phát điện tái tạo.\nĐược xây dựng trên nền tảng AWS, giải pháp này tận dụng sức mạnh của AI/ML để xử lý dữ liệu thời gian thực từ hàng nghìn cảm biến năng lượng trên nhiều địa điểm.\nBài viết này trình bày cách TCS và AWS cùng hợp tác mang lại hiệu quả vận hành vượt trội và kết quả kinh doanh bền vững cho ngành năng lượng.\nKiến trúc giải pháp và luồng dữ liệu Kiến trúc của giải pháp được thiết kế theo luồng dữ liệu khép kín, tận dụng các dịch vụ AWS để quản lý, xử lý và phân tích thông tin một cách toàn diện.\nHình 1. Kiến trúc tổng thể của giải pháp Nhà máy điện thông minh trên AWS.\nNhập dữ liệu: Thu thập dữ liệu từ OPC-UA (thiết bị công nghiệp), hệ thống lịch sử tại chỗ và hồ dữ liệu Amazon S3.\nMỗi tổ máy có thể gửi tới 4.000 giá trị cảm biến mỗi phút. Tiếp nhận và điều phối: AWS IoT Core tiếp nhận luồng dữ liệu và kích hoạt AWS Step Functions để điều phối tự động. Xử lý dữ liệu: Các AWS Lambda functions thực hiện làm sạch, tính toán KPI và tạo cảnh báo. Lưu trữ: Amazon DocumentDB lưu dữ liệu có cấu trúc (KPI, cảnh báo), Amazon S3 lưu dữ liệu cảm biến thô và kết quả huấn luyện. Đào tạo mô hình ML: Thực hiện trong Amazon SageMaker, mô hình được lưu trong Amazon Elastic Container Registry (ECR). Suy luận thời gian thực: Mô hình được triển khai qua Amazon ECS cho TCS InTwin (engine phân tích online). Triển khai ứng dụng: Giao diện front-end/back-end chạy container trên Amazon ECS đảm bảo mở rộng linh hoạt. Các chức năng chính Giải pháp Nhà máy điện thông minh của TCS mang đến bốn khả năng cốt lõi giúp thay đổi cách các nhà máy vận hành:\nHình 2. Bốn năng lực cốt lõi của giải pháp.\nBản sao kỹ thuật số AI tự học (Self-learning Digital Twin):\nKết hợp dữ liệu thực và mô hình AI vật lý để liên tục thích nghi với điều kiện hoạt động, đảm bảo dự đoán chính xác và tiết kiệm chi phí.\nGiải pháp mở và có thể mở rộng:\nCó thể tích hợp với hệ thống nhà máy hiện có hoặc mô hình AI riêng, kiến trúc mở và có khả năng giải thích.\nBàn làm việc kỹ thuật số low-code:\nCho phép tạo và quản lý mô hình AI nhanh chóng, hỗ trợ tạo KPI, FMEA và các use case cụ thể.\nNền tảng dựng sẵn:\nCác mô-đun có thể cấu hình sẵn cho từng nhà máy, giúp rút ngắn thời gian triển khai và mở rộng quy mô dễ dàng.\nCác trường hợp sử dụng thực tế Dự báo phát điện mặt trời Sử dụng mô hình ML và phân tích nâng cao để dự đoán sản lượng năng lượng tái tạo.\nTại một trang trại gió ngoài khơi ở Anh, độ chính xác dự báo tăng 15,1%, doanh thu tăng 6%.\nTối ưu hóa quá trình đốt cháy trong sản xuất nhiệt Tại một nhà máy Nhật Bản, AI giúp cải thiện 0,5% hiệu suất, giảm 8% NOx, tiết kiệm 2,5 triệu USD/năm.\nBảo trì dự đoán linh kiện tuabin khí Tại một nhà máy Úc, mô hình dự đoán hỏng hóc trước 8–12 tháng, giảm 20% chi phí bảo trì và thời gian ngừng hoạt động.\nLợi ích kinh doanh Giải pháp của TCS giúp doanh nghiệp năng lượng:\nLợi ích Tác động Giảm chi phí vận hành Cắt giảm tới 20% chi phí bảo trì và vận hành. Dự đoán hỏng hóc chính xác Độ chính xác dự báo lỗi lên đến 85%. Tối ưu hóa KPI và giảm khí thải Cải thiện hiệu suất đồng thời giảm phát thải carbon. Hỗ trợ lực lượng lao động AI hỗ trợ ra quyết định, giảm phụ thuộc vào kinh nghiệm cá nhân. Ngoài ra, việc tích hợp AWS giúp loại bỏ các silo dữ liệu, nâng cao năng suất và tạo nền tảng chuẩn hóa cho các nhà máy điện trong tương lai.\nKết luận Giải pháp Nhà máy điện thông minh TCS trên AWS đang định hình tương lai bền vững của ngành năng lượng.\nThông qua AI và phân tích nâng cao, nền tảng này giúp tối ưu hiệu suất, bảo trì dự đoán, và tích hợp liền mạch năng lượng tái tạo.\nTCS – với chuyên môn sâu và đội ngũ chuyên gia được AWS chứng nhận – đã chứng minh khả năng triển khai thành công trên nhiều loại hình nhà máy, từ nhiệt điện truyền thống đến năng lượng tái tạo quy mô lớn.\nĐể tìm hiểu thêm, hãy xem bài đăng gốc của TCS về Giải pháp Nhà máy điện thông minh trên AWS.\nGiới thiệu về các tác giả Alakh Srivastava\nGiám đốc sản phẩm toàn cầu – Thực hành Nhà máy điện thông minh, TCS.\nHơn 20 năm kinh nghiệm trong chuyển đổi kỹ thuật số ngành điện, chuyên về năng lượng tái tạo, AI và IoT công nghiệp.\nRajesh Natesan\nTrưởng nhóm Kỹ thuật chính – Nhóm Nhà máy điện thông minh, TCS.\n20 năm kinh nghiệm trong IoT, AI/ML và kiến trúc hệ thống năng lượng quy mô lớn.\nSiva Thangavel\nKiến trúc sư giải pháp đối tác tại AWS.\nCung cấp giải pháp kiến trúc tối ưu cho đối tác và khách hàng doanh nghiệp trong nhiều ngành công nghiệp.\nYogesh Chaturvedi\nKiến trúc sư giải pháp chính tại AWS – lĩnh vực Năng lượng và Tiện ích.\nTập trung giúp khách hàng giải quyết thách thức bằng công nghệ đám mây. Ngoài công việc, anh yêu thích đi bộ đường dài, du lịch và thể thao.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.3-week3/",
	"title": "Worklog Tuần 3",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 3: Tập trung vào Networking trong AWS, đặc biệt là VPC và Route 53. Thiết lập mạng an toàn và cấu hình tên miền trong AWS. Học về Security Groups, NACLs và VPN. Thực hành labs cho các dịch vụ mạng và cấu hình bảo mật. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học về AWS VPC (Virtual Private Cloud) + Tổng quan về VPC + Tạo VPC, Subnet, Route Table 22/09/2025 22/09/2025 Tài liệu học tập 3 - Học về Amazon Route 53 + Quản lý tên miền với Route 53 + Cài đặt và quản lý bản ghi DNS 23/09/2025 23/09/2025 Tài liệu học tập 4 - Học về Security Groups và NACLs (Network ACL) + Cấu hình Security Group cho EC2 + Cấu hình NACL cho subnet 24/09/2025 24/09/2025 Tài liệu học tập 5 - Học về VPN trong AWS + Khái niệm Site-to-Site VPN + Tạo và cấu hình Site-to-Site VPN, routing lưu lượng 25/09/2025 25/09/2025 Tài liệu học tập 6 - Thực hành labs tổng hợp: + VPC, Route 53, VPN, Security Groups và NACLs + Kiểm tra lại cấu hình bảo mật và kết nối mạng giữa các tài nguyên 26/09/2025 26/09/2025 Tài liệu học tập Kết quả đạt được tuần 3: Đã tạo và cấu hình được một VPC với các subnet, route table và internet gateway. Cài đặt Route 53 để quản lý tên miền và các bản ghi DNS cơ bản (A, CNAME, …). Cấu hình Security Groups và NACLs để kiểm soát lưu lượng vào/ra ở mức instance và subnet. Thiết lập Site-to-Site VPN phục vụ kết nối an toàn giữa mạng on-premises (giả lập) và VPC trên AWS. Hoàn thành các bài lab thực hành về Networking và Security trên AWS, củng cố hiểu biết về kiến trúc mạng và các lớp bảo mật trong AWS. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/3-blogstranslated/",
	"title": "Các bài blogs đã dịch",
	"tags": [],
	"description": "",
	"content": "Blog 1 - Cách iFood xây dựng nền tảng để chạy hàng trăm mô hình machine learning với Amazon SageMaker Inference Blog này giới thiệu cách iFood sử dụng Amazon SageMaker Inference để vận hành hàng trăm mô hình machine learning trên quy mô lớn. Bài viết trình bày cách iFood tự động hóa quy trình huấn luyện, triển khai và giám sát mô hình, đồng thời tối ưu chi phí và hiệu suất với các tính năng như zero-scale endpoints và multi-model GPU serving.\nBlog 2 - Cách Salesforce Business Technology sử dụng AWS Direct Connect SiteLink để kết nối toàn cầu đáng tin cậy Blog này mô tả cách Salesforce Business Technology triển khai AWS Direct Connect SiteLink để xây dựng kiến trúc mạng toàn cầu đáng tin cậy. Bài viết chia sẻ cách SiteLink giúp Salesforce hợp nhất mạng giữa bảy địa điểm, giảm độ trễ, tăng cường bảo mật và đơn giản hóa vận hành bằng cách tận dụng AWS global backbone.\nBlog 3 - Giải pháp Nhà máy điện thông minh của TCS trên AWS giúp các tiện ích tối ưu hóa hoạt động và thúc đẩy chuyển đổi năng lượng như thế nào Blog này giới thiệu cách Tata Consultancy Services (TCS) triển khai Smart Power Plant trên AWS, giúp các công ty năng lượng tối ưu hiệu suất, giảm khí thải và thúc đẩy chuyển đổi năng lượng bền vững. Giải pháp sử dụng AI/ML, IoT và digital twin để phân tích dữ liệu theo thời gian thực, dự đoán sự cố và tối ưu quá trình phát điện. Bài viết cũng trình bày các trường hợp sử dụng thực tế như dự báo năng lượng tái tạo, tối ưu quá trình đốt cháy và bảo trì dự đoán, mang lại hiệu quả kinh tế và giảm phát thải carbon.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.4-week4/",
	"title": "Worklog Tuần 4",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 4: Hiểu về các dịch vụ cơ sở dữ liệu trên AWS (RDS, DynamoDB). Học cách triển khai và quản lý các instance cơ sở dữ liệu. Tìm hiểu về sao lưu, khôi phục, mở rộng quy mô và tối ưu hóa hiệu suất cơ sở dữ liệu. Thực hành labs với RDS và DynamoDB. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học về AWS RDS + Tạo một RDS instance + Sao lưu và bảo trì RDS 29/09/2025 29/09/2025 Tài liệu học tập 3 - Học về Amazon DynamoDB + Giới thiệu về DynamoDB + Làm việc với bảng và dữ liệu 30/09/2025 30/09/2025 Tài liệu học tập 4 - Tìm hiểu cơ chế sao lưu (backup) và khôi phục dữ liệu (restore) trong RDS 01/10/2025 01/10/2025 Tài liệu học tập 5 - Tìm hiểu về tối ưu hóa hiệu suất cơ sở dữ liệu trong AWS (RDS \u0026amp; DynamoDB) 02/10/2025 02/10/2025 Tài liệu học tập 6 - Thực hành labs cho RDS và DynamoDB + Tạo / sửa / xóa database, bảng, dữ liệu + Test backup \u0026amp; restore 03/10/2025 03/10/2025 Tài liệu học tập Kết quả đạt được tuần 4: Đã triển khai và cấu hình được các RDS instance (tạo, chỉnh sửa, dừng/xoá). Làm quen với DynamoDB và thực hành thao tác với bảng, item, và truy vấn dữ liệu. Hiểu cơ chế sao lưu tự động và thủ công trong RDS, cũng như quy trình khôi phục dữ liệu. Nắm được một số nguyên tắc cơ bản để tối ưu hiệu suất cơ sở dữ liệu trên AWS (chọn instance type, storage, IOPS, index…). Hoàn thành các lab thực hành với RDS và DynamoDB, củng cố kiến thức về database trên AWS. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/4-eventparticipated/",
	"title": "Các events đã tham gia",
	"tags": [],
	"description": "",
	"content": "Sự kiện 1 Tên sự kiện: Vietnam Cloud Day 2025\nThời gian tổ chức: 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Bến Nghé, Quận 1, Thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nMô tả ngắn gọn nội dung và hoạt động chính trong sự kiện:\nVietnam Cloud Day là sự kiện thường niên do AWS tổ chức, quy tụ chuyên gia, doanh nghiệp và cộng đồng công nghệ để chia sẻ về các xu hướng mới trong điện toán đám mây, AI, dữ liệu lớn và bảo mật.\nChương trình bao gồm các phiên thảo luận chiến lược, các track chuyên sâu theo ngành (FSI, viễn thông, bán lẻ, bất động sản…), các phiên chia sẻ về kiến trúc hiện đại (microservices, event-driven, serverless) và trình bày case study thực tế từ Techcombank, Honda, Masterise, TymeX,… tạo cái nhìn toàn diện về hành trình hiện đại hóa trên nền tảng AWS.\nKết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án):\n- Hiểu rõ hơn vai trò của Cloud \u0026amp; GenAI trong chiến lược chuyển đổi số quốc gia và trong các ngành trọng điểm.\n- Nắm bắt các mô hình kiến trúc hiện đại như DDD, microservices, event-driven, serverless và cách lựa chọn dịch vụ compute phù hợp (EC2, ECS, Fargate, Lambda).\n- Nhận thức sâu hơn về tầm quan trọng của chiến lược dữ liệu, bảo mật “security by design” và tư duy “migrate to operate” thay vì chỉ “lift-and-shift”.\n- Hình thành nhiều ý tưởng áp dụng vào dự án học tập/cá nhân (ví dụ: thiết kế hệ thống trên AWS, tích hợp Amazon Q Developer vào quy trình DevOps) và mở rộng network với cộng đồng kỹ sư Cloud.\nSự kiện 2 Tên sự kiện: GenAI-powered App-DB Modernization workshop\nThời gian tổ chức: 07/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, Thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nMô tả ngắn gọn nội dung và hoạt động chính trong sự kiện:\nWorkshop tập trung vào chủ đề Agentic AI và hệ sinh thái Amazon QuickSuite, làm rõ sự khác biệt giữa Generative AI truyền thống và Agentic AI có khả năng hành động tự chủ.\nNgười tham dự được giới thiệu lần đầu về QuickSuite tại Việt Nam, bao gồm sự kết hợp giữa Amazon QuickSight và QuickSuite Q để xây dựng các “Analyst Agents” có thể đọc dữ liệu, trả lời câu hỏi nghiệp vụ và đề xuất hành động phù hợp.\nChương trình cũng giới thiệu gói hỗ trợ tài chính AWS LIFT (tín dụng lên tới 80.000 USD) nhằm giảm rào cản chi phí khi thử nghiệm các giải pháp AI/Agentic AI.\nPhần hands-on kéo dài khoảng 90 phút giúp người tham dự trực tiếp thao tác với QuickSight + QuickSuite Q dưới sự hướng dẫn của chuyên gia AWS và đối tác Cloud Kinetics, đồng thời có cơ hội trao đổi, networking với cộng đồng làm về cloud, data và AI.\nKết quả hoặc giá trị đạt được (bài học, kỹ năng mới, đóng góp cho nhóm/dự án):\n- Hiểu rõ hơn khái niệm Agentic AI, sự chuyển dịch từ “AI chỉ trả lời” sang “AI thực sự làm việc thay con người” và các kịch bản ứng dụng trong doanh nghiệp.\n- Nắm được các thành phần chính của Amazon QuickSuite, cách kết hợp QuickSight và QuickSuite Q để xây dựng các tác tử phân tích dữ liệu (analyst agents).\n- Nhận thức được vai trò của chương trình AWS LIFT trong việc hỗ trợ tài chính cho các PoC/R\u0026amp;D về AI, từ đó có thể đề xuất áp dụng cho các dự án trong tương lai.\n- Cải thiện kỹ năng thiết kế use case cho Agentic AI (lựa chọn các quy trình lặp lại, nhiều bước, dựa trên dữ liệu) và hình thành thêm ý tưởng áp dụng vào học tập/dự án như tự động báo cáo, giám sát chỉ số hoặc gợi ý tối ưu vận hành.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.5-week5/",
	"title": "Worklog Tuần 5",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 5: Học về AWS CloudWatch để giám sát và quản lý các dịch vụ AWS. Tìm hiểu về AWS CloudTrail và AWS Config để theo dõi và quản lý thay đổi trong môi trường AWS. Thực hành cấu hình và giám sát tài nguyên trên AWS. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học về AWS CloudWatch + Cấu hình và giám sát tài nguyên AWS với CloudWatch + Tạo cảnh báo (Alarms) và biểu đồ (Dashboards) 06/10/2025 06/10/2025 Tài liệu học tập 3 - Học về AWS CloudTrail + Giám sát hành động và sự kiện của người dùng trên AWS + Phân tích log sự kiện CloudTrail 07/10/2025 07/10/2025 Tài liệu học tập 4 - Học về AWS Config + Theo dõi thay đổi cấu hình và lịch sử tài nguyên AWS 08/10/2025 08/10/2025 Tài liệu học tập 5 - Thực hành cấu hình và giám sát với CloudWatch + Tạo CloudWatch Alarm + Giám sát EC2 và các tài nguyên khác qua metric \u0026amp; log 09/10/2025 09/10/2025 Tài liệu học tập 6 - Thực hành với CloudTrail và AWS Config + Phân tích sự kiện CloudTrail + Quản lý thay đổi cấu hình với AWS Config 10/10/2025 10/10/2025 Tài liệu học tập Kết quả đạt được tuần 5: Đã cấu hình và giám sát các tài nguyên AWS sử dụng AWS CloudWatch (EC2, RDS, …). Tạo được các cảnh báo (alarms) và biểu đồ (dashboards) để theo dõi hiệu suất và trạng thái hệ thống. Hiểu cách sử dụng AWS CloudTrail để theo dõi các sự kiện và hành động của người dùng trong tài khoản AWS. Sử dụng AWS Config để theo dõi và quản lý các thay đổi cấu hình tài nguyên AWS theo thời gian. Củng cố kiến thức về giám sát, logging và audit trong môi trường AWS, phục vụ cho việc vận hành hệ thống an toàn và ổn định. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Batch-Based Clickstream Analytics Platform Figure: Architecture Batch-base Clickstream Analytics Platform.\nTổng quan Workshop này triển khai một nền tảng phân tích Clickstream theo kiểu batch (Batch-Based Clickstream Analytics Platform) cho một website thương mại điện tử bán sản phẩm máy tính.\nHệ thống thu thập các sự kiện (events) clickstream từ frontend, lưu dữ liệu JSON thô trong Amazon S3, xử lý events theo lịch ETL định kỳ (AWS Lambda + EventBridge), và nạp dữ liệu phân tích vào một PostgreSQL Data Warehouse trên EC2 nằm trong private subnet.\nCác dashboard phân tích được xây dựng bằng R Shiny, chạy trên cùng EC2 với Data Warehouse, và được truy cập thông qua AWS Systems Manager Session Manager.\nNền tảng được thiết kế với các tiêu chí:\nTách biệt rõ ràng giữa workload OLTP và Analytics Backend analytics chỉ chạy trong private subnet (không có truy cập public vào DW) Sử dụng các thành phần serverless của AWS để tối ưu chi phí và khả năng mở rộng Quản trị qua SSM Session Manager vào EC2 chạy DW / Shiny Có thể chạy web Shiny bằng localhost:3838 Các thành phần kiến trúc chính Miền Frontend \u0026amp; OLTP\nỨng dụng Next.js: ClickSteam.NextJS được host bằng AWS Amplify Hosting Amazon CloudFront được tích hợp trong Amplify giúp tăng tốc độ truyền tải file tĩnh Amazon Cognito User Pool để xác thực người dùng PostgreSQL OLTP chạy trên EC2: SBW_EC2_WebDB (public subnet) Database: clickstream_web (schema public) Port: 5432 Miền Ingestion \u0026amp; Data Lake\nAmazon API Gateway (HTTP API): clickstream-http-api Route: POST /clickstream Lambda Ingest: clickstream-lambda-ingest Validate payload, enrich metadata, ghi file JSON vào S3 S3 Raw Clickstream Bucket: clickstream-s3-ingest Prefix: events/YYYY/MM/DD/ Mẫu tên file: event-\u0026lt;uuid\u0026gt;.json RAW_BUCKET = clickstream-s3-ingest Miền Analytics \u0026amp; Data Warehouse\nEC2 private cho DWH + Shiny: SBW_EC2_ShinyDWH (private subnet 10.0.128.0/20)\nDatabase DW: clickstream_dw Bảng chính: clickstream_events với các field: event_id, event_timestamp, event_name user_id, user_login_state, identity_source, client_id, session_id, is_first_visit context_product_id, context_product_name, context_product_category, context_product_brand context_product_price, context_product_discount_price, context_product_url_path R Shiny Server chạy trên port 3838, web path /sbw_dashboard Lambda ETL: SBW_Lamda_ETL (chạy trong VPC)\nĐọc JSON thô từ clickstream-s3-ingest Transform thành các dòng dữ liệu dạng SQL-ready Insert vào bảng clickstream_dw.public.clickstream_events EventBridge Rule: SBW_ETL_HOURLY_RULE\nLịch chạy: rate(1 hour) VPC \u0026amp; Networking\nVPC CIDR: 10.0.0.0/16 Public subnet: 10.0.0.0/20 → SBW_Project-subnet-public1-ap-southeast-1a (EC2 OLTP) Private subnet: 10.0.128.0/20 → SBW_Project-subnet-private1-ap-southeast-1a (DW, Shiny, ETL Lambda) S3 Gateway VPC Endpoint để truy cập S3 trong private network SSM Interface Endpoints (SSM, SSMMessages, EC2Messages) cho Session Manager Truy cập quản trị (SSM)\nPort forwarding: localPort = 3838 portNumber = 3838 Shiny URL khi truy cập từ local: http://localhost:3838/sbw_dashboard Bản đồ nội dung 5.1. Mục tiêu \u0026amp; Phạm vi 5.2. Giới thiệu kiến trúc 5.3. Triển khai hệ thống thu thập Clickstream 5.4. Xây dựng lớp phân tích dữ liệu private 5.5. Trực quan hóa phân tích với Shiny Dashboards 5.6. Tổng kết \u0026amp; Dọn dẹp "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.6-week6/",
	"title": "Worklog Tuần 6",
	"tags": [],
	"description": "",
	"content": " Mục tiêu tuần 6: Tìm hiểu về AWS Auto Scaling và Elastic Load Balancing (ELB) để đảm bảo ứng dụng có thể mở rộng và phân phối tải hiệu quả. Học về AWS Elastic Container Service (ECS) và AWS Fargate. Thực hành triển khai ứng dụng container trên ECS và sử dụng Auto Scaling để tự động điều chỉnh tài nguyên. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học về AWS Auto Scaling + Cấu hình Auto Scaling cho EC2 + Thiết lập chính sách mở rộng (scale-out) và thu hẹp (scale-in) 13/10/2025 13/10/2025 Tài liệu học tập 3 - Học về Elastic Load Balancer (ELB) + Cấu hình và sử dụng ELB để phân phối tải giữa các EC2 instance / service 14/10/2025 14/10/2025 Tài liệu học tập 4 - Học về AWS ECS và AWS Fargate + Giới thiệu kiến trúc ECS, Task, Service + Giới thiệu Fargate và mô hình chạy container không quản lý server 15/10/2025 15/10/2025 Tài liệu học tập 5 - Thực hành triển khai ứng dụng trên ECS \u0026amp; Fargate + Triển khai ứng dụng container đơn giản trên ECS + Sử dụng Fargate để chạy container 16/10/2025 16/10/2025 Tài liệu học tập 6 - Thực hành với Auto Scaling và ELB cho ứng dụng trên ECS + Cấu hình Auto Scaling cho ECS Service + Tích hợp với ELB để phân phối tải 17/10/2025 17/10/2025 Tài liệu học tập Kết quả đạt được tuần 6: Đã cấu hình AWS Auto Scaling và Elastic Load Balancing cho ứng dụng chạy trên EC2 / ECS. Làm quen với AWS ECS và AWS Fargate, hiểu cách tổ chức Cluster – Task – Service. Thực hành triển khai ứng dụng container trên ECS, sử dụng Fargate để chạy container mà không cần quản lý máy chủ. Hiểu cách kết hợp ELB + Auto Scaling + ECS để xây dựng hệ thống có khả năng tự động mở rộng, phân phối tải và vận hành ổn định. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/6-self-evaluation/",
	"title": "Tự đánh giá",
	"tags": [],
	"description": "",
	"content": "Trong suốt thời gian thực tập tại Amazon Web Services (AWS) từ 08/09/2025 đến 05/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng những kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi tham gia vào dự án Batch-based Clickstream Analytics Platform cho một website thương mại điện tử bán sản phẩm máy tính., với các nhiệm vụ chính như:\nTìm hiểu và triển khai các dịch vụ AWS như Amazon S3, AWS Lambda, Amazon EventBridge, Amazon EC2, AWS Amplify, Amazon Cognito để phục vụ bài toán thu thập và xử lý dữ liệu clickstream.\nHỗ trợ xây dựng pipeline thu thập, lưu trữ và xử lý dữ liệu clickstream theo mô hình batch, trong đó dữ liệu hành vi người dùng trên website được ghi nhận, đưa vào S3 và xử lý định kỳ bằng Lambda/EventBridge trước khi nạp vào hệ thống phân tích.\nTham gia cấu hình hạ tầng trên AWS, kết nối với cơ sở dữ liệu PostgreSQL/Supabase và tích hợp với ứng dụng frontend (Next.js) của website thương mại điện tử.\nViết tài liệu kỹ thuật, báo cáo tiến độ và trao đổi thường xuyên với mentor/team để cập nhật tình hình và thống nhất hướng triển khai.\nThông qua đó, tôi cải thiện rõ rệt các kỹ năng về lập trình, thiết kế hệ thống, làm việc với dịch vụ cloud, xây dựng pipeline xử lý dữ liệu batch, viết báo cáo, làm việc nhóm và giao tiếp trong môi trường chuyên nghiệp.\nVề tác phong, tôi luôn cố gắng hoàn thành nhiệm vụ được giao, tuân thủ quy trình làm việc của team và chủ động trao đổi khi gặp khó khăn để đảm bảo chất lượng công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ☐ ✅ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ☐ ✅ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ☐ ✅ ☐ Cần cải thiện Nâng cao tính kỷ luật và kỹ năng quản lý thời gian, chấp hành nghiêm túc nội quy, deadline trong mọi môi trường làm việc. Rèn luyện thêm tư duy giải quyết vấn đề, đặc biệt là kỹ năng phân tích nguyên nhân gốc rễ và so sánh nhiều phương án trước khi lựa chọn giải pháp. Cải thiện kỹ năng giao tiếp: trình bày ngắn gọn, rõ ràng hơn trong các buổi họp, chủ động chia sẻ khó khăn/thắc mắc với mentor và các thành viên trong nhóm. Nhìn chung, tôi đánh giá kỳ thực tập tại AWS là một trải nghiệm rất ý nghĩa, giúp tôi trưởng thành hơn cả về chuyên môn lẫn tác phong làm việc, đồng thời nhận ra những điểm cần tiếp tục rèn luyện trong chặng đường sắp tới.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/7-feedback/",
	"title": "Chia sẻ, đóng góp ý kiến",
	"tags": [],
	"description": "",
	"content": "Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc tại AWS rất chuyên nghiệp nhưng vẫn thân thiện và cởi mở. Mọi người luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, giải đáp khi mình chưa hiểu, nên mình cảm thấy khá thoải mái khi trao đổi và đặt câu hỏi. Không khí làm việc nghiêm túc nhưng không quá áp lực, giúp mình tập trung tốt hơn và tự tin hơn khi tham gia vào dự án thực tế.\n2. Sự hỗ trợ của mentor / team admin\nCác anh mentor trong team luôn hỗ trợ rất nhiệt tình, từ việc giải thích kiến thức liên quan đến AWS đến cách làm việc trong một team kỹ thuật chuyên nghiệp. Khi mình gặp vấn đề, mọi người không chỉ đưa ra lời giải mà còn hướng dẫn cách tư duy, để mình có thể tự tìm hướng xử lý. Nhờ vậy, mình chủ động hơn và học được nhiều kinh nghiệm thực tế.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nMình đang học ngành Kỹ thuật phần mềm, và công việc thực tập là tham gia dự án clickstream cùng team, kết nối/tích hợp các dịch vụ AWS vào hệ thống, nên mình thấy khá phù hợp với chuyên ngành. Công việc giúp mình áp dụng được kiến thức nền tảng về lập trình, hệ thống và kiến trúc phần mềm, đồng thời cho mình cơ hội tiếp cận với môi trường cloud thực tế. Nhờ đó, mình vừa củng cố kiến thức, vừa hiểu rõ hơn mình muốn theo đuổi hướng nào trong tương lai.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình có cơ hội trau dồi thêm kiến thức chuyên môn và cách tham gia vào một dự án thực tế. Bên cạnh đó, mình cũng cải thiện được kỹ năng làm việc nhóm và kỹ năng giao tiếp trong môi trường chuyên nghiệp, biết cách tiếp nhận và phản hồi ý kiến một cách tích cực hơn.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa làm việc tại AWS rất tích cực: mọi người tôn trọng lẫn nhau, sẵn sàng chia sẻ và hỗ trợ khi cần. Trong team, mọi người phối hợp với nhau khá nhịp nhàng, cùng trao đổi khi có vấn đề kỹ thuật và cùng cố gắng để hoàn thành mục tiêu chung của dự án. Điều này giúp mình, dù là thực tập sinh, vẫn cảm thấy mình được tin tưởng và là một phần của team.\n6. Chính sách / phúc lợi cho thực tập sinh\nNgoài môi trường và công việc thực tế, mình còn có cơ hội tham gia khoảng 4–5 buổi event do AWS tổ chức, nơi chia sẻ thêm về kiến thức, công nghệ và các chủ đề liên quan đến ngành. Đây là những hoạt động rất hữu ích, giúp mình mở rộng góc nhìn, cập nhật xu hướng mới và kết nối với nhiều anh/chị trong lĩnh vực. Điều này khiến trải nghiệm thực tập trở nên phong phú và ý nghĩa hơn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\nMình rất hài lòng với môi trường làm việc thân thiện, được anh/chị và mentor hỗ trợ nhiệt tình, được giao các nhiệm vụ mang tính thực tế giúp mình vừa học vừa làm và tự tin hơn trong công việc. Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau?\nHiện tại trải nghiệm thực tập của mình rất tốt, quy trình làm việc rõ ràng và luôn được hỗ trợ khi cần. Nếu có thể, công ty có thể tổ chức thêm một số buổi giao lưu, chia sẻ kinh nghiệm hoặc team bonding nhỏ để các bạn thực tập và các team có thêm cơ hội kết nối, trao đổi với nhau. Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao?\nCó. Mình sẽ khuyên bạn bè thực tập ở đây vì môi trường thân thiện, mọi người sẵn sàng chỉ dẫn, mentor hướng dẫn tận tình và công việc giúp tích lũy kinh nghiệm thực tế chứ không chỉ mang tính thủ tục. Điều này rất hữu ích cho định hướng nghề nghiệp sau này. Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập?\nHiện tại mình cảm thấy trải nghiệm thực tập đã rất tốt. Công ty đã có 3–4 buổi chia sẻ kiến thức, điều đó giúp mình học được rất nhiều. Nếu được, mình chỉ mong công ty duy trì đều đặn các buổi chia sẻ như vậy để mọi người có thêm cơ hội giao lưu và học hỏi lẫn nhau. Bạn có muốn tiếp tục chương trình này trong tương lai?\nCó. Nếu có cơ hội, mình rất muốn tiếp tục tham gia các dự án hoặc chương trình khác của công ty để tiếp tục học hỏi, rèn luyện kỹ năng và gắn bó lâu dài hơn. Góp ý khác (tự do chia sẻ):\nMình chưa có góp ý gì thêm, chỉ muốn gửi lời cảm ơn đến công ty và anh/chị trong team vì đã luôn hỗ trợ, động viên và tạo điều kiện cho mình trong suốt thời gian thực tập. Đây là một trải nghiệm ý nghĩa, giúp mình trưởng thành hơn cả về chuyên môn lẫn thái độ làm việc. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.7-week7/",
	"title": "Worklog Tuần 7",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 7: Nắm tổng quan dự án Batch-based Clickstream Analytics \u0026amp; sessionization. Xác định mục tiêu, vấn đề cần giải quyết và phương pháp tiếp cận của dự án. Tìm hiểu các dịch vụ AWS phù hợp cho kiến trúc clickstream. Phác thảo kiến trúc hệ thống và ước tính chi phí triển khai cơ bản. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Họp online kick-off với các thành viên trong nhóm FCJ - Giới thiệu tổng quan dự án: sessionization \u0026amp; clickstream cho website thương mại điện tử - Thống nhất phạm vi, mục tiêu, sản phẩm cuối (web + pipeline phân tích) 20/10/2025 20/10/2025 3 - Tìm hiểu lý thuyết về clickstream và sessionization: khái niệm, ý nghĩa, các chỉ số thường dùng - Tham khảo một số kiến trúc tham chiếu clickstream trên AWS - Ghi lại yêu cầu chức năng \u0026amp; phi chức năng liên quan đến dữ liệu, bảo mật, hiệu năng 21/10/2025 21/10/2025 4 - Họp online cả nhóm để liệt kê những dịch vụ AWS có thể sử dụng trong dự án: Amplify, CloudFront, S3, API Gateway, Lambda, EventBridge, EC2, RDS/EC2 DW, Cognito, IAM, CloudWatch, SNS,… - Phân tích vai trò từng dịch vụ trong kiến trúc (frontend, ingest, storage, ETL, analytics, monitoring) 22/10/2025 22/10/2025 5 - Bắt đầu thiết kế kiến trúc tổng thể: + Vẽ luồng dữ liệu - Cả nhóm review sơ bộ kiến trúc qua cuộc họp online 23/10/2025 23/10/2025 6 - Hoàn thiện bản architecture diagram phiên bản 1 24/10/2025 24/10/2025 Kết quả đạt được tuần 7: Cả nhóm đã hiểu rõ tổng quan dự án:\nBài toán thu thập \u0026amp; phân tích dữ liệu clickstream cho website bán máy tính \u0026amp; thiết bị điện tử. Nhu cầu sessionization để nhóm các hành vi của người dùng theo phiên truy cập. Xác định được mục tiêu \u0026amp; vấn đề cần giải quyết:\nXây dựng pipeline batch-based clickstream từ frontend → lưu trữ → ETL → phân tích. Tận dụng các dịch vụ managed của AWS để giảm chi phí vận hành và tăng khả năng mở rộng. Đã có bản vẽ kiến trúc phiên bản 1 cho toàn hệ thống và thống nhất trong nhóm qua các buổi họp online.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.8-week8/",
	"title": "Worklog Tuần 8",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 8: Gặp mặt offline lần đầu, thống nhất cách làm việc trực tiếp trong nhóm. Hoàn thiện proposal trên Git/GitPages, cấu hình hiển thị nội dung cho dễ tra cứu. Bắt đầu nghiên cứu Amazon Cognito, S3, ORM và tiến hành build web thương mại điện tử từ template sẵn có. Chuẩn bị cho giai đoạn tiếp theo: tạo dữ liệu, nghiên cứu CloudFront, Amplify, LocalStack, chuẩn hóa môi trường làm việc. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Offline meeting: gặp mặt team lần đầu - Kiểm tra lại proposal, sửa các lỗi nhỏ trong nội dung - Đẩy proposal lên Git/GitPages - Phân chia các đầu việc cho giai đoạn tiếp theo của dự án 27/10/2025 27/10/2025 3 - Họp online: cùng nhau nghiên cứu Amazon Cognito \u0026amp; S3 - Bắt đầu build web thương mại điện tử bằng template frontend sẵn từ Git - Quyết định không sử dụng backend riêng, tập trung vào kiến trúc clickstream trên AWS 28/10/2025 28/10/2025 4 - Tự học thêm về ORM trong template frontend: + Cách mapping dữ liệu, định nghĩa models + Cách migrate dữ liệu - Ghi chú lại để sau này kết nối với database thật (phục vụ phần Data Warehouse / OLTP) 29/10/2025 29/10/2025 5 - Họp nhóm: xác nhận web đã build xong bản đầu tiên chạy trên local - Thảo luận bước tiếp theo: tạo data mô phỏng, nghiên cứu CloudFront, Amplify, LocalStack - Thống nhất chuẩn hóa môi trường Python \u0026amp; thư viện phục vụ ETL/analytics 30/10/2025 30/10/2025 6 - Cá nhân: Web khi build xong còn nhiều lỗi - Nhận ý kiến của team về lỗi UI Web rồi sửa lại 31/10/2025 31/10/2025 Kết quả đạt được tuần 8: Lần đầu gặp mặt offline, không khí làm việc nhóm thoải mái hơn, trao đổi trực tiếp nhanh và hiệu quả hơn. Proposal của dự án đã được: Rà soát và chỉnh sửa một số lỗi nhỏ về nội dung. Đưa lên Git/GitPages, giúp cả nhóm dễ dàng truy cập và tham khảo khi làm việc. Web thương mại điện tử: Đã build được bản đầu tiên chạy trên local dựa trên template sẵn có nhưng còn sai sót về UI. Bước đầu hiểu được cấu trúc code và cách ORM hoạt động trong project frontend. Cả team đã bắt đầu làm quen và thảo luận nhiều hơn về: Cognito, S3, CloudFront, Amplify, LocalStack và định hướng sử dụng cho các phần tiếp theo của kiến trúc. Tạo tiền đề để sang các tuần sau tập trung vào tích hợp dịch vụ AWS vào web và xây dựng pipeline clickstream hoàn chỉnh. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.9-week9/",
	"title": "Worklog Tuần 9",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 9: Rà soát lại hướng triển khai CloudFront, Amplify và thống nhất cách sử dụng LocalStack. Điều chỉnh kiến trúc hệ thống cho phù hợp với thiết kế mới (Amplify, Supabase/PostgreSQL, LocalStack,…). Tiếp tục hoàn thiện giao diện web (UI) và xử lý các lỗi còn tồn tại. Bắt đầu làm quen với Docker để đóng gói môi trường phát triển. Chuẩn bị template báo cáo (docx) và định hình cách đưa nội dung lên Hugo. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Cá nhân: sửa lại UI web theo feedback của team (layout, màu sắc, lỗi hiển thị) - Tiếp tục tìm hiểu về S3, Cognito, CloudFront, Amplify, LocalStack để nắm rõ hơn vai trò của từng dịch vụ trong kiến trúc - Kiểm tra lại web sau khi sửa UI để đảm bảo không phát sinh lỗi mới 03/11/2025 06/11/2025 3 - Họp nhóm: xem lại phương án dùng CloudFront \u0026amp; Amplify trong kiến trúc - Thống nhất sử dụng LocalStack bản Base để mô phỏng nhiều dịch vụ (đặc biệt là Cognito) - Chỉnh lại luồng kiến trúc tương ứng với việc dùng Supabase/PostgreSQL làm database cho web 09/11/2025 10/11/2025 4 - Họp: tìm hiểu cách sử dụng Docker (image, container, cài thư viện vào image) - Đề xuất ý tưởng dùng Docker + LocalStack làm môi trường phát triển chuẩn cho cả nhóm 11/11/2025 11/11/2025 5 - Họp nhóm: chỉnh sửa và chốt architecture diagram v9 - Cá nhân: hoàn thiện file docx template (các phần worklog, workshop, mô tả kiến trúc) - Chia nhỏ các phần nội dung, phân công người phụ trách và đặt deadline rõ ràng cho từng phần 12/11/2025 13/11/2025 Kết quả đạt được tuần 9: Giao diện web (UI) đã được rà soát và cải thiện:\nSửa một số lỗi hiển thị, căn lề, màu sắc theo góp ý của team. Web ổn định hơn trên local, sẵn sàng cho việc tích hợp thêm các dịch vụ AWS. Nhóm đã hiểu rõ hơn vai trò các dịch vụ AWS trong kiến trúc:\nTiếp tục tìm hiểu và thống nhất cách dùng S3, Cognito, CloudFront, Amplify, LocalStack. Quyết định chọn LocalStack bản Base để giả lập nhiều dịch vụ (đặc biệt là Cognito) trong môi trường dev. Chốt hướng dùng Supabase/PostgreSQL làm database cho web. Kiến trúc hệ thống được cập nhật lên phiên bản v9:\nĐiều chỉnh lại luồng dữ liệu phù hợp với Amplify, Supabase và LocalStack. Danh sách các service chính trong mô hình đã được thống nhất, giúp nhóm có “khung” rõ ràng để triển khai. Bước đầu làm quen với Docker:\nNắm được khái niệm image, container và cách cài thư viện vào image. Đặt nền tảng cho việc dùng Docker + LocalStack làm môi trường phát triển chuẩn cho cả nhóm. Template báo cáo (docx) đã có bản phác thảo và phân chia công việc:\nHoàn thiện khung cho các phần: worklog, workshop, mô tả kiến trúc. Chia nhỏ nội dung, phân công người phụ trách và đặt deadline rõ ràng, giúp việc viết báo cáo sau này dễ dàng và nhất quán hơn. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.10-week10/",
	"title": "Worklog Tuần 10",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 10: Kiểm tra lại template báo cáo (docx) và rà soát cấu trúc nội dung. Chạy và nghiên cứu lại dự án web thương mại điện tử, kiểm tra độ ổn định. Làm quen và thực hành với Docker và LocalStack. Deploy web lên Vercel, xử lý các lỗi build, chuẩn bị bước chuyển từ Clerk sang Cognito. Hoàn tất bước chuẩn bị cho môi trường LocalStack Pro + Terraform + Amplify + Cognito + PostgreSQL trên EC2 + S3 theo kiến trúc đề ra. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Kiểm tra lại template docx (bố cục, mục lục, phần worklog/workshop) - Chạy lại và nghiên cứu cấu trúc dự án web thương mại điện tử - Kiểm tra website bán hàng đã ổn định chưa (load trang, điều hướng, tương tác cơ bản) - Bắt đầu làm quen với LocalStack - Kích hoạt GitHub Student - Học cách sử dụng Docker + LocalStack ở mức cơ bản 21/11/2025 21/11/2025 3 - Test web sàn thương mại điện tử: + Kiểm tra các chức năng cơ bản (xem thông tin, thêm giỏ, tiến hành mua,…) - Thử dùng Clerk để đăng nhập, lấy user id về database nhưng không phù hợp yêu cầu → thống nhất chuyển sang Cognito - Deploy web lên Vercel: fix nhiều lỗi build (next.config.ts, package.json, ESLint, env) cho đến khi deploy thành công, lưu được user id vào database (user pool) 23/11/2025 24/11/2025 4 - Họp online: học và thực hành LocalStack Pro + Cấu hình API Key cho LocalStack Pro + Chạy docker image LocalStack + Apply Terraform vào LocalStack theo đúng kiến trúc - Terraform: chỉnh sửa file TF cho khớp với diagram, kích hoạt CloudFront trong Amplify - Amplify: nghiên cứu cách đưa project NextJS vào Amplify - Cognito: thử nghiệm implement Cognito trong môi trường Amplify local - Web data: chuẩn bị kế hoạch deploy PostgreSQL lên EC2 (subnet 1) và đẩy file ảnh mẫu lên S3 24/11/2025 24/11/2025 Kết quả đạt được tuần 10: Template báo cáo (docx):\nĐã được kiểm tra lại về bố cục và nội dung chính (worklog, workshop, mô tả dự án). Giúp nhóm có một khung tài liệu rõ ràng hơn để sử dụng cho các tuần sau. Dự án web thương mại điện tử:\nĐã chạy lại và kiểm tra độ ổn định, các chức năng cơ bản hoạt động đúng (xem sản phẩm, thêm vào giỏ, tiến hành mua,…). Từ việc thử dùng Clerk và nhận ra không phù hợp, nhóm thống nhất chuyển sang Cognito để đồng bộ với kiến trúc AWS. Deploy web lên Vercel:\nGặp nhiều lỗi build (next.config.ts, package.json, trùng file cấu hình, lỗi ESLint, env) nhưng đã xử lý lần lượt. Sau 4 lần thất bại, lần thứ 5 deploy thành công, web chạy ổn định trên Vercel và lưu được user id vào database thông qua user pool. Docker \u0026amp; LocalStack Pro:\nCác thành viên đã làm quen với Docker (image, container, cách cài thư viện vào image). Cấu hình thành công LocalStack Pro: set API key, chạy được docker image, apply Terraform vào LocalStack. Đây là bước quan trọng để chuẩn hóa môi trường dev cho toàn nhóm. Hạ tầng theo kiến trúc mục tiêu:\nTerraform được chỉnh sửa để khớp với sơ đồ kiến trúc và kích hoạt CloudFront trong Amplify. Đã bắt đầu nghiên cứu cách đưa NextJS vào Amplify, implement Cognito trong môi trường Amplify local. Chuẩn bị kế hoạch cho phần web data: PostgreSQL trên EC2 (subnet 1) và upload file ảnh lên S3, làm nền tảng cho các tuần triển khai tiếp theo. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.11-week11/",
	"title": "Worklog Tuần 11",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 11: Triển khai ứng dụng web thương mại điện tử lên AWS Amplify trên môi trường AWS thật. Tích hợp Amazon Cognito vào web để quản lý đăng nhập/người dùng. Thiết lập S3 để lưu trữ hình ảnh và cấu hình web sử dụng hình ảnh từ S3. Chuyển data từ Supabase sang EC2 và sử dụng EC2 làm nguồn dữ liệu chính. Hoàn thiện bước tạo và cấu hình các dịch vụ AWS cloud cốt lõi theo kiến trúc đã đề ra. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Online meeting: triển khai ứng dụng web lên AWS Amplify trên môi trường AWS thật - Tích hợp Cognito vào web - Bắt đầu tạo các AWS Cloud services cần thiết theo kiến trúc (Amplify app, Cognito user pool, S3 bucket, EC2, …) 01/12/2025 03/12/2025 3 - Hoàn tất việc tích hợp Cognito vào web và xác nhận login hoạt động - Deploy thành công web lên Amplify (build \u0026amp; hosting ổn định) - Tạo S3 bucket, upload hình ảnh sản phẩm và cấu hình web đọc hình ảnh trực tiếp từ S3 03/12/2025 04/12/2025 4 - Chuyển dữ liệu từ Supabase sang database trên EC2 (import/export, migrate schema \u0026amp; data) - Cấu hình lại ứng dụng web để sử dụng EC2 làm nguồn dữ liệu chính thay cho Supabase - Kiểm tra nhanh các chức năng chính sau khi đổi nguồn data 04/12/2025 04/12/2025 Kết quả đạt được tuần 11: Web thương mại điện tử đã được:\nDeploy thành công lên AWS Amplify trên môi trường AWS thật. Build \u0026amp; hosting ổn định, có thể truy cập và test trực tiếp trên Amplify. Cognito:\nĐã được tích hợp vào web, hỗ trợ đăng nhập/người dùng theo đúng hướng kiến trúc AWS. Luồng đăng nhập cơ bản hoạt động, sẵn sàng cho các bước mở rộng sau này (phân quyền, bảo mật,…). S3 \u0026amp; media:\nTạo S3 bucket và upload hình ảnh sản phẩm lên S3. Cấu hình lại web để sử dụng hình ảnh từ S3, tách biệt phần media khỏi source code. Data layer (Supabase → EC2):\nDữ liệu đã được chuyển từ Supabase sang EC2. Ứng dụng web đã được cấu hình lại để sử dụng database trên EC2 làm nguồn dữ liệu chính. Kiểm tra nhanh các chức năng chính sau khi đổi data cho thấy hệ thống vẫn hoạt động ổn. Dịch vụ AWS cloud cốt lõi:\nHoàn thành bước đầu tạo và cấu hình các dịch vụ quan trọng: Amplify, Cognito, S3, EC2, … theo đúng định hướng kiến trúc. Tạo nền tảng vững chắc để các tuần sau tập trung vào phần clickstream, ETL và analytics. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/1-worklog/1.12-week12/",
	"title": "Worklog Tuần 12",
	"tags": [],
	"description": "",
	"content": "Mục tiêu tuần 12: Hoàn thành dự án và kiểm thử lại hệ thống. Đảm bảo luồng xử lý chạy end-to-end ổn định (web → data → phân tích). Hoàn thiện và tổng hợp Worklog các tuần trước. Hỗ trợ bạn trong nhóm rà soát Worklog và chỉnh sửa slide thuyết trình cho buổi báo cáo cuối. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Họp hoàn thành các phần còn lại của dự án + Kiểm tra lại các tính năng chính trên web + Test lại luồng xử lý dữ liệu và các biểu đồ phân tích - Hỗ trợ bạn trong nhóm: góp ý, chỉnh sửa Worklog và slide thuyết trình (bố cục, nội dung, điểm nhấn) 07/12/2025 08/12/2025 3 - Bắt đầu viết Worklog: tổng hợp lại các hoạt động chính theo từng tuần - Ghi chú các mốc quan trọng, thay đổi kiến trúc, dịch vụ AWS sử dụng 08/12/2025 09/12/2025 4 - Hoàn thiện bản Worklog cá nhân 09/12/2025 09/12/2025 Kết quả đạt được tuần 12: Dự án đã được hoàn thành và kiểm thử lại:\nCác chức năng chính trên web hoạt động ổn định sau khi test. Luồng xử lý dữ liệu được kiểm tra end-to-end, đảm bảo hệ thống sẵn sàng cho phần demo/báo cáo. Worklog cá nhân:\nĐã tổng hợp và hoàn thiện Worklog , ghi rõ công việc, mốc thời gian và kết quả. Các điểm nổi bật (thay đổi kiến trúc, triển khai dịch vụ AWS, khắc phục lỗi, hoàn thiện dashboard) được note lại để phục vụ cho phần báo cáo và tự đánh giá. Hỗ trợ nhóm:\nĐã hỗ trợ bạn trong nhóm rà soát và chỉnh sửa Worklog, giúp nội dung nhất quán hơn giữa các thành viên. Góp ý và điều chỉnh slide thuyết trình, đảm bảo câu chuyện dự án mạch lạc từ kiến trúc → triển khai → kiểm thử → bài học rút ra. Tuần 12 đánh dấu thời điểm kết thúc dự án, mọi phần chính đã hoàn thiện và nhóm sẵn sàng cho buổi trình bày/đánh giá cuối cùng.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/5-workshop/5.1-objectives--scope/",
	"title": "Mục tiêu &amp; Phạm vi",
	"tags": [],
	"description": "",
	"content": "Bối cảnh kinh doanh Hệ thống mục tiêu là một website e-commerce bán laptop, màn hình và phụ kiện.\nBusiness muốn:\nHiểu cách người dùng tương tác với website: Họ truy cập những trang nào Xem sản phẩm nào Các sự kiện add-to-cart, checkout Đo lường conversion funnel từ product view → add to cart → checkout Xác định: Sản phẩm top (bán chạy / được xem nhiều) Khung giờ hoạt động cao điểm (theo giờ, theo ngày) Giúp sử dụng chiến lược marketing phù hợp nhất để tăng doanh thu, tiết kiệm chi phí Để đạt được điều đó, nền tảng:\nThu thập bộ dữ liệu hành vi người dùng bằng clickstream, sau đó đưa ra thống kê và phân tích Mục tiêu học tập Hiểu kiến trúc Giải thích được kiến trúc tổng thể của một batch-based clickstream analytics platform sử dụng: Amplify, CloudFront, Cognito, EC2 OLTP ở miền user-facing API Gateway, Lambda Ingest, S3 Raw bucket ở miền ingestion \u0026amp; data lake ETL Lambda, PostgreSQL DW trên EC2, R Shiny ở miền analytics \u0026amp; DW Giải thích được vì sao OLTP và Analytics được tách: Logic: khác schema, khác loại workload Physical: public subnet vs private subnet, 2 EC2 khác nhau Kỹ năng thực hành Gửi clickstream events từ frontend vào API Gateway → Lambda Ingest → S3 Raw (clickstream-s3-ingest). Cấu hình Gateway VPC Endpoint cho S3 và chỉnh route table private để các thành phần private truy cập S3. Cấu hình và test một ETL Lambda (SBW_Lamda_ETL) có khả năng: Đọc file JSON thô từ s3://clickstream-s3-ingest/events/YYYY/MM/DD/ Transform events thành các dòng dữ liệu cho bảng clickstream_dw.public.clickstream_events Kết nối vào DW (SBW_EC2_ShinyDWH) và chạy các câu truy vấn SQL mẫu: Đếm số lượng events Top sản phẩm Funnel cơ bản Truy cập R Shiny dashboards qua SSM port forwarding và đọc hiểu: Biểu đồ funnel Biểu đồ về mức độ tương tác sản phẩm Biểu đồ time-series hoạt động theo thời gian Nhận thức về bảo mật và chi phí Hiểu được tầm quan trọng của việc bảo mật dữ liệu hành vi người dùng bằng cách không cho EC2_ShinyDWH, Lamda_ETL bằng cách cho EC2_ShinyDWH, Lamda_ETL vào Private subnet. Chỉ cho Lamda_ETL truy cập S3 qua Gateway VPC Endpoint Chỉ cho admin đi vào EC2_ShinyDWH thông qua SSM bằng Interface VPC Endpoints Nhận biết các control bảo mật chính: Phân tách public subnet và private subnet Security group giữa sg_oltp_webDB, sg_Lambda_ETL, sg_analytics_ShinyDWH IAM permission tối thiểu cho từng Lambda Zero-SSH admin sử dụng AWS Systems Manager Session Manager (không cần bastion host, không mở cổng SSH). Phạm vi Workshop Workshop tập trung vào 3 nhóm khả năng chính:\nTriển khai lớp ingestion clickstream\nThu thập tương tác trên browser trong frontend Next.js Gửi sự kiện dạng JSON tới API Gateway (clickstream-http-api) Lưu events thô theo thời gian trong clickstream-s3-ingest Xây dựng lớp analytics private\nTạo VPC, subnets, route tables và VPC endpoints Chạy SBW_Lamda_ETL bên trong VPC Kết nối Lambda ETL tới EC2 Data Warehouse private (SBW_EC2_ShinyDWH) Trực quan hóa analytics với Shiny dashboards\nTruy vấn clickstream_dw từ R Shiny Hiển thị funnel, hiệu quả sản phẩm và trend theo thời gian Truy cập Shiny thông qua SSM Session Manager port forwarding Ngoài phạm vi Để workshop không quá phức tạp, chúng ta không đi sâu vào:\nReal-time streaming (Kinesis, Kafka, MSK, …) Dịch vụ DW nâng cao (Amazon Redshift / Redshift Serverless) Khuyến nghị, segmentation hay anomaly detection dùng ML CI/CD production, blue/green deployment, multi-account Tối ưu SQL nâng cao, thiết kế index chi tiết Đây là những hướng mở rộng tự nhiên sau khi nền tảng batch-based clickstream đã được dựng xong.\n"
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/5-workshop/5.2-architecture-walkthrough/",
	"title": "Architecture Walkthrough",
	"tags": [],
	"description": "",
	"content": "\nHình: Batch-based Clickstream Analytics Platform.\n5.2.1 Miền User \u0026amp; Frontend (1) User Browser – Người dùng Nhiệm vụ\nTruy cập website: duyệt catalogue, xem trang chi tiết sản phẩm, giỏ hàng, checkout… Đăng nhập / đăng ký tài khoản. Phát sinh clickstream events như: page_view, product_view, add_to_cart, purchase, … Vai trò trong pipeline\nLà nguồn gốc mọi hành vi mà hệ thống analytics phân tích. JavaScript ở frontend sẽ gom các event này và gửi về backend thông qua API (6). (2) Amazon CloudFront (CDN / Edge) Nhiệm vụ\nLà lớp CDN phân phối nội dung cho website: Cache HTML/CSS/JS/images để giảm latency. Giảm tải cho origin (Amplify, S3 assets). Có thể làm điểm vào chung cho traffic web: Route/forward request: Nội dung web động → Amplify. Ảnh / media tĩnh → S3 (3). Tại sao quan trọng\nWebsite thương mại điện tử cần tốc độ tải trang tốt. CloudFront giúp cải thiện trải nghiệm người dùng ở nhiều khu vực địa lý. (3) Amazon S3 – Media Assets Nhiệm vụ\nLưu ảnh sản phẩm và các assets tĩnh khác của website. Đóng vai trò origin khi CloudFront (2) phục vụ ảnh/asset. Lưu ý\nBucket này (ví dụ clickstream-s3-sbw) tách biệt khỏi RAW clickstream bucket (8) để: Phân quyền rõ ràng. Dễ quản trị, dễ dọn dẹp. (4) Amazon Amplify – Front-end Hosting Nhiệm vụ\nBuild \u0026amp; deploy ứng dụng Next.js (ví dụ ClickSteam.NextJS). Host frontend (SSR/ISR, API routes). Quản lý pipeline deploy: build, artifact, domain mapping. Liên kết với dịch vụ khác\nKết nối với Cognito (5) để xử lý đăng nhập. Gửi clickstream events từ frontend tới API Gateway (6). Kết nối tới EC2 OLTP (20) qua Prisma để đọc/ghi dữ liệu giao dịch. (5) Amazon Cognito – Authentication / Authorization Nhiệm vụ\nQuản lý user identity: Đăng ký / đăng nhập / reset password. Lưu user pool, cấp token JWT (ID token, access token). Cấp token cho frontend để gọi các API backend theo đúng quyền. Vai trò trong clickstream\nCho phép xác định được trạng thái: user_login_state (logged-in / guest). identity_source (Cognito, social login…). Các thông tin này được gắn vào event và lưu xuống S3/DWH để phân tích hành vi user. 5.2.2 Miền Ingestion \u0026amp; Data Lake (6) Amazon API Gateway – Clickstream HTTP API Nhiệm vụ\nCung cấp endpoint HTTP public cho frontend: POST /clickstream. Thực hiện validate cơ bản: Method/path, throttling. Tùy chọn: tích hợp Cognito authorizer. Luồng xử lý\nNhận request JSON từ browser. Forward payload tới Lambda Clickstream Ingest (7). (7) AWS Lambda – Clickstream Ingest Nhiệm vụ chính\nNhận event từ API Gateway (6).\nĐóng vai trò ingestion layer:\nValidate schema / loại event. Enrich tối thiểu: Sinh event_id. Chuẩn hoá event_timestamp. Gắn client_id, session_id, user_login_state, identity_source nếu cần. Ghi event thô (raw JSON) xuống S3 Clickstream Raw bucket (8) theo prefix/time-partition.\nGhi log ra CloudWatch (17) để debug.\n(8) Amazon S3 – Clickstream Raw Data Nhiệm vụ\nLưu toàn bộ dữ liệu clickstream thô do Lambda Ingest (7) đổ vào.\nĐóng vai trò một “mini data lake” cho batch ETL:\nDữ liệu tổ chức theo folder/prefix thời gian: events/YYYY/MM/DD/. ETL (11) đọc dữ liệu theo lô (theo giờ / theo ngày…). Vai trò kiến trúc\nLà source of truth cho clickstream: Có thể reprocess hoặc rebuild Data Warehouse nếu cần. (9) Amazon EventBridge – ETL Trigger / Cron Job Nhiệm vụ\nChạy lịch batch schedule, ví dụ: rate(1 hour). Mỗi lần đến lịch: Trigger Lambda ETL (11). Tại sao tách riêng\n“Đồng hồ” ETL nằm ở EventBridge: Dễ chỉnh tần suất (1h, 30’, 5’…). Dễ disable/enable. Tách “khi nào chạy” khỏi logic ETL. 5.2.3 Miền VPC \u0026amp; Private Analytics (19) VPC + Subnets + Internet Gateway Amazon VPC\nCô lập mạng, kiểm soát routing / security cho toàn platform. Public subnet – OLTP\nChứa EC2 OLTP (20). Có route 0.0.0.0/0 → Internet Gateway. Cho phép: Amplify/Internet truy cập PostgreSQL OLTP theo SG. Private subnet – Analytics\nChứa: EC2 Shiny + DWH (12). Lambda ETL (11). Không có public IP. Chỉ đi ra ngoài qua các VPC Endpoint (10, 15). Internet Gateway\nCấp đường Internet cho tài nguyên trong public subnet. Private subnet không route ra IGW (trừ khi bạn cấu hình khác). (10) Gateway Endpoint – S3 Gateway Endpoint Nhiệm vụ\nCho phép tài nguyên trong VPC (Lambda ETL, EC2 private) truy cập S3 (8) mà không cần NAT/Internet. Traffic đến S3 đi qua mạng riêng AWS, bảo mật và rẻ hơn NAT Gateway. Vai trò\nLà mảnh ghép quan trọng để: Giữ nguyên quyết định “không dùng NAT Gateway”. Vẫn cho phép ETL / DW đọc ghi S3. (11) AWS Lambda – ETL Nhiệm vụ\nĐược EventBridge (9) trigger theo lịch.\nChạy bên trong private subnet của VPC.\nThực hiện ETL batch:\nĐọc raw events từ S3 (8) qua Gateway Endpoint (10). Transform / clean / flatten theo schema Data Warehouse (ví dụ 15 field bạn đã chốt). Load vào PostgreSQL DWH trên EC2 private (12): Insert / upsert, có thể partition theo ngày/giờ. Ghi log và metrics ra CloudWatch (17); khi lỗi có thể gửi thông báo qua SNS (18).\n(12) Amazon EC2 – Private (Shiny + DWH) Nhiệm vụ\nMáy chủ Data Warehouse (PostgreSQL) + Shiny Server. Nhận dữ liệu đã chuẩn hoá từ Lambda ETL (11) và lưu vào các bảng DWH. Cung cấp dữ liệu cho dashboard Shiny: Shiny truy vấn Postgres local/private. Đặc điểm\nChạy trong private subnet. Không có public IP. Truy cập quản trị qua SSM Session Manager (14 + 15). (13) R Shiny Server (trên EC2 Private) Nhiệm vụ\nHost các dashboard phân tích:\nKPI tổng quan. Conversion funnel. Top products. Hành vi user, session analysis… Kết nối trực tiếp tới PostgreSQL DWH trên cùng EC2.\nTruy cập\nLắng nghe trên port 3838.\nThường được truy cập qua:\nVPN nội bộ, hoặc SSM port forwarding (14). (14) AWS Systems Manager – Session Manager Nhiệm vụ\nCho admin truy cập EC2 private không cần SSH, không cần public IP.\nHỗ trợ:\nMở terminal vào EC2 (run command). Port forwarding (ví dụ forward localhost:3838 → Shiny trên EC2). Audit phiên truy cập tốt hơn. Ví dụ\nBạn có thể chạy Shiny từ máy local tại:\nhttp://localhost:3838/sbw_dashboard\nsau khi cấu hình session port-forward thành công. (15) Interface Endpoint – SSM VPC Endpoints Nhiệm vụ\nTạo đường kết nối private từ EC2/Lambda trong VPC đến các dịch vụ SSM/Session Manager:\nssm, ssmmessages, ec2messages, … Đảm bảo:\nEC2 private vẫn dùng được SSM. Không phải đi qua Internet/NAT. 5.2.4 Cross-cutting Services (16) Amazon IAM Nhiệm vụ\nQuản lý role/policy cho toàn hệ thống:\nPermission cho API Gateway, Lambda. Lambda Ingest ghi S3 (8). Lambda ETL đọc S3 (8) + connect DB (12). EC2 role cho SSM + CloudWatch agent (nếu có). Nguyên tắc\nLeast privilege. Tách quyền rõ theo chức năng và theo từng service. (17) Amazon CloudWatch Nhiệm vụ\nThu thập logs \u0026amp; metrics từ:\nLambda Ingest (7). Lambda ETL (11). EventBridge rule (9). EC2 nếu cài agent. Định nghĩa alarms: lỗi ETL, lỗi ingest, số lần retry, duration, v.v.\nVai trò\nLà nơi debug chính khi pipeline có vấn đề. (18) Amazon SNS Nhiệm vụ\nLà kênh thông báo khi có sự cố:\nETL fail. Ingest fail. CloudWatch alarm kích hoạt. Gửi email / SMS / webhook tuỳ cấu hình.\n(20) Amazon EC2 – Public (OLTP) Nhiệm vụ\nChạy PostgreSQL OLTP phục vụ hệ thống web thương mại điện tử:\nGiao dịch đơn hàng. Thông tin sản phẩm, tồn kho. Thông tin người dùng. Liên hệ với DWH\nTách khỏi Data Warehouse (12):\nOLTP tối ưu cho giao dịch. DWH tối ưu cho phân tích, batch load. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/5-workshop/5.3-implementing-clickstream-ingestion/",
	"title": "Triển khai thu nhận Clickstream",
	"tags": [],
	"description": "",
	"content": "5.3.1 Tổng quan luồng thu nhận Luồng dữ liệu mức cao:\nNgười dùng tương tác với frontend Next.js (ClickSteam.NextJS) được host trên Amplify. JavaScript phía frontend đóng gói metadata clickstream (page/user/session/product) thành payload JSON. Trình duyệt gửi yêu cầu POST tới clickstream-http-api tại POST /clickstream. API Gateway chuyển tiếp yêu cầu tới clickstream-lambda-ingest. Lambda Ingest bổ sung metadata _ingest và ghi mỗi sự kiện thành một tệp JSON vào: s3://clickstream-s3-ingest/events/YYYY/MM/DD/HH/event-\u0026lt;uuid\u0026gt;.json (phân vùng theo giờ UTC) Thiết kế giữ stateless và append-only, phù hợp cho ETL lô phía sau và chèn idempotent.\n5.3.2 Thiết kế S3 Bucket Hai bucket liên quan:\nBucket cho các Asset - clickstream-s3-sbw\nLưu trữ tài nguyên website: ảnh sản phẩm, tệp tĩnh. Không dùng cho sự kiện clickstream. Bucket Clickstream RAW - clickstream-s3-ingest\nChỉ lưu sự kiện clickstream JSON thô. Phân vùng theo giờ UTC: events/YYYY/MM/DD/HH/ Đặt tên tệp: event-\u0026lt;uuid\u0026gt;.json Phân vùng theo giờ giúp ETL lô dễ hơn (vd xử lý giờ trước hoặc prefix ngày/giờ cụ thể).\n5.3.3 Thiết kế Lambda Ingest - clickstream-lambda-ingest Nhiệm vụ Hàm clickstream-lambda-ingest:\nPhân tích payload JSON nhận từ API Gateway. Chỉ thêm metadata _ingest: receivedAt, sourceIp, userAgent, method, path, requestId, apiId, stage, traceId. Ghi phần thân sự kiện đúng như client gửi (không tự điền user/session/product phía server) vào S3. Quyền IAM Vai trò thực thi cần:\ns3:PutObject trên: arn:aws:s3:::clickstream-s3-ingest/events/* Các API CloudWatch Logs để ghi log. Hàm không cần quyền đọc.\n5.3.4 API Gateway HTTP API - clickstream-http-api HTTP API cung cấp endpoint HTTPS công khai cho ingestion:\nRoute: POST /clickstream -\u0026gt; Lambda clickstream-lambda-ingest Tùy chọn khuyến nghị:\nBật CORS để frontend Amplify có thể gọi từ domain của nó. Bật access log tới CloudWatch log group để debug. (Tùy chọn) Gắn API key hoặc Cognito authorizer nếu muốn hạn chế ingestion. 5.3.5 Frontend Clickstream Publisher (Logic) Danh tính \u0026amp; tính idempotent Sinh eventId cho mỗi sự kiện (UUID) để đảm bảo nguyên lý idempotent. Giữ clientId trong localStorage (cố định theo trình duyệt). Giữ sessionId trong sessionStorage (timeout nhàn rỗi 30 phút) và isFirstVisit. Metadata người dùng, trang và click Người dùng/xác thực (nếu có): userId, userLoginState, tùy chọn identity_source. Trang/click: pageUrl, referrer, metadata phần tử cho click (tag/id/role/text/dataset). Ngữ cảnh sản phẩm Gửi dưới dạng product.{id,name,category,brand,price,discountPrice,urlPath}; ETL ánh xạ tới các cột DW context_product_*. Phạm vi sự kiện Tự động: page_view, click toàn cục. Tùy chỉnh/sản phẩm: home_view, category_view, product_view, add_to_cart_click, remove_from_cart_click, wishlist_toggle, share_click, login_open, login_success, logout, checkout_start, checkout_complete. Mapping sự kiện domain home_view: load trang chủ (component tracker). category_view: render danh sách danh mục (slug/params). product_view: render chi tiết sản phẩm (có ngữ cảnh sản phẩm). add_to_cart_click / remove_from_cart_click: handler thêm/xóa giỏ. wishlist_toggle: handler nút wishlist. share_click: handler nút chia sẻ. login_open / login_success / logout: luồng auth. checkout_start / checkout_complete: bước vào checkout và hoàn tất. Component \u0026amp; wiring lib/clickstreamClient.ts: xử lý danh tính/phiên, builder cơ sở, log console, fetch fire-and-forget tới NEXT_PUBLIC_CLICKSTREAM_ENDPOINT (biến môi trường bắt buộc). lib/clickstreamEvents.ts: helper domain bọc trackCustom và dựng ngữ cảnh sản phẩm/giỏ/đơn hàng. contexts/ClickstreamProvider.tsx + app/layout.tsx: nối provider toàn cục, tự động page_view, listener click toàn cục. Component tracker: HomeTracker.tsx, CategoryTracker.tsx, ProductViewTracker.tsx bỏ qua auto page_view và phát sự kiện domain. UI đã gắn: AddToCartButton.tsx, FavoriteButton.tsx, app/(client)/cart/page.tsx phát sự kiện thêm/xóa giỏ, wishlist, checkout và đánh dấu nút với global-clickstream-ignore-click để tránh click toàn cục trùng lặp. Hành vi runtime Chỉ chạy phía client (không có hiệu ứng SSR). Log mọi sự kiện lên console; nếu thiếu endpoint, chạy dry-run và cảnh báo một lần. Lỗi mạng không chặn UI. 5.3.6 Chiếu trường (frontend -\u0026gt; S3 -\u0026gt; DW) Trường / Khối Payload frontend Raw S3 (sau Ingest) DW (PostgreSQL) Ghi chú event_id eventId sinh ở client giữ nguyên payload event_id (ánh xạ từ eventId; ETL fallback UUID) Khóa chính, ON CONFLICT DO NOTHING event_timestamp - - (có LastModified của S3) _ingest.receivedAt \u0026gt; payload \u0026gt; LastModified ETL suy ra event_name eventName eventName event_name page_url pageUrl pageUrl - Không lưu trong DW referrer referrer referrer - Không lưu trong DW user_id userId userId user_id user_login_state userLoginState userLoginState user_login_state identity_source tùy chọn tùy chọn identity_source Cần frontend/auth cung cấp client_id clientId clientId client_id session_id sessionId sessionId session_id is_first_visit isFirstVisit isFirstVisit is_first_visit product id product.id product.id context_product_id product name product.name product.name context_product_name product category product.category product.category context_product_category product brand product.brandName / brand?.name / brand?.title / brand product.brand hoặc product.brandName context_product_brand Frontend ánh xạ brand từ các trường DB product price product.price product.price context_product_price BIGINT product discount price product.discountPrice product.discountPrice context_product_discount_price BIGINT product url path product.urlPath product.urlPath context_product_url_path element metadata element.{tag,id,role,text,dataset} element... - Không lưu (cần thay đổi schema) ingest metadata - _ingest.{receivedAt,sourceIp,userAgent,method,path,requestId,apiId,stage,traceId} - Không lưu; chỉ có khi ETL Mẫu gọi (mỗi yêu cầu một sự kiện):\nawait fetch(\u0026#34;https://\u0026lt;api-id\u0026gt;.execute-api.ap-southeast-1.amazonaws.com/clickstream\u0026#34;, { method: \u0026#34;POST\u0026#34;, headers: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; }, body: JSON.stringify(eventPayload), keepalive: true, }); ETL ánh xạ eventId -\u0026gt; event_id (PK với ON CONFLICT DO NOTHING), suy ra event_timestamp từ _ingest.receivedAt \u0026gt; payload \u0026gt; S3 LastModified, và chèn vào clickstream_dw.public.clickstream_events.\n5.3.6 Kiểm thử \u0026amp; xác nhận Để kiểm tra thu nhận:\nDùng UI của app Amplify: Duyệt vài trang sản phẩm Thêm sản phẩm vào giỏ Kiểm tra bucket S3 clickstream-s3-ingest: Điều hướng tới events/YYYY/MM/DD/HH/ Xác nhận xuất hiện các tệp mới event-\u0026lt;uuid\u0026gt;.json. Mở một tệp JSON: Kiểm tra metadata _ingest và ngữ cảnh sản phẩm có mặt. Xem log: API Gateway access logs Lambda function logs "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/5-workshop/5.4-building-the-private-analytics-layer/",
	"title": "Xây dựng lớp Private Analytics",
	"tags": [],
	"description": "",
	"content": "5.4.1 Cấu hình VPC, Subnets và Route Tables VPC CIDR: 10.0.0.0/16 Public subnet: 10.0.0.0/20 → SBW_Project-subnet-public1-ap-southeast-1a Chứa SBW_EC2_WebDB (EC2 OLTP). Private subnet: 10.0.128.0/20 → SBW_Project-subnet-private1-ap-southeast-1a Chứa SBW_EC2_ShinyDWH và SBW_Lamda_ETL. Public Route Table\n10.0.0.0/16 → local 0.0.0.0/0 → Internet Gateway Private Route Table\n10.0.0.0/16 → local S3 prefix list → Gateway VPC Endpoint cho S3 Không có route 0.0.0.0/0 tới IGW hoặc NAT Gateway 5.4.2 VPC Endpoints (S3 \u0026amp; SSM) S3 Gateway VPC Endpoint Cho phép truy cập S3 trong private network cho: SBW_Lamda_ETL Không cần dùng NAT Gateway. SSM Interface Endpoints com.amazonaws.ap-southeast-1.ssm com.amazonaws.ap-southeast-1.ssmmessages com.amazonaws.ap-southeast-1.ec2messages Các endpoint này cho phép Session Manager quản lý và port-forward tới SBW_EC2_ShinyDWH mà không cần public IP hay cổng SSH.\n5.4.3 Data Warehouse trên EC2 – SBW_EC2_ShinyDWH Trên EC2 private này:\nPostgreSQL DB: clickstream_dw Bảng chính: clickstream_events với các field: event_id event_timestamp event_name user_id user_login_state identity_source client_id session_id is_first_visit context_product_id context_product_name context_product_category context_product_brand context_product_price context_product_discount_price context_product_url_path Instance cho phép:\nSBW_Lamda_ETL conect postgreSQL DB: clickstream_dw Localhost web Shiny thông qua SSM 5.4.4 ETL Lambda – SBW_Lamda_ETL (chạy trong Private subnet) ETL Lambda là nơi xử lý batch chính.\nCấu hình VPC:\nSubnet: SBW_Project-subnet-private1-ap-southeast-1a Security group: sg_Lambda_ETL Environment variables:\nDWH_HOST, DWH_PORT=5432, DWH_USER, DWH_PASSWORD, DWH_DATABASE=clickstream_dw RAW_BUCKET=clickstream-s3-ingest AWS_REGION=ap-southeast-1 Nhiệm vụ:\nXác định danh sách files trong s3://clickstream-s3-ingest/events/YYYY/MM/DD/ cho batch cần xử lý. Với mỗi file JSON: Extra Transform Load IAM role:\nCấp quyền cho Lamda truy cập vào EC2_ShinyDWH 5.4.5 Lên lịch bằng EventBridge – SBW_ETL_HOURLY_RULE EventBridge giúp nền tảng hoạt động theo kiểu batch:\nTên rule: SBW_ETL_HOURLY_RULE Schedule: rate(1 hour) Target: SBW_Lamda_ETL Mỗi lần rule chạy:\nETL Lambda chạy trong private subnet. Đọc các events mới từ S3 qua Gateway Endpoint. Nạp dữ liệu đã xử lý vào clickstream_dw. Ta cũng có thể trigger ETL Lambda thủ công (từ Lambda console) cho mục đích backfill hoặc test.\n5.4.6 Tóm tắt Security Groups \u0026amp; Connectivity sg_Lambda_ETL:\nOutbound tới S3 endpoint và sg_analytics_ShinyDWH:5432. sg_analytics_ShinyDWH:\nInbound 5432/tcp từ sg_Lambda_ETL. Inbound 3838/tcp cho Shiny (chỉ dùng qua SSM port forwarding). "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/5-workshop/5.5-visualizing-analytics-with-shiny-dashboards/",
	"title": "Trực quan hóa phân tích với các bảng điều khiển Shiny",
	"tags": [],
	"description": "",
	"content": "5.5.1 Thông tin môi trường OS: Ubuntu 22.04 (Jammy) – EC2 trong private subnet PostgreSQL: v18 (cài từ repo apt.postgresql.org) Shiny Server: bản binary .deb từ RStudio (Posit) User chạy Shiny: shiny Đường dẫn app: /srv/shiny-server/sbw_dashboard/app.R 5.5.2 Cài các package hệ thống (system libs) Lưu ý cần bật NAT Gateway trước khi tải các buckets hệ thống. Đăng nhập EC2 bằng SSM Session Manager hoặc SSH (tạm thời, nếu có), sau đó chạy:\n# 1) Update danh sách package sudo apt-get update # 2) Cài R (nếu chưa cài) sudo apt-get install -y r-base # 3) Cài Postgres client \u0026amp; dev headers (cho RPostgres) # Nếu DB của bạn là PG 18 thì dùng postgresql-server-dev-18 # (nếu version khác thì đổi số 18 -\u0026gt; 14, 15, ...) sudo apt-get install -y postgresql-client-18 postgresql-server-dev-18 # 4) Cài libpq + libssl (bắt buộc để build RPostgres) sudo apt-get install -y libpq-dev libssl-dev # 5) (Nếu chưa cài Shiny Server) # Tùy theo cách bạn đã cài, ở đây chỉ ghi nhớ: # - shiny-server service: /etc/systemd/system/shiny-server.service # - thư mục app: /srv/shiny-server/ # - user chạy: shiny Kiểm tra lại libpq và dev headers đã có:\ndpkg -l | grep -E \u0026#39;libpq-dev|postgresql-server-dev\u0026#39; || echo \u0026#34;MISSING_LIBS\u0026#34; ls -l /usr/include/postgresql/libpq-fe.h || echo \u0026#34;NO_LIBPQ_HEADER\u0026#34; Nếu không thấy lỗi → OK.\n5.5.3 Cấu hình thư mục R libraries cho user shiny Để Shiny Server load được các package R, ta cài package dưới user shiny và dùng thư mục:\n/home/shiny/R/x86_64-pc-linux-gnu-library/4.1 Chạy:\nsudo -u shiny R --vanilla \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; # Tạo thư mục library cho user shiny nếu chưa có dir.create(Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), recursive = TRUE, showWarnings = FALSE) # Đưa R_LIBS_USER lên đầu .libPaths() .libPaths(c(Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), .libPaths())) cat(\u0026#34;LIBPATHS: \u0026#34;); print(.libPaths()) q(\u0026#34;no\u0026#34;) EOF Bạn sẽ thấy LIBPATHS có dòng 1 là /home/shiny/R/x86_64-pc-linux-gnu-library/4.1.\n5.5.4 Cài các R package cần thiết Các package cần cho dashboard:\nshiny DBI RPostgres dplyr ggplot2 lubridate pool Cài tất cả dưới user shiny:\nsudo -u shiny R --vanilla \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; dir.create(Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), recursive = TRUE, showWarnings = FALSE) .libPaths(c(Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), .libPaths())) cat(\u0026#34;LIBPATHS: \u0026#34;); print(.libPaths()) install.packages( c(\u0026#34;shiny\u0026#34;, \u0026#34;DBI\u0026#34;, \u0026#34;RPostgres\u0026#34;, \u0026#34;dplyr\u0026#34;, \u0026#34;ggplot2\u0026#34;, \u0026#34;lubridate\u0026#34;, \u0026#34;pool\u0026#34;), repos = \u0026#34;https://cloud.r-project.org\u0026#34; ) q(\u0026#34;no\u0026#34;) EOF 💡 Nếu gặp lỗi liên quan tới libpq-fe.h hoặc libpq:\nKiểm tra lại đã cài libpq-dev, postgresql-server-dev-XX, libssl-dev chưa. Chạy lại install.packages(\u0026quot;RPostgres\u0026quot;, ...) sau khi cài đủ libs. Kiểm tra lại việc load package:\nsudo -u shiny R --vanilla \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; .libPaths(c(Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), .libPaths())) cat(\u0026#34;LIBPATHS: \u0026#34;); print(.libPaths()) library(shiny) library(DBI) library(RPostgres) library(dplyr) library(ggplot2) library(lubridate) library(pool) cat(\u0026#34;All packages loaded OK \u0026#34;) q(\u0026#34;no\u0026#34;) EOF Nếu không có error → môi trường R đã OK.\n5.5.5 Triển khai Shiny app 5.5.5.1 Tạo thư mục app và copy code sudo mkdir -p /srv/shiny-server/sbw_dashboard sudo chown -R shiny:shiny /srv/shiny-server/sbw_dashboard Tạo (hoặc thay) file app:\nsudo nano /srv/shiny-server/sbw_dashboard/app.R # DÁN TOÀN BỘ CODE app.R (bản full mà bạn đang dùng) # Ctrl+O, Enter, Ctrl+X để lưu Đảm bảo quyền:\nsudo chown shiny:shiny /srv/shiny-server/sbw_dashboard/app.R sudo chmod 644 /srv/shiny-server/sbw_dashboard/app.R 5.5.5.2 Restart Shiny Server sudo systemctl restart shiny-server sudo systemctl status shiny-server 5.5.6 Kiểm tra app từ EC2 (local) Từ session SSM trên EC2 (terminal):\n# Check trang welcome Shiny curl -m 5 -sS -o /dev/null -w \u0026#34;WELCOME HTTP %{http_code} \u0026#34; http://127.0.0.1:3838/ # Check app SBW dashboard curl -m 10 -sS -o /dev/null -w \u0026#34;DASHBOARD HTTP %{http_code} \u0026#34; http://127.0.0.1:3838/sbw_dashboard/ Nếu trả về DASHBOARD HTTP 200 → app chạy OK.\nNếu trả về 500:\nLATEST=$(ls -1t /var/log/shiny-server/sbw_dashboard-shiny-*.log | head -n 1) echo \u0026#34;LATEST=$LATEST\u0026#34; sudo tail -n 100 \u0026#34;$LATEST\u0026#34; Xem error log để debug.\n5.5.7 Truy cập dashboard từ máy local Vì EC2 ở private subnet, bạn dùng SSM port forwarding:\n# Ví dụ dùng AWS CLI v2 trên máy local: aws ssm start-session --target \u0026lt;INSTANCE_ID_PRIVATE\u0026gt; --document-name AWS-StartPortForwardingSessionToRemoteHost --parameters \u0026#39;{\u0026#34;host\u0026#34;:[\u0026#34;127.0.0.1\u0026#34;],\u0026#34;portNumber\u0026#34;:[\u0026#34;3838\u0026#34;],\u0026#34;localPortNumber\u0026#34;:[\u0026#34;3838\u0026#34;]}\u0026#39; Sau đó, trên máy local mở trình duyệt tới:\nhttp://127.0.0.1:3838/sbw_dashboard/ Dashboard sẽ hiển thị với, ví dụ:\nCác KPI cards (tổng số events, users, sessions…) Biểu đồ events over time, event mix, events by login state Tab Products \u0026amp; Raw sample (phân trang, newest trước, auto refresh mỗi 10s – tuỳ code app của bạn) 5.5.8 Tóm tắt nhanh các lệnh quan trọng # Cài system libs sudo apt-get update sudo apt-get install -y r-base postgresql-client-18 postgresql-server-dev-18 libpq-dev libssl-dev # Cài R packages cho user shiny sudo -u shiny R --vanilla \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; dir.create(Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), recursive = TRUE, showWarnings = FALSE) .libPaths(c(Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), .libPaths())) install.packages( c(\u0026#34;shiny\u0026#34;, \u0026#34;DBI\u0026#34;, \u0026#34;RPostgres\u0026#34;, \u0026#34;dplyr\u0026#34;, \u0026#34;ggplot2\u0026#34;, \u0026#34;lubridate\u0026#34;, \u0026#34;pool\u0026#34;), repos = \u0026#34;https://cloud.r-project.org\u0026#34; ) q(\u0026#34;no\u0026#34;) EOF # Deploy app sudo mkdir -p /srv/shiny-server/sbw_dashboard sudo nano /srv/shiny-server/sbw_dashboard/app.R # dán code sudo chown -R shiny:shiny /srv/shiny-server/sbw_dashboard sudo systemctl restart shiny-server # Kiểm tra dashboard curl -m 10 -sS -o /dev/null -w \u0026#34;DASHBOARD HTTP %{http_code} \u0026#34; http://127.0.0.1:3838/sbw_dashboard/ "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/5-workshop/5.6-summary--clean-up/",
	"title": "Tổng kết &amp; Dọn dẹp",
	"tags": [],
	"description": "",
	"content": "5.6.1 Tóm tắt Sau khi hoàn thành bài Lab chúng ta đã dựng được một Clickstream Analytics Platform hoàn chỉnh:\nLớp User-Facing\nỨng dụng Next.js (ClickSteam.NextJS) trên Amplify + CloudFront Xác thực người dùng bằng Cognito PostgreSQL OLTP (clickstream_web) trên SBW_EC2_WebDB (public subnet) Lớp Ingestion \u0026amp; Raw Data\nAPI Gateway HTTP API: clickstream-http-api (route POST /clickstream) Lambda Ingest: clickstream-lambda-ingest S3 Raw bucket: clickstream-s3-ingest/events/YYYY/MM/DD/event-\u0026lt;uuid\u0026gt;.json Lớp Analytics Private\nVPC với public \u0026amp; private subnets (SBW_Project_VPC) S3 Gateway Endpoint, SSM Interface Endpoints Data Warehouse trên EC2: SBW_EC2_ShinyDWH, DB clickstream_dw ETL Lambda trong VPC: SBW_Lamda_ETL, được trigger bởi SBW_ETL_HOURLY_RULE R Shiny dashboards (sbw_dashboard) chỉ truy cập qua SSM port forwarding Tổng thể, kiến trúc này cho thấy cách thiết kế một batch-based analytics platform an toàn, tối ưu chi phí, chủ yếu dùng serverless + hai EC2.\n5.6.2 Nội dung chính Separation of concerns: OLTP và Analytics tách trên 2 EC2 khác nhau, thuộc các domain logic khác nhau. Security: DW và Shiny chạy trong private subnet, không có public IP. SSM Session Manager thay thế SSH truyền thống. S3 Gateway Endpoint giữ traffic S3 trong private network của AWS. Tối ưu chi phí: Không sử dụng NAT Gateway. ETL dùng serverless (Lambda + EventBridge). S3 làm storage giá rẻ cho dữ liệu thô. Dễ mở rộng: Thiết kế hiện tại là batch-based, nhưng có thể mở rộng sang real-time, analytics phức tạp hơn hoặc chuyển sang các công nghệ DW khác. 5.6.3 Dọn dẹp Resource Amplify \u0026amp; CloudFront\nXóa Amplify app (ClickSteam.NextJS). Thao tác này cũng xóa CloudFront distribution. API Gateway \u0026amp; Lambda\nXóa clickstream-http-api. Xóa các Lambda: clickstream-lambda-ingest SBW_Lamda_ETL EventBridge\nXóa rule SBW_ETL_HOURLY_RULE. S3 Buckets\nLàm rỗng (empty) rồi xóa: clickstream-s3-ingest (RAW clickstream) clickstream-s3-sbw (assets) nếu không dùng cho dự án khác EC2 Instances\nStop hoặc terminate: SBW_EC2_WebDB SBW_EC2_ShinyDWH Release Elastic IP (nếu có gán). VPC \u0026amp; Networking\nXóa VPC endpoints (S3 Gateway, SSM Interface Endpoints). Xóa route tables, subnets, Internet Gateway. Cuối cùng, xóa SBW_Project_VPC nếu không còn dùng. "
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/tranhoangtin-se185022-AWSFCJ/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]